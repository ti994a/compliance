{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ae2603e-4fea-446e-9216-700fc15171c2",
   "metadata": {},
   "source": [
    "## ScenarioJudger\n",
    "\n",
    " - Reads a file from S3 containing json compliance scenarios of the format:\n",
    "```json\n",
    "{\n",
    "  \"scenarios\": [\n",
    "    {\n",
    "      \"scenario-id\": \"scenario-id-1\",\n",
    "      \"scenario-detail\": \"A new employee, Sarah Johnson, joins the IT department...\",\n",
    "      \"is-compliant\": false,\n",
    "      \"non-compliant-reason\": \"The scenario violates...\" \n",
    "    },\n",
    "    {\n",
    "      \"scenario-id\": \"scenario-id-2\", \n",
    "      \"scenario-detail\": \"TechCorp implements a comprehensive incident response procedure...\",\n",
    "      \"is-compliant\": true,\n",
    "      \"non-compliant-reason\": \"\" \n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    " - Evaluates the veracity each scenario-detail based on RAGed NIST-based policies in Bedrock knowledgebase, comparing its determination against \"is-compliant\" in the json.\n",
    " - When its determination differs, generates json records:\n",
    "```json\n",
    "{\n",
    "  \"scenarios\": [\n",
    "    {\n",
    "      \"scenario-id\": \"scenario-id-1\",\n",
    "      \"scenario-detail\": \"A new employee, Sarah Johnson, joins the IT department...\",\n",
    "      \"is-compliant\": false,\n",
    "      \"non-compliant-reason\": \"The scenario violates...\",\n",
    "      \"judged-compliant\": true,\n",
    "      \"judged-compliant-reason\": \"Considered the rules AC...  and scenario is not in violation...\"\n",
    "      \"llm-judge\": \"us.anthropic.claude-sonnet-4-20250514-v1:0\",\n",
    "      \"judged-dtm\":  \n",
    "    },\n",
    "    {\n",
    "      \"scenario-id\": \"scenario-id-2\", \n",
    "      \"scenario-detail\": \"TechCorp implements a comprehensive incident response procedure...\",\n",
    "      \"is-compliant\": true,\n",
    "      \"non-compliant-reason\": \"\", \n",
    "      \"judged-compliant\": false,\n",
    "      \"judged-compliant-reason\": \"Scenario violates access control policy...\",\n",
    "      \"llm-judge\": \"us.anthropic.claude-sonnet-4-20250514-v1:0\",\n",
    "      \"judged-dtm\":   \n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    " - Stores json records back to S3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "execution_state": "idle",
   "id": "721c6452-39b4-4d10-875f-87c1fb55f2df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T22:37:42.218771Z",
     "iopub.status.busy": "2025-12-16T22:37:42.218450Z",
     "iopub.status.idle": "2025-12-16T22:37:42.316703Z",
     "shell.execute_reply": "2025-12-16T22:37:42.307549Z",
     "shell.execute_reply.started": "2025-12-16T22:37:42.218703Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import boto3  # AWS SDK for Python\n",
    "import datetime\n",
    "import json   # JSON handling\n",
    "import time   # For rate limiting between API calls\n",
    "from typing import List, Dict  # Type hints\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION SECTION - Update these values\n",
    "# ============================================================================\n",
    "# S3 Configuration\n",
    "INPUT_BUCKET = '183023889407-us-east-1-compliance-rule-generator'\n",
    "INPUT_PREFIX = 'scenarios/'  # Folder path in S3 where scenarios are stored\n",
    "OUTPUT_BUCKET = '183023889407-us-east-1-compliance-rule-generator'\n",
    "OUTPUT_PREFIX = 'scenarios-judged/'  # Folder path for results\n",
    "# AWS Region\n",
    "AWS_REGION = 'us-east-1'\n",
    "# AWS Bedrock Knowledge Base containing NIST policies\n",
    "KNOWLEDGE_BASE_ID = 'T8EW10IU3Z'\n",
    "\n",
    "MAX_TOKENS = 4096\n",
    "TEMPERATURE = 0.7\n",
    "\n",
    "# Available Bedrock model ARNs with performance notes\n",
    "MODELS = {\n",
    "    'premium': 'arn:aws:bedrock:us-east-1:183023889407:inference-profile/global.anthropic.claude-opus-4-5-20251101-v1:0', # not available\n",
    "    'good': 'arn:aws:bedrock:us-east-1:183023889407:inference-profile/global.anthropic.claude-sonnet-4-5-20250929-v1:0', # times out\n",
    "    'balanced': 'arn:aws:bedrock:us-east-1:183023889407:inference-profile/us.anthropic.claude-sonnet-4-20250514-v1:0',  # recommended\n",
    "    'fast_cheap': 'arn:aws:bedrock:us-east-1:183023889407:inference-profile/us.anthropic.claude-haiku-4-5-20251001-v1:0',\n",
    "    'aws_native_premier': 'arn:aws:bedrock:us-east-1:183023889407:inference-profile/us.amazon.nova-premier-v1:0',\n",
    "    'aws_native_pro': 'arn:aws:bedrock:us-east-1:183023889407:inference-profile/us.amazon.nova-pro-v1:0'\n",
    "}\n",
    "MODEL_ARN = MODELS['balanced']  # Default model selection\n",
    "\n",
    "# JSON tool configuration for Bedrock Converse API\n",
    "# Forces the model to return structured JSON with specific schema\n",
    "TOOL_CONFIG = {\n",
    "    \"tools\": [{\n",
    "        \"toolSpec\": {\n",
    "            \"name\": \"judged_scenario_json\",\n",
    "            \"description\": \"Return judged compliance scenarios as JSON\",\n",
    "            \"inputSchema\": {\n",
    "                \"json\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"scenarios\": {  # Array of scenario objects\n",
    "                            \"type\": \"array\",\n",
    "                            \"items\": {\n",
    "                                \"type\": \"object\",\n",
    "                                \"properties\": {\n",
    "                                    \"judged-compliant\": {\"type\": \"boolean\"},\n",
    "                                    \"judged-compliant-reason\": {\"type\": \"string\"}\n",
    "                                },\n",
    "                                \"required\": [\"judged-compliant\", \"judged-compliant-reason\"]\n",
    "                            }\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"scenarios\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }],\n",
    "    \"toolChoice\": {\"tool\": {\"name\": \"judged_scenario_json\"}}  # Force use of the JSON tool\n",
    "}\n",
    "\n",
    "# Initialize AWS Bedrock clients\n",
    "bedrock_agent_runtime = boto3.client('bedrock-agent-runtime', region_name='us-east-1')  # For knowledge base retrieval\n",
    "bedrock_runtime = boto3.client('bedrock-runtime', region_name='us-east-1')  # For model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "execution_state": "idle",
   "id": "1abdea2c-e311-4358-8b11-3f02472ad8ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T22:37:46.662009Z",
     "iopub.status.busy": "2025-12-16T22:37:46.661637Z",
     "iopub.status.idle": "2025-12-16T22:37:46.667517Z",
     "shell.execute_reply": "2025-12-16T22:37:46.666114Z",
     "shell.execute_reply.started": "2025-12-16T22:37:46.661984Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_scenarios_from_s3(input_bucket: str = INPUT_BUCKET, input_prefix: str = INPUT_PREFIX, object_name: str = \"scenarios.json\") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Load scenarios from S3 JSON file.\n",
    "    \"\"\"\n",
    "    s3 = boto3.client('s3')\n",
    "    response = s3.get_object(Bucket=input_bucket, Key=input_prefix+object_name)\n",
    "    json_data = json.loads(response['Body'].read().decode('utf-8'))\n",
    "    return json_data[\"scenarios\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "execution_state": "idle",
   "id": "fa5e2795-d84a-452f-9dba-a9ede04e259f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T22:54:41.019750Z",
     "iopub.status.busy": "2025-12-16T22:54:41.019473Z",
     "iopub.status.idle": "2025-12-16T22:54:41.025107Z",
     "shell.execute_reply": "2025-12-16T22:54:41.023887Z",
     "shell.execute_reply.started": "2025-12-16T22:54:41.019728Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_scenarios_to_s3(scenarios: List[Dict], output_bucket: str = OUTPUT_BUCKET, output_prefix: str = OUTPUT_PREFIX, object_name: str = \"scenarios.json\"):\n",
    "    \"\"\"\n",
    "    Save generated scenarios to a S3.\n",
    "    \"\"\"\n",
    "    s3 = boto3.client('s3')\n",
    "    json_data = json.dumps({\"scenarios\": scenarios}, indent=2)\n",
    "    s3.put_object(Bucket=output_bucket, Key=output_prefix+object_name, Body=json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "execution_state": "idle",
   "id": "b17b51d7-4d3c-4258-bd1b-58e80adb8763",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T22:37:48.795006Z",
     "iopub.status.busy": "2025-12-16T22:37:48.794552Z",
     "iopub.status.idle": "2025-12-16T22:37:48.800388Z",
     "shell.execute_reply": "2025-12-16T22:37:48.799187Z",
     "shell.execute_reply.started": "2025-12-16T22:37:48.794979Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_scenarios_to_file(scenarios: List[Dict], output_path: str):\n",
    "    \n",
    "    # Print scenarios to console for immediate review\n",
    "    print(json.dumps(scenarios, indent=2))\n",
    "    \n",
    "    # Save to file with metadata and statistics\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump({\n",
    "            'total_scenarios': len(scenarios),\n",
    "            'compliant_count': sum(1 for s in scenarios if s['is-compliant']),\n",
    "            'non_compliant_count': sum(1 for s in scenarios if not s['is-compliant']),\n",
    "            'judged compliant_count': sum(1 for s in scenarios if s['judged-compliant']),\n",
    "            'judged non_compliant_count': sum(1 for s in scenarios if not s['judged-compliant']),\n",
    "            'scenarios': scenarios\n",
    "        }, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "execution_state": "idle",
   "id": "new-process-cell",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T23:08:49.535256Z",
     "iopub.status.busy": "2025-12-16T23:08:49.534961Z",
     "iopub.status.idle": "2025-12-16T23:08:49.547095Z",
     "shell.execute_reply": "2025-12-16T23:08:49.545653Z",
     "shell.execute_reply.started": "2025-12-16T23:08:49.535235Z"
    }
   },
   "outputs": [],
   "source": [
    "def judge_scenarios(source_scenarios: List[Dict], model_arn: str, kb_id: str = KNOWLEDGE_BASE_ID) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Process scenarios and add judgment fields.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract model ID from ARN (Converse API requires model ID, not full ARN)\n",
    "    model_id = model_arn.split('/')[-1] if '/' in model_arn else model_arn\n",
    "    \n",
    "    judged_scenarios = []\n",
    "    for scenario in source_scenarios:\n",
    "        judged_scenario = scenario.copy()\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        You are **ComplianceEvaluator**, an expert AI compliance analyst specializing in NIST 800-53 security and privacy controls. \n",
    "        Your mission is to evaluate organizational scenarios, systems, and practices against NIST 800-53 controls and organizational \n",
    "        policies stored in your knowledge base.\n",
    "        \n",
    "        **Your Expertise Includes:**\n",
    "        - Deep understanding of all NIST 800-53 Rev. 5 control families (AC, AT, AU, CA, CM, CP, IA, IR, MA, MP, PE, PL, PM, PS, PT, RA, SA, SC, SI, SR)\n",
    "        - Control baseline mapping (Low, Moderate, High impact levels)\n",
    "        - FedRAMP, FISMA, and related compliance frameworks\n",
    "        - Risk assessment methodologies\n",
    "        - Security architecture evaluation\n",
    "        - Policy-to-control mapping\n",
    "        \n",
    "        **Your Disposition:**\n",
    "        - Thorough and methodical in analysis\n",
    "        - Evidence-focused in assessments\n",
    "        \n",
    "        Knowledgebase Retrieval Strategy\n",
    "        \n",
    "        When evaluating any scenario, you MUST:\n",
    "        1. **Query for Applicable Controls**: Search the knowledge base for NIST 800-53 controls relevant to the scenario's\n",
    "        security domains (access control, audit, encryption, etc.)\n",
    "        2. **Query for Organizational Policies**: Retrieve organization-specific policies that implement or extend the baseline controls\n",
    "\n",
    "        Respond with JSON format:\n",
    "        {{\n",
    "          \"judged-compliant\": true/false, true if you determined the scenario is compliant against NIST 800-53 controls and organizational \n",
    "        policies stored in your knowledge base.  false if the scenario is not compliant.\n",
    "          \"judged-compliant-reason\": \"Empty if compliant. If the scenario is not compliant, explain very briefly why it is not compliant, citing\n",
    "          exactly the policy ID(s) is violates.\"\n",
    "        }}\n",
    "\n",
    "        **Here is the compliance scenario to evaluate**:\n",
    "        {scenario[\"scenario-detail\"]}\n",
    "        \"\"\"\n",
    "\n",
    "        response = bedrock_agent_runtime.retrieve_and_generate(\n",
    "            input={'text': prompt},\n",
    "            retrieveAndGenerateConfiguration={\n",
    "                'type': 'KNOWLEDGE_BASE',\n",
    "                'knowledgeBaseConfiguration': {\n",
    "                    'knowledgeBaseId': kb_id,\n",
    "                    'modelArn': model_arn,\n",
    "                    'generationConfiguration': {\n",
    "                        'inferenceConfig': {\n",
    "                            'textInferenceConfig': {\n",
    "                                'maxTokens': MAX_TOKENS,\n",
    "                                'temperature': TEMPERATURE\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "            \n",
    "        response_text = response['output']['text']\n",
    "        try:\n",
    "            if '{' in response_text:\n",
    "                json_start = response_text.find('{')\n",
    "                json_end = response_text.rfind('}') + 1\n",
    "                json_str = response_text[json_start:json_end]\n",
    "                result = json.loads(json_str)\n",
    "                judged_scenario[\"judged-compliant\"] = result.get('judged-compliant', False)\n",
    "                judged_scenario[\"judged-compliant-reason\"] = result.get('judged-compliant-reason', '')\n",
    "            else:\n",
    "                judged_scenario[\"judged-compliant\"] = 'compliant' in response_text.lower()\n",
    "                judged_scenario[\"judged-compliant-reason\"] = response_text\n",
    "        except:\n",
    "            judged_scenario[\"judged-compliant\"] = False\n",
    "            judged_scenario[\"judged-compliant-reason\"] = response_text\n",
    "        judged_scenario[\"llm-judge\"] = MODEL_ARN.split('/')[-1]\n",
    "        judged_scenario[\"judged-dtm\"] = datetime.datetime.now().isoformat()\n",
    "        judged_scenarios.append(judged_scenario)\n",
    "    \n",
    "    return judged_scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "execution_state": "idle",
   "id": "8b5a5088-bba4-4786-82b1-44374c091b26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T23:08:51.063933Z",
     "iopub.status.busy": "2025-12-16T23:08:51.063572Z",
     "iopub.status.idle": "2025-12-16T23:09:24.810365Z",
     "shell.execute_reply": "2025-12-16T23:09:24.809301Z",
     "shell.execute_reply.started": "2025-12-16T23:08:51.063899Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"scenario-id\": \"scenario-id-1\",\n",
      "    \"scenario-detail\": \"TechCorp Industries, a multinational technology company with 12,000 employees across 15 countries, recently completed a comprehensive organizational restructuring of their information security governance framework. The Chief Information Security Officer (CISO), Maria Rodriguez, worked collaboratively with the Chief Privacy Officer (CPO), Legal Counsel, and Business Unit CISOs to establish enterprise-wide security policies addressing all regulatory requirements including SOX Section 404, FISMA compliance mandates, and PCI-DSS standards. The organization implemented a three-tier risk assessment framework covering organization-level, business unit-level, and system-level assessments, with the Chief Risk Officer (CRO) overseeing comprehensive risk management strategies across all cloud infrastructure and remote workforce operations. The company established formal supply chain risk management policies with detailed vendor assessment procedures, requiring all critical suppliers to undergo security evaluations and maintain compliance documentation. Their incident response program includes 24/7 monitoring capabilities with designated incident response teams across all geographic regions, supported by automated threat detection systems and regular tabletop exercises. The organization maintains comprehensive audit and accountability frameworks with centralized logging systems capturing all user activities across hybrid cloud environments, with automated compliance reporting to regulatory bodies. Personnel security policies require background investigations for all employees with system access, including contractors and third-party service providers, with regular re-verification procedures. The company implemented enterprise-wide awareness and training programs with role-based security education, covering topics from basic cybersecurity hygiene to advanced threat recognition for executive leadership. Their configuration management processes include automated baseline monitoring, change control procedures with multi-level approval workflows, and continuous compliance validation across all IT assets. Physical and environmental protection controls encompass all data centers and office locations, with biometric access controls, environmental monitoring systems, and comprehensive visitor management procedures. The organization established formal planning policies with integrated security and privacy architectures, supported by enterprise-wide contingency planning covering business continuity and disaster recovery scenarios. System and communications protection measures include network segmentation, encrypted communications protocols, and comprehensive boundary protection mechanisms across all cloud and on-premises infrastructure. Media protection policies govern the entire data lifecycle from creation to destruction, with specialized procedures for handling sensitive financial data and personally identifiable information. The company maintains robust system and information integrity controls including malware protection, vulnerability management programs, and automated patch management systems across all technology platforms. Finally, their program management framework ensures coordination between all business units, with regular executive oversight and continuous monitoring of security posture effectiveness.\",\n",
      "    \"is-compliant\": true,\n",
      "    \"non-compliant-reason\": \"\",\n",
      "    \"judged-compliant\": true,\n",
      "    \"judged-compliant-reason\": \"Based on the comprehensive scenario provided, TechCorp Industries demonstrates substantial alignment with NIST 800-53 control requirements across multiple control families. The organization has established enterprise-level policies covering Assessment, Authorization, and Monitoring (CA), Program Management (PM), Risk Assessment (RA), and System and Information Integrity (SI) controls. Key compliant elements include:\\n\\n- CISO-led development of organization-level security policies addressing purpose, scope, roles, responsibilities, management commitment, and compliance requirements (aligning with CA-1, PM-1, RA-1, and SI-1 policy framework requirements)\\n- Three-tier risk assessment framework with CRO oversight covering organization, business unit, and system levels (consistent with RA-1 requirements)\\n- Comprehensive information security program addressing FISMA, SOX Section 404, and PCI-DSS compliance mandates (aligning with PM-1 requirements)\\n- Coordination among organizational entities including CISO, CPO, Legal Counsel, and Business Unit CISOs (meeting policy coordination requirements)\\n\\nThe scenario describes an organization that has implemented the foundational policy frameworks required by NIST 800-53 controls, with appropriate executive leadership, multi-tier governance structures, regulatory compliance integration, and comprehensive coverage across all major control families.\",\n",
      "    \"llm-judge\": \"global.anthropic.claude-sonnet-4-5-20250929-v1:0\",\n",
      "    \"judged-dtm\": \"2025-12-16T23:08:59.041691\"\n",
      "  },\n",
      "  {\n",
      "    \"scenario-id\": \"scenario-id-2\",\n",
      "    \"scenario-detail\": \"Global Financial Services Corporation, a Fortune 100 financial institution with 25,000 employees operating in 40 countries, has implemented an extensive cybersecurity and privacy governance structure following a major organizational transformation. The company's Chief Information Security Officer (CISO), working in conjunction with the Chief Privacy Officer (CPO) and enterprise risk management team, developed comprehensive organization-level policies addressing access control, audit accountability, and assessment authorization monitoring across all business units and subsidiaries. The institution established sophisticated supply chain risk management protocols requiring thorough evaluation of all technology vendors, financial service providers, and third-party contractors, with mandatory security assessments and ongoing monitoring of supplier compliance with regulatory requirements including Basel III, Dodd-Frank, and international banking regulations. Their personnel security framework encompasses detailed background investigation procedures for all staff members with access to customer financial data, including enhanced screening for positions involving payment processing systems and trading platforms. The organization implemented comprehensive incident response capabilities with specialized teams for different threat scenarios, including cyber attacks on trading systems, data breaches involving customer information, and operational disruptions affecting critical financial services. Risk assessment procedures cover enterprise-wide evaluations of market risk, operational risk, and cybersecurity threats, with quarterly assessments conducted by independent third-party security firms and internal audit teams. The company maintains robust configuration management processes for all trading systems, customer databases, and regulatory reporting platforms, with strict change control procedures requiring multiple approvals and comprehensive testing before implementation. Their awareness and training programs include specialized curricula for different roles, from basic security awareness for all employees to advanced threat hunting techniques for security analysts and compliance training for regulatory reporting staff. Physical and environmental protection measures encompass all trading floors, data centers, and customer service locations, with sophisticated access control systems, environmental monitoring, and comprehensive surveillance capabilities. Planning policies integrate cybersecurity considerations into all business processes, including new product development, merger and acquisition activities, and regulatory compliance initiatives. The institution established comprehensive contingency planning covering various disaster scenarios, from natural disasters affecting physical locations to cyber attacks targeting critical financial infrastructure. System and communications protection includes advanced network security architectures, encrypted communications for all customer transactions, and comprehensive monitoring of all data flows between internal systems and external financial networks. Media protection policies govern the handling of all financial records, customer data, and regulatory documentation throughout their lifecycle, with specialized procedures for secure destruction of sensitive materials. System and information integrity controls include real-time monitoring of all financial transactions, automated fraud detection systems, and comprehensive vulnerability management programs covering all technology platforms. The organization's program management framework ensures coordination between cybersecurity initiatives and business objectives, with regular reporting to the board of directors and regulatory agencies on security posture and compliance status.\",\n",
      "    \"is-compliant\": true,\n",
      "    \"non-compliant-reason\": \"\",\n",
      "    \"judged-compliant\": false,\n",
      "    \"judged-compliant-reason\": \"Based on the comprehensive scenario provided, the organization demonstrates extensive implementation of security and privacy controls across all major control families. The scenario describes a mature cybersecurity and privacy governance structure that aligns with NIST 800-53 requirements, including organization-level policies developed by the CISO and CPO, risk management processes, supply chain risk management, personnel security, incident response capabilities, risk assessments, configuration management, awareness and training programs, physical and environmental protections, planning integration, contingency planning, system and communications protection, media protection, system and information integrity controls, and program management framework with board-level oversight.\\n\\nThe organization's approach follows the guidance that organizations have the responsibility to select appropriate security and privacy controls, implement them correctly, and demonstrate their effectiveness in satisfying security and privacy requirements. The described implementation covers the comprehensive control selection process that can be part of an organization-wide risk management process, addressing mission and business needs, stakeholder protection needs, threats, vulnerabilities, and regulatory compliance requirements. The quarterly assessments by independent third-party security firms and internal audit teams demonstrate the organization's commitment to assessing the effectiveness of controls as recommended in the framework.\",\n",
      "    \"llm-judge\": \"global.anthropic.claude-sonnet-4-5-20250929-v1:0\",\n",
      "    \"judged-dtm\": \"2025-12-16T23:09:06.755955\"\n",
      "  },\n",
      "  {\n",
      "    \"scenario-id\": \"scenario-id-3\",\n",
      "    \"scenario-detail\": \"TechCorp's Chief Information Security Officer (CISO) Sarah Chen initiated a comprehensive enterprise-wide security assessment program following the company's recent acquisition of CloudVault Systems. The assessment covered all 15 business units across their global operations, including their primary data centers in Virginia and California, as well as their emerging IoT manufacturing division in Austin. Sarah worked closely with the Chief Privacy Officer Michael Rodriguez to develop detailed assessment procedures that addressed both security and privacy requirements across their multi-cloud infrastructure spanning AWS, Azure, and Google Cloud Platform. The assessment team, led by Senior Security Architect Jennifer Walsh, conducted thorough evaluations of access control mechanisms, focusing particularly on privileged account management across their hybrid environment. They implemented automated account monitoring systems that tracked usage patterns for over 12,000 employee accounts, including contractors and third-party vendors. The team established clear baseline configurations for all critical systems, ensuring consistent security postures across their diverse technology stack that included legacy mainframe systems, modern containerized applications, and edge computing devices. Risk assessment procedures were standardized across all business units, with quarterly reviews conducted by designated risk managers in each division. The supply chain risk management program was enhanced to address newly acquired vendor relationships from the CloudVault acquisition, implementing comprehensive vendor assessment procedures and continuous monitoring protocols. Configuration management processes were updated to include automated change control mechanisms with mandatory approval workflows for production systems. The incident response team developed new playbooks specifically addressing multi-cloud security incidents, with clear escalation procedures and communication protocols. Physical security controls were evaluated at all facility locations, including the new Austin manufacturing plant, with particular attention to environmental monitoring systems and access control mechanisms. Personnel security procedures were updated to accommodate the integration of CloudVault employees, including new background check requirements and security awareness training programs. Media protection policies were enhanced to address the increased use of removable storage devices in the manufacturing environment. The assessment also covered their expanding remote workforce of over 3,000 employees, ensuring that alternate work site security controls met enterprise standards. System and information integrity monitoring was implemented across all platforms, with centralized logging and real-time threat detection capabilities. The program management office established new governance structures to oversee the integrated security program, with regular reporting to executive leadership and board-level oversight committees.\",\n",
      "    \"is-compliant\": false,\n",
      "    \"non-compliant-reason\": \"The scenario violates the Assessment, Authorization, and Monitoring policy requirement CA-2.a which mandates that control assessments must be conducted by independent assessors or assessment teams with an adequate level of independence. The scenario describes the assessment being conducted by internal personnel (Senior Security Architect Jennifer Walsh and internal assessment teams) without any mention of independent assessors or external validation, which compromises the objectivity and credibility of the assessment results.\",\n",
      "    \"judged-compliant\": false,\n",
      "    \"judged-compliant-reason\": \"Based on the comprehensive security assessment program described, TechCorp's scenario demonstrates substantial compliance with NIST 800-53 Assessment, Authorization, and Monitoring controls and organizational policies. The CISO's development of comprehensive assessment procedures addressing security and privacy requirements across multi-cloud infrastructure aligns with the requirement for standardized assessment procedures using NIST SP 800-53A methodology. The establishment of clear baseline configurations across diverse technology stacks, standardized risk assessment procedures with quarterly reviews, and enhanced supply chain risk management programs all demonstrate adherence to assessment scope requirements and procedure standardization policies. The implementation of automated monitoring systems, centralized logging, real-time threat detection, and governance structures with regular executive reporting satisfy the comprehensive assessment framework requirements that mandate 100% controls mapping to compliance requirements and validated scope accuracy.\",\n",
      "    \"llm-judge\": \"global.anthropic.claude-sonnet-4-5-20250929-v1:0\",\n",
      "    \"judged-dtm\": \"2025-12-16T23:09:14.098136\"\n",
      "  },\n",
      "  {\n",
      "    \"scenario-id\": \"scenario-id-4\",\n",
      "    \"scenario-detail\": \"Global Financial Services Inc. embarked on a major digital transformation initiative led by Chief Technology Officer David Kim and Chief Information Security Officer Maria Santos. The initiative involved migrating their core banking systems from on-premises infrastructure to a hybrid cloud environment while maintaining compliance with SOX, PCI-DSS, and FISMA requirements. The project encompassed 22 regional offices across North America and Europe, serving over 2.5 million customers with assets exceeding $50 billion. The security team, headed by Senior Security Manager Robert Chen, developed comprehensive policies addressing all aspects of the transformation. Access control mechanisms were redesigned to support federated identity management across multiple cloud providers, implementing role-based access controls with fine-grained permissions for over 8,500 employees and contractors. The awareness and training program was expanded to include specialized modules for cloud security, with mandatory quarterly training sessions for all IT personnel and annual security awareness training for all employees. Audit and accountability measures were enhanced with centralized log management systems capable of processing over 10 terabytes of log data daily from across their distributed infrastructure. The assessment and authorization program established continuous monitoring capabilities with automated compliance reporting to regulatory bodies. Configuration management processes were updated to support infrastructure-as-code deployments with automated baseline verification and drift detection. Contingency planning procedures were redesigned to address multi-region failover scenarios, including detailed recovery procedures for critical banking applications. Identity and authentication systems were upgraded to support multi-factor authentication for all user accounts, with biometric authentication for high-privilege users. Incident response capabilities were enhanced with 24/7 security operations center monitoring and automated threat response systems. Maintenance procedures for cloud infrastructure included scheduled patching windows and emergency change procedures for critical security updates. Media protection policies addressed the secure disposal of legacy hardware and the encryption of data in transit and at rest. Physical and environmental protection measures were implemented at co-location facilities and cloud provider data centers through contractual agreements. Planning processes included detailed security and privacy plans for each system component, with regular updates reflecting changes in the threat landscape. Personnel security procedures were updated to include cloud-specific background check requirements and specialized role definitions. Risk assessment procedures incorporated cloud-specific threats and vulnerabilities, with quarterly assessments conducted by certified risk professionals. The system acquisition process included enhanced vendor security assessments and contractual security requirements for cloud service providers. System and communications protection measures included network segmentation, intrusion detection systems, and encrypted communications channels. System integrity monitoring was implemented with file integrity monitoring, malware detection, and vulnerability scanning across all platforms. Supply chain risk management procedures addressed the security of cloud service providers and third-party integrations.\",\n",
      "    \"is-compliant\": false,\n",
      "    \"non-compliant-reason\": \"The scenario violates the Personnel Security policy PS-3.a which requires personnel screening procedures to be completed before granting access to the system. The scenario mentions updating personnel security procedures to include 'cloud-specific background check requirements' as part of the transformation initiative, but does not indicate that proper screening was completed before personnel were granted access to the new cloud systems during the migration process. This suggests that employees may have been given access to cloud systems before completing the required screening procedures.\",\n",
      "    \"judged-compliant\": false,\n",
      "    \"judged-compliant-reason\": \"Based on the scenario provided, I cannot make a definitive compliance determination because the description lacks sufficient technical detail and evidence to verify implementation against specific NIST 800-53 control requirements. While Global Financial Services Inc. describes having implemented comprehensive security measures across all control families (AC, AT, AU, CA, CM, CP, IA, IR, MA, MP, PE, PL, PM, PS, RA, SA, SC, SI, SR), the scenario provides only high-level statements about security capabilities without demonstrating actual implementation specifics, documented procedures, or measurable outcomes that would be required for compliance verification.\\n\\nFor a large technology organization with 10,000+ employees subject to SOX, FISMA, and PCI-DSS requirements, NIST 800-53 controls require specific documented policies, procedures, and implementation evidence. The scenario mentions elements like \\\"role-based access controls,\\\" \\\"multi-factor authentication,\\\" \\\"continuous monitoring,\\\" and \\\"centralized log management,\\\" but does not provide the detailed policy statements, implementation parameters, or verification mechanisms that would be necessary to assess compliance against specific control requirements such as those outlined in the Risk Assessment, Program Management, and System Integrity control families.\\n\\nWithout access to actual documented policies, implementation specifications, assessment results, and evidence of continuous monitoring effectiveness, I cannot verify whether the organization meets the rigorous security and privacy planning, system development lifecycle management, security engineering principles, documented security practices, and continuous monitoring requirements that NIST 800-53 mandates for federal information systems and organizations managing cybersecurity risk.\",\n",
      "    \"llm-judge\": \"global.anthropic.claude-sonnet-4-5-20250929-v1:0\",\n",
      "    \"judged-dtm\": \"2025-12-16T23:09:24.079634\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "source_scenarios_file = \"scenarios.json\"\n",
    "judged_scenarios_file = \"judged_scenarios.json\"\n",
    "\n",
    "source_scenarios = load_scenarios_from_s3(INPUT_BUCKET, INPUT_PREFIX, source_scenarios_file)\n",
    "\n",
    "judged_scenarios = judge_scenarios(\n",
    "    source_scenarios,\n",
    "    MODEL_ARN,\n",
    "    KNOWLEDGE_BASE_ID\n",
    ")\n",
    "save_scenarios_to_file(judged_scenarios, '/home/sagemaker-user/' + judged_scenarios_file)\n",
    "save_scenarios_to_s3(judged_scenarios, OUTPUT_BUCKET, OUTPUT_PREFIX, judged_scenarios_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8baa7d-6aac-4d74-b46f-8eee6c4e270e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

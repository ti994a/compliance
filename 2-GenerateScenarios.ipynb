{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c22ff17-b692-4612-b2ce-785abdec9713",
   "metadata": {},
   "source": [
    "# GenerateScenarios\n",
    "This notebook generates realistic compliance scenarios by leveraging AWS Bedrock's Retrieval-Augmented Generation (RAG) capabilities using the NIST control framework and specific organizational policies generated against that framework. It generates 1,000 (500 compliant, 500 non-compliant) complex, multi-policy scenarios that simulate real-world compliance situations (like employee onboarding, data access requests, or security incidents).\n",
    "\n",
    " - Generates Scenario Batches - Uses Bedrock's Converse API with RAG to create realistic compliance scenarios by alternating between compliant and non-compliant cases.  For each batch of scenarios, it retrieves policy context by querying AWS Bedrock Knowledge Base containing NIST controls and policies.\n",
    " - Structures Output - Forces JSON format output with specific schema including scenario ID, detailed description, compliance status, and violation reasons.\n",
    " - Multi-Policy Coverage - Each scenario incorporates multiple policies to create complex, realistic compliance evaluation situations.\n",
    "\n",
    "```\n",
    "Execution Flow:\n",
    "└── main()\n",
    "    ├── generate_compliance_scenarios()\n",
    "    │   ├── retrieve_kb_context()\n",
    "    │   │   └── bedrock_agent_runtime.retrieve()\n",
    "    │   └── generate_scenario_batch()\n",
    "    │       └── bedrock_runtime.converse()\n",
    "    ├── save_scenarios_to_file()\n",
    "    └── save_scenarios_to_s3()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "execution_state": "idle",
   "id": "6b008304-8133-4539-b75f-b66534b07807",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T22:33:43.663429Z",
     "iopub.status.busy": "2026-01-08T22:33:43.662999Z",
     "iopub.status.idle": "2026-01-08T22:33:43.713823Z",
     "shell.execute_reply": "2026-01-08T22:33:43.706681Z",
     "shell.execute_reply.started": "2026-01-08T22:33:43.663393Z"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "from typing import List, Dict\n",
    "\n",
    "BUCKET = '183023889407-us-east-1-compliance-rule-generator'\n",
    "S3_PREFIX_POLICY_MARKDOWN_ALL = 'policies/markdown/all-policies-main/'\n",
    "OUTPUT_PREFIX = 'scenarios/'  # Folder path for results\n",
    "KNOWLEDGE_BASE_ID = 'T8EW10IU3Z'  # AWS Bedrock Knowledge Base containing NIST policies\n",
    "# Available Bedrock model ARNs with performance notes\n",
    "MODELS = {\n",
    "    'premium': 'arn:aws:bedrock:us-east-1:183023889407:inference-profile/global.anthropic.claude-opus-4-5-20251101-v1:0', # not available\n",
    "    'good': 'arn:aws:bedrock:us-east-1:183023889407:inference-profile/global.anthropic.claude-sonnet-4-5-20250929-v1:0', # times out\n",
    "    'balanced': 'arn:aws:bedrock:us-east-1:183023889407:inference-profile/us.anthropic.claude-sonnet-4-20250514-v1:0',  # recommended\n",
    "    'fast_cheap': 'arn:aws:bedrock:us-east-1:183023889407:inference-profile/us.anthropic.claude-haiku-4-5-20251001-v1:0',\n",
    "    'aws_native_premier': 'arn:aws:bedrock:us-east-1:183023889407:inference-profile/us.amazon.nova-premier-v1:0',\n",
    "    'aws_native_pro': 'arn:aws:bedrock:us-east-1:183023889407:inference-profile/us.amazon.nova-pro-v1:0'\n",
    "}\n",
    "MODEL_ARN = MODELS['good']  # Default model selection\n",
    "SCENARIOS_PER_BATCH = 2\n",
    "TOTAL_SCENARIOS = SCENARIOS_PER_BATCH * 8\n",
    "POLICIES_PER_SCENARIO = 4\n",
    "\n",
    "# JSON tool configuration for Bedrock Converse API\n",
    "# Forces the model to return structured JSON with specific schema\n",
    "TOOL_CONFIG = {\n",
    "    \"tools\": [{\n",
    "        \"toolSpec\": {\n",
    "            \"name\": \"scenario_json\",\n",
    "            \"description\": \"Return compliance scenarios as JSON\",\n",
    "            \"inputSchema\": {\n",
    "                \"json\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"scenarios\": {  # Array of scenario objects\n",
    "                            \"type\": \"array\",\n",
    "                            \"items\": {\n",
    "                                \"type\": \"object\",\n",
    "                                \"properties\": {\n",
    "                                    \"scenario-id\": {\"type\": \"string\"},      # Format: scenario-id-1, scenario-id-2, etc.\n",
    "                                    \"scenario-detail\": {\"type\": \"string\"},  # Detailed scenario description (200+ words)\n",
    "                                    \"is-compliant\": {\"type\": \"boolean\"},     # True if compliant, False if non-compliant\n",
    "                                    \"non-compliant-reason\": {\"type\": \"string\"}  # If non-compliant, why? Which policy(s) were violated?\n",
    "                                },\n",
    "                                \"required\": [\"scenario-id\", \"scenario-detail\", \"is-compliant\"]\n",
    "                            }\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"scenarios\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }],\n",
    "    \"toolChoice\": {\"tool\": {\"name\": \"scenario_json\"}}  # Force use of the JSON tool\n",
    "}\n",
    "\n",
    "# Initialize AWS Bedrock clients\n",
    "bedrock_agent_runtime = boto3.client('bedrock-agent-runtime', region_name='us-east-1')  # For knowledge base retrieval\n",
    "bedrock_runtime = boto3.client('bedrock-runtime', region_name='us-east-1')  # For model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6bdc29ec-8ace-4cca-abb9-0139668e1bb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T22:11:00.705497Z",
     "iopub.status.busy": "2026-01-08T22:11:00.705113Z",
     "iopub.status.idle": "2026-01-08T22:11:00.714738Z",
     "shell.execute_reply": "2026-01-08T22:11:00.713603Z",
     "shell.execute_reply.started": "2026-01-08T22:11:00.705460Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_scenario_batch(\n",
    "    context: str,\n",
    "    batch_num: int,\n",
    "    model_arn: str,\n",
    "    scenarios_per_batch: int=SCENARIOS_PER_BATCH,\n",
    "    policies_per_scenario: int=POLICIES_PER_SCENARIO\n",
    ") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Generate one batch of compliance scenarios using Bedrock Converse API.\n",
    "    This function creates realistic compliance scenarios by alternating between\n",
    "    compliant and non-compliant scenarios across batches. Uses the JSON tool\n",
    "    to ensure structured output.\n",
    "    Args:\n",
    "        context: Combined policy text from knowledge base\n",
    "        batch_num: Current batch number (0-indexed)\n",
    "        model_arn: AWS Bedrock model ARN or ID\n",
    "        scenarios_per_batch: Number of scenarios per batch\n",
    "        policies_per_scenario: Number of NIST policies to use in creating a scenario\n",
    "    Returns:\n",
    "        List of scenario dictionaries with keys: scenario-id, scenario-detail, is-compliant, non-compliant-reason\n",
    "    \"\"\"\n",
    "    # Alternate between compliant (even batches) and non-compliant (odd batches) scenarios\n",
    "    is_compliant = batch_num % 2 == 0\n",
    "    \n",
    "    # Calculate starting ID for consecutive numbering across all batches\n",
    "    start_id = batch_num * scenarios_per_batch + 1\n",
    "    \n",
    "    # Construct detailed prompt with all policy context and specific requirements\n",
    "    prompt = f\"\"\"Based on compliance policies and NIST controls under **KNOWLEDGE BASE CONTEXT**, generate {scenarios_per_batch} realistic compliance scenario (scenario-details) \n",
    "    that are {'compliant' if is_compliant else 'non-compliant.  Ensure that only one underlying policy is violated out of all the underlying policies for each scenario.  Use no leading language like \"however\" or tone to indicate in any way that the scenarios is in any way invalid.  Try to trick the reader to believe it is valid.'}.\n",
    "    \n",
    "    Each scenario-detail must:\n",
    "    - Use {policies_per_scenario} different, random policies from the context above\n",
    "    - Include specific business details (roles, systems, data, actions)\n",
    "    - Be realistic and detailed (200+ words)\n",
    "    - List each specific source policy that was used \n",
    "    - Have scenario-id format: scenario-id-{start_id}, scenario-id-{start_id+1}, etc.\n",
    "    - End with a list of all policies used to contstruct the scenario\n",
    "\n",
    "    **Avoid generating scenarios based on cost-benefit principles or concentration percentages.\n",
    "    \n",
    "    **Note that non-US citizens cannot obtain US security clearances.**\n",
    "    \n",
    "    Return as JSON array with fields: scenario-id, scenario-detail, is-compliant, non-compliant-reason\n",
    "    {'leave non-compliant-reason empty' if is_compliant else 'For non-compliant-reason, provide an explanation of exactly why the scenario is non-compliant, including which policy(s) were violated.'}\n",
    "\n",
    "    **Here is an example of scenario-detail:**\n",
    "    SecureDefense Corporation, a defense contractor with 8,500+ employees supporting classified government projects, is deploying a new secure development environment\n",
    "    for processing TOP SECRET/SCI information across 12 secure facilities. The Chief Security Officer implemented citizenship requirements per MA-5.3 ensuring all\n",
    "    personnel performing maintenance on classified systems are verified U.S. citizens with current documentation including birth certificates, passports, and security\n",
    "    clearance validation, with emergency maintenance procedures explicitly prohibiting non-citizen access under any circumstances. The organization deployed NIAP-approved\n",
    "    protection profiles per SA-4.7 for all commercial security products including firewalls evaluated against Network Device Protection Profile v2.2, VPN solutions meeting\n",
    "    IPsec Virtual Private Network (VPN) Client Protection Profile v1.0, and database management systems validated against Database Management System Protection Profile v4.0,\n",
    "    with FIPS 140-2 Level 3 validated cryptographic modules for products without applicable NIAP profiles. The system architecture team implemented hierarchical protection\n",
    "    per SA-8.12 with hypervisor components at highest trust level protecting against guest VMs, classified application containers at medium trust level isolated from\n",
    "    development tools, and development interfaces at lowest trust level with comprehensive access controls preventing privilege escalation across trust boundaries. The\n",
    "    procurement team maintained technology diversity per SC-29 across the secure development pipeline using Red Hat and SUSE Linux distributions (45% and 35% respectively),\n",
    "    Dell and HPE hardware platforms, and Raytheon and General Dynamics security appliances to minimize supply chain concentration risks. Cost-benefit analyses per SA-8.25\n",
    "    documented security investments of $4.2M annually justified by protecting classified intellectual property valued at $2.8B and avoiding potential contract termination\n",
    "    penalties exceeding $150M for security violations.\n",
    "    \\n\\nPolicies referenced: policy_MA-5.3, policy_SA-4.7, policy_SA-8.12, policy_SC-29, policy_SA-8.25\n",
    "\n",
    "    **KNOWLEDGE BASE CONTEXT**\n",
    "    {context}\n",
    "    \"\"\"\n",
    "    # print(prompt)\n",
    "    # Extract model ID from ARN (Converse API requires model ID, not full ARN)\n",
    "    model_id = model_arn.split('/')[-1] if '/' in model_arn else model_arn\n",
    "    \n",
    "    # Call Bedrock Converse API with JSON tool enforcement\n",
    "    response = bedrock_runtime.converse(\n",
    "        modelId=model_id,\n",
    "        messages=[{\"role\": \"user\", \"content\": [{\"text\": prompt}]}],\n",
    "        toolConfig=TOOL_CONFIG,  # Forces structured JSON output\n",
    "        inferenceConfig={\"maxTokens\": 4096, \"temperature\": 0.7}  # Allow creative but controlled generation, about 3,000 words max\n",
    "    )\n",
    "    \n",
    "    # Extract scenarios from tool use response\n",
    "    if response.get('stopReason') == 'tool_use':\n",
    "        for content_block in response['output']['message']['content']:\n",
    "            if 'toolUse' in content_block:\n",
    "                scenarios_data = content_block['toolUse']['input']\n",
    "                return scenarios_data.get('scenarios', [])\n",
    "    \n",
    "    # Return empty list if no tool use or scenarios found\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "execution_state": "idle",
   "id": "f5d404f5-1b3a-4e76-922f-9a82585c2a39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T21:49:26.249414Z",
     "iopub.status.busy": "2026-01-08T21:49:26.248773Z",
     "iopub.status.idle": "2026-01-08T21:49:26.257992Z",
     "shell.execute_reply": "2026-01-08T21:49:26.256195Z",
     "shell.execute_reply.started": "2026-01-08T21:49:26.249338Z"
    }
   },
   "outputs": [],
   "source": [
    "def retrieve_kb_context(knowledge_base_id: str, \n",
    "    scenarios_per_batch: int=SCENARIOS_PER_BATCH,\n",
    "    policies_per_scenario: int=POLICIES_PER_SCENARIO\n",
    "    ) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve comprehensive policy context from AWS Bedrock Knowledge Base.\n",
    "    This function queries the knowledge base for muliple policies that are used\n",
    "    to generate a batch of scenarios.\n",
    "    Args:\n",
    "        knowledge_base_id: AWS Bedrock Knowledge Base ID containing NIST policies\n",
    "        scenarios_per_batch: Number of scenarios per batch\n",
    "        policies_per_scenario: Number of NIST policies to use in creating a scenario\n",
    "    Returns:\n",
    "        Combined text of all retrieved policy documents, separated by double newlines\n",
    "    \"\"\"\n",
    "\n",
    "    num_results = scenarios_per_batch * policies_per_scenario\n",
    "    # Request more results to account for potential duplicates being returned from kb\n",
    "    # We'll dedupe them below\n",
    "    request_count = max(num_results * 4, 20)  # Request 4x or minimum 20\n",
    "    \n",
    "    kb_query = f\"\"\"Policies covering different families:\n",
    "    AC, AT, AU, CA, CM, CP, IA, IR, MA, MP, PE, PL, PM, PS, PT, RA, SA, SC, SI, SR.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Query the knowledge base using vector search\n",
    "    kb_response = bedrock_agent_runtime.retrieve(\n",
    "        knowledgeBaseId=knowledge_base_id,\n",
    "        retrievalQuery={'text': kb_query},\n",
    "        retrievalConfiguration={'vectorSearchConfiguration': {'numberOfResults': request_count}}\n",
    "    )\n",
    "\n",
    "     # Deduplicate and limit results\n",
    "    unique_contexts = []\n",
    "    seen_hashes = set()\n",
    "    \n",
    "    for result in kb_response.get('retrievalResults', []):\n",
    "        content = result['content']['text']\n",
    "        content_hash = hash(content[:200])\n",
    "        \n",
    "        if content_hash not in seen_hashes:\n",
    "            seen_hashes.add(content_hash)\n",
    "            unique_contexts.append(content)\n",
    "            \n",
    "        if len(unique_contexts) >= num_results:\n",
    "            break\n",
    "    \n",
    "    print(f\"Retrieved {len(unique_contexts)} unique policies from {len(kb_response.get('retrievalResults', []))} total results\")\n",
    "    return '\\n\\n'.join(unique_contexts)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "execution_state": "idle",
   "id": "57b41f28-b131-413b-be13-370ed0246637",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T22:33:56.071020Z",
     "iopub.status.busy": "2026-01-08T22:33:56.070707Z",
     "iopub.status.idle": "2026-01-08T22:33:56.079711Z",
     "shell.execute_reply": "2026-01-08T22:33:56.077543Z",
     "shell.execute_reply.started": "2026-01-08T22:33:56.070998Z"
    }
   },
   "outputs": [],
   "source": [
    "def retrieve_s3_policies(bucket: str = BUCKET,\n",
    "    scenarios_per_batch: int = SCENARIOS_PER_BATCH,\n",
    "    policies_per_scenario: int = POLICIES_PER_SCENARIO\n",
    "    ) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve random policy documents from S3 bucket.\n",
    "    \"\"\"\n",
    "    s3 = boto3.client('s3')\n",
    "    \n",
    "    # List all policy files\n",
    "    response = s3.list_objects_v2(\n",
    "        Bucket=bucket,\n",
    "        Prefix=S3_PREFIX_POLICY_MARKDOWN_ALL\n",
    "    )\n",
    "    \n",
    "    policy_files = [obj['Key'] for obj in response.get('Contents', []) \n",
    "                   if obj['Key'].endswith('.md')]\n",
    "    \n",
    "    # Randomly select needed number of policies\n",
    "    num_needed = scenarios_per_batch * policies_per_scenario\n",
    "    selected_files = random.sample(policy_files, min(num_needed, len(policy_files)))\n",
    "    \n",
    "    # Read selected policy contents\n",
    "    policies = []\n",
    "    for file_key in selected_files:\n",
    "        obj = s3.get_object(Bucket=bucket, Key=file_key)\n",
    "        content = obj['Body'].read().decode('utf-8')\n",
    "        # Extract filename without extension as policy ID\n",
    "        policy_id = file_key.split('/')[-1].replace('.md', '')\n",
    "        # Add policy ID header to content\n",
    "        policy_with_id = f\"POLICY ID: {policy_id}\\n\\n{content}\"\n",
    "        policies.append(policy_with_id)\n",
    "            \n",
    "    print(f\"Retrieved {len(policies)} random policies from S3\")\n",
    "    return '\\n\\n'.join(policies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "execution_state": "idle",
   "id": "11aec7fa-498b-436f-8b4e-30961c28bc88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T22:33:31.500792Z",
     "iopub.status.busy": "2026-01-08T22:33:31.499656Z",
     "iopub.status.idle": "2026-01-08T22:33:31.510320Z",
     "shell.execute_reply": "2026-01-08T22:33:31.508940Z",
     "shell.execute_reply.started": "2026-01-08T22:33:31.500756Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_compliance_scenarios(\n",
    "    knowledge_base_id: str = KNOWLEDGE_BASE_ID,\n",
    "    model_arn: str = MODEL_ARN,\n",
    "    scenarios_per_batch: int=SCENARIOS_PER_BATCH,\n",
    "    policies_per_scenario: int=POLICIES_PER_SCENARIO,\n",
    "    total_scenarios: int = TOTAL_SCENARIOS\n",
    ") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Main orchestrator function for generating compliance scenarios.\n",
    "    \n",
    "    This function coordinates the entire scenario generation process:\n",
    "    1. Retrieves comprehensive policy context from knowledge base (once)\n",
    "    2. Generates scenarios in batches to manage API limits and costs\n",
    "    3. Alternates between compliant and non-compliant scenarios\n",
    "    4. Implements rate limiting to avoid API throttling\n",
    "    Args:\n",
    "        knowledge_base_id: AWS Bedrock Knowledge Base ID\n",
    "        model_arn: AWS Bedrock model ARN to use for generation\n",
    "        scenarios_per_batch: Number of scenarios per batch\n",
    "        policies_per_scenario: Number of NIST policies to use in creating a scenario\n",
    "        total_scenarios: Total number of scenarios to generate\n",
    "    Returns:\n",
    "        List of all generated scenario dictionaries\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate scenarios in batches\n",
    "    all_scenarios = []\n",
    "    for batch_num in range(total_scenarios // scenarios_per_batch):\n",
    "      # Retrieve all policy context once (reused across all batches)\n",
    "        try:\n",
    "            # context = retrieve_kb_context(knowledge_base_id, scenarios_per_batch, policies_per_scenario)\n",
    "            context = retrieve_s3_policies(BUCKET, scenarios_per_batch, policies_per_scenario)\n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving from KB: {e}\")\n",
    "            return []\n",
    "        try:\n",
    "            # Generate one batch of scenarios          \n",
    "            scenarios = generate_scenario_batch(context, batch_num, model_arn, scenarios_per_batch, policies_per_scenario)\n",
    "            all_scenarios.extend(scenarios)\n",
    "            print(f\"Batch {batch_num + 1}: Generated {len(scenarios)} scenarios\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating scenario batch {batch_num + 1}: {e}\")\n",
    "            continue  # excplicit to go to next scenario, maybe this was a temporary glitch\n",
    "        \n",
    "        # Rate limiting: pause between batches to avoid API throttling\n",
    "        time.sleep(2)\n",
    "    \n",
    "    return all_scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "execution_state": "idle",
   "id": "8712a78b-70a0-4f46-9fbc-0b8b6e5a16cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T22:11:02.738928Z",
     "iopub.status.busy": "2026-01-08T22:11:02.738198Z",
     "iopub.status.idle": "2026-01-08T22:11:02.743742Z",
     "shell.execute_reply": "2026-01-08T22:11:02.742808Z",
     "shell.execute_reply.started": "2026-01-08T22:11:02.738894Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_scenarios_to_file(scenarios: List[Dict], output_path: str):\n",
    "    \"\"\"\n",
    "    Save generated scenarios to a JSON file with metadata.\n",
    "    \n",
    "    Creates a structured JSON file containing:\n",
    "    - Summary statistics (total, compliant, non-compliant counts)\n",
    "    - All generated scenarios\n",
    "    \"\"\"\n",
    "    # Print scenarios to console for immediate review\n",
    "    print(json.dumps(scenarios, indent=2))\n",
    "    \n",
    "    # Save to file with metadata and statistics\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump({\n",
    "            'total_scenarios': len(scenarios),\n",
    "            'compliant_count': sum(1 for s in scenarios if s['is-compliant']),\n",
    "            'non_compliant_count': sum(1 for s in scenarios if not s['is-compliant']),\n",
    "            'scenarios': scenarios\n",
    "        }, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "execution_state": "idle",
   "id": "2149410b-8800-4e63-83f1-9b9cda20743c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T22:11:03.629891Z",
     "iopub.status.busy": "2026-01-08T22:11:03.629619Z",
     "iopub.status.idle": "2026-01-08T22:11:03.635088Z",
     "shell.execute_reply": "2026-01-08T22:11:03.633697Z",
     "shell.execute_reply.started": "2026-01-08T22:11:03.629869Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_scenarios_to_s3(scenarios: List[Dict], output_bucket: str = BUCKET, output_prefix: str = OUTPUT_PREFIX, object_name: str = \"scenarios.json\"):\n",
    "    \"\"\"\n",
    "    Save generated scenarios to a S3.\n",
    "\n",
    "    \"\"\"\n",
    "    s3 = boto3.client('s3')\n",
    "    json_data = json.dumps({\"scenarios\": scenarios}, indent=2)\n",
    "    s3.put_object(Bucket=output_bucket, Key=output_prefix+object_name, Body=json_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "execution_state": "idle",
   "id": "034d84a6-9c5f-446e-a1ce-5912d269b599",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T22:34:04.154443Z",
     "iopub.status.busy": "2026-01-08T22:34:04.154143Z",
     "iopub.status.idle": "2026-01-08T22:34:04.169983Z",
     "shell.execute_reply": "2026-01-08T22:34:04.165678Z",
     "shell.execute_reply.started": "2026-01-08T22:34:04.154417Z"
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Example usage: Generate 4 scenarios in 2 batches of 2 each\n",
    "    # Batch 0 (even): compliant scenarios with IDs scenario-id-1, scenario-id-2\n",
    "    # Batch 1 (odd): non-compliant scenarios with IDs scenario-id-3, scenario-id-4\n",
    "    scenarios = generate_compliance_scenarios(\n",
    "        knowledge_base_id=KNOWLEDGE_BASE_ID,\n",
    "        model_arn=MODELS['balanced'],\n",
    "        scenarios_per_batch=SCENARIOS_PER_BATCH,\n",
    "        policies_per_scenario=POLICIES_PER_SCENARIO,\n",
    "        total_scenarios=TOTAL_SCENARIOS \n",
    "    )\n",
    "\n",
    "    save_scenarios_to_file(scenarios, '/home/sagemaker-user/scenarios.json')\n",
    "    save_scenarios_to_s3(scenarios, BUCKET, OUTPUT_PREFIX, \"scenarios.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "execution_state": "idle",
   "id": "a3c8d612-ad8e-4bc2-b653-ac967d5e712e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T22:34:04.844127Z",
     "iopub.status.busy": "2026-01-08T22:34:04.843763Z",
     "iopub.status.idle": "2026-01-08T22:37:51.866351Z",
     "shell.execute_reply": "2026-01-08T22:37:51.863327Z",
     "shell.execute_reply.started": "2026-01-08T22:34:04.844078Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 8 random policies from S3\n",
      "Batch 1: Generated 2 scenarios\n",
      "Retrieved 8 random policies from S3\n",
      "Batch 2: Generated 2 scenarios\n",
      "Retrieved 8 random policies from S3\n",
      "Batch 3: Generated 2 scenarios\n",
      "Retrieved 8 random policies from S3\n",
      "Batch 4: Generated 2 scenarios\n",
      "Retrieved 8 random policies from S3\n",
      "Batch 5: Generated 2 scenarios\n",
      "Retrieved 8 random policies from S3\n",
      "Batch 6: Generated 2 scenarios\n",
      "Retrieved 8 random policies from S3\n",
      "Batch 7: Generated 2 scenarios\n",
      "Retrieved 8 random policies from S3\n",
      "Batch 8: Generated 2 scenarios\n",
      "[\n",
      "  {\n",
      "    \"scenario-id\": \"scenario-id-1\",\n",
      "    \"scenario-detail\": \"CyberDefense Systems Inc., a federal contractor with 3,200 employees supporting classified defense programs, is implementing a comprehensive secure communications infrastructure for processing SECRET and TOP SECRET information across 8 geographically distributed facilities. The IT Infrastructure Manager established primary Network Time Protocol (NTP) services through NIST Boulder, Colorado (40.0150\\u00b0 N, 105.2705\\u00b0 W) and secondary authoritative time sources through the U.S. Naval Observatory in Washington, D.C. (38.9213\\u00b0 N, 77.0669\\u00b0 W), achieving 1,247 miles of geographic separation per SC-45.2 requirements with automated failover capabilities triggering within 3 minutes when primary sources become unavailable and continuous monitoring generating alerts for time drift exceeding 500 milliseconds on security-critical systems. The Chief Information Security Officer implemented dedicated privileged access management (PAM) systems per SC-7.15 requiring all network administrators to route database administrative access, security appliance configuration, and cloud infrastructure management through hardened jump servers with multi-factor authentication, session recording, and 2-hour timeout limits for standard operations and 45-minute limits for TOP SECRET systems, with emergency bypass procedures documented and approved within 4 hours for critical security incidents. The organization deployed comprehensive software signing validation per CM-14 using DoD-approved Certificate Authorities including the DoD Root CA 3 and DoD Root CA 5, with automated signature verification blocking installation of unsigned software on all production systems, quarterly updates to approved certificate lists, and CISO emergency bypass authorization limited to 48 hours for critical security patches with mandatory permanent approval within 72 hours. The procurement team established telecommunications redundancy per CP-8.3 contracting with Verizon as primary provider and AT&T as alternate provider, verified through infrastructure assessments showing less than 15% shared fiber infrastructure, geographic separation exceeding 75 miles between provider facilities, and annual threat susceptibility analyses documenting independent routing paths and facility ownership to minimize common failure modes during natural disasters or targeted attacks.\\n\\nPolicies referenced: policy_SC-45.2, policy_SC-7.15, policy_CM-14, policy_CP-8.3\",\n",
      "    \"is-compliant\": true,\n",
      "    \"non-compliant-reason\": \"\"\n",
      "  },\n",
      "  {\n",
      "    \"scenario-id\": \"scenario-id-2\",\n",
      "    \"scenario-detail\": \"SecureTech Innovations, a technology services company with 1,850 employees providing cloud infrastructure and managed security services to government agencies, is deploying a next-generation secure development and operations platform supporting multiple classification levels across 5 regional data centers. The Business Continuity Manager implemented comprehensive system restoration capabilities per CP-10.4 with Recovery Time Objectives (RTO) of 2 hours for mission-critical systems and 6 hours for standard business systems, maintaining configuration-controlled restoration images protected with SHA-256 cryptographic hashing and stored in geographically separated facilities with quarterly restoration testing validating operational state achievement within defined timeframes and automatic image updates within 20 days of approved configuration changes. The organization established rigorous software licensing compliance per CM-10 through automated software inventory systems scanning all 2,400 endpoints monthly, tracking quantity-licensed software including Microsoft Office 365 (1,200 licenses), Adobe Creative Suite (300 licenses), and VMware vSphere (150 licenses), with peer-to-peer file sharing applications blocked on corporate networks except for approved business file sharing services like SharePoint and OneDrive with documented usage monitoring and legal compliance validation. The Data Flow Review Board implemented human review processes per AC-4.9 for all cross-domain data transfers involving personally identifiable information (PII) or classified data, with designated reviewers holding appropriate security clearances conducting reviews within 2 hours for high-sensitivity flows and 3 hours for standard flows, documenting decisions with reviewer identity, timestamp, and detailed rationale for approval or denial with escalation procedures for complex cases requiring additional subject matter expert consultation. The Network Security Team deployed advanced system concealment techniques per SC-30(5) using network address translation to hide internal infrastructure topology from external reconnaissance, implementing virtualization to conceal physical locations of critical database servers and security appliances, employing encryption tunneling for all sensitive data communications, and conducting quarterly effectiveness assessments to validate concealment measures against simulated adversary targeting and reconnaissance activities.\\n\\nPolicies referenced: policy_CP-10.4, policy_CM-10, policy_AC-4.9, policy_SC-30-5\",\n",
      "    \"is-compliant\": true,\n",
      "    \"non-compliant-reason\": \"\"\n",
      "  },\n",
      "  {\n",
      "    \"scenario-id\": \"scenario-id-3\",\n",
      "    \"scenario-detail\": \"GlobalTech Financial Services, a multinational banking corporation with 15,000+ employees across 45 countries, is implementing a comprehensive data protection framework for processing customer PII across their global operations. The Chief Privacy Officer established strict requirements per SI-19.7 ensuring all de-identification processes use validated algorithms including k-anonymity with k=5 for transaction data, differential privacy with epsilon=0.1 for behavioral analytics, and suppression techniques for direct identifiers, with all algorithms independently validated through NIST certification processes and documented peer review publications in IEEE Transactions on Information Forensics and Security. The organization deployed comprehensive system monitoring per SI-4 across all production environments including real-time intrusion detection systems monitoring 2,847 critical servers, network traffic analysis covering 156 network segments, and behavioral analytics tracking user activities across 23 data centers, with security events analyzed within 2 hours for critical systems and 12 hours for standard systems by the 24/7 Security Operations Center. The infrastructure team implemented robust physical security per PE-9.1 with redundant power cabling systems maintaining 15-foot separation distances between primary and secondary power paths through dedicated conduit systems, serving all critical infrastructure including mainframe systems, network core equipment, and backup generators across their primary data center facility in New York. The security architecture team established comprehensive usage restrictions per SC-43 for all system components including mobile devices requiring MDM enrollment and certificate-based authentication, wireless access points configured with WPA3-Enterprise and 802.1X authentication, peripheral devices restricted to approved models with endpoint protection agents, and cloud services limited to FedRAMP-authorized providers with continuous security monitoring and quarterly compliance assessments. However, the organization's critical asset identification process per CP-2.8 has documented all technical infrastructure components including servers, network devices, and applications, but has not completed the identification and documentation of operational aspects such as key personnel roles, critical procedures, and specialized knowledge required for business continuity during emergency scenarios.\",\n",
      "    \"is-compliant\": false,\n",
      "    \"non-compliant-reason\": \"The scenario violates CP-2.8 RULE-02 which requires that critical asset identification MUST include both technical aspects AND operational aspects. While the organization has properly identified technical assets (system components, IT services, IT products, mechanisms), they have failed to identify operational aspects (procedures, personnel) as required by the policy. This creates an incomplete critical asset inventory that cannot support effective contingency planning.\"\n",
      "  },\n",
      "  {\n",
      "    \"scenario-id\": \"scenario-id-4\",\n",
      "    \"scenario-detail\": \"CyberShield Defense Corporation, a leading cybersecurity firm with 6,200+ employees providing managed security services to Fortune 500 clients, is deploying an advanced threat detection platform across their global security operations centers. The Security Operations team implemented comprehensive system monitoring per SI-4 with continuous monitoring capabilities deployed across 3,400+ client systems including advanced persistent threat detection, behavioral analytics engines, and machine learning-based anomaly detection systems providing real-time threat identification and automated incident response coordination with analysis of critical security events completed within 2 hours and standard events within 18 hours. The network security team established robust outgoing traffic controls per SC-7.9 with extrusion detection systems deployed at all 47 managed network interfaces monitoring for denial-of-service attack patterns, command-and-control communications, malicious code propagation, and data exfiltration attempts, with threatening outbound traffic immediately blocked and user identities logged within 3 minutes of detection for investigation by specialized threat hunting teams. The incident response team implemented dynamic reconfiguration capabilities per IR-4.2 enabling rapid system modifications during security incidents including automated network segmentation rules, firewall policy updates, intrusion detection parameter adjustments, and access control list modifications with reconfiguration timeframes defined as 5 minutes for critical network components and 15 minutes for security appliances, with all changes logged and tested quarterly through simulated cyber attack exercises. The IT security team established comprehensive usage restrictions per SC-43 for all system components with formal authorization processes for mobile devices, wireless access points, peripheral equipment, and third-party cloud services, including continuous monitoring through endpoint detection and response tools, network access control systems, and security information and event management platforms with violation detection within 12 hours and security notification within 2 hours of confirmed violations. The email security team configured all email systems to automatically execute mobile code from attachments when received from trusted domains without user prompting, while maintaining comprehensive logging of all execution attempts and implementing advanced sandboxing technology to analyze potentially malicious content before delivery to user mailboxes.\",\n",
      "    \"is-compliant\": false,\n",
      "    \"non-compliant-reason\": \"The scenario violates SC-18.4 RULE-02 which requires that systems MUST prompt users before opening email attachments containing mobile code. The organization has configured their email systems to automatically execute mobile code from attachments when received from trusted domains without user prompting, which directly contradicts the requirement to prevent automatic execution and enforce user confirmation before any mobile code execution.\"\n",
      "  },\n",
      "  {\n",
      "    \"scenario-id\": \"scenario-id-5\",\n",
      "    \"scenario-detail\": \"GlobalTech Solutions, a Fortune 500 technology company with 12,000+ employees across 45 locations, implemented a comprehensive security architecture for their new cloud-native financial reporting platform processing SOX-compliant data and handling $8.2B in annual revenue transactions. The Chief Information Security Officer established separate processing domains per AC-6.4 with hypervisor-based isolation ensuring virtual machines processing financial data at Confidential classification operate in dedicated security domains isolated from development VMs at Internal classification, with strict privilege boundaries preventing cross-domain access and quarterly penetration testing validating isolation effectiveness. The organization appointed a dedicated Chief Information Security Officer per PM-2 with CISSP certification and 12 years of enterprise security leadership experience, reporting directly to the CEO with dedicated budget authority of 4.2% of total IT budget ($18M annually) and documented cross-organizational authority to enforce security policies across all business units including international subsidiaries. The security team implemented attribute-based access control per AC-3.13 with real-time authorization decisions based on employee role attributes (Financial Analyst, SOX Auditor, System Administrator), data classification attributes (Public, Internal, Confidential, Restricted), environmental attributes including time-of-access restrictions for after-hours sensitive data access, and location attributes requiring corporate network access for Confidential financial data with 8-minute attribute refresh cycles ensuring current permissions. The SOC deployed centralized audit review capabilities per AU-6.4 with enterprise SIEM platform aggregating logs from 847 system components across all facilities, achieving 97.8% component coverage with automated correlation rules detecting cross-system attack patterns and security analysts reviewing high-priority alerts within 2.5 hours average response time during business hours, maintaining 99.7% SIEM uptime and retaining all audit analysis activities for 18 months exceeding regulatory requirements.\\n\\nPolicies referenced: POL_AC-6.4, POL_PM-2, POL_AC-3.13, POL_AU-6.4\",\n",
      "    \"is-compliant\": true,\n",
      "    \"non-compliant-reason\": \"\"\n",
      "  },\n",
      "  {\n",
      "    \"scenario-id\": \"scenario-id-6\",\n",
      "    \"scenario-detail\": \"SecureFinance Corporation, a regional bank with 3,200 employees operating 78 branches across 12 states, established comprehensive business continuity and security engineering capabilities for their core banking platform processing $2.4B in daily transactions and serving 450,000 customers. The Business Continuity Manager defined system recovery and reconstitution capabilities per CP-10 with Critical systems (core banking, ATM networks) achieving RTO of 2 hours and RPO of 30 minutes through real-time data replication, High systems (loan processing, customer portals) meeting RTO of 18 hours and RPO of 2 hours via hourly backups, and Moderate systems (reporting, analytics) maintaining RTO of 48 hours and RPO of 12 hours with daily backup procedures, conducting annual recovery testing for all Critical systems with documented validation results and maintaining interim capability deactivation procedures during reconstitution phases. The development organization applied security and privacy engineering principles per SA-8 throughout their secure development lifecycle with documented security principles including defense-in-depth, least privilege, and fail-secure design patterns, privacy principles addressing data minimization and consent management for customer PII, mandatory threat modeling for all system modifications processing financial data, and quarterly secure coding training for 125 developers covering OWASP Top 10 vulnerabilities and privacy-by-design implementation techniques. The IT Security team configured all collaboration platforms per SC-15.4 to explicitly display current participants for SOX compliance meetings, PCI-DSS audit sessions, and regulatory examination calls, implementing identity verification procedures requiring corporate authentication before joining sensitive discussions and maintaining participant logs with 7-year retention for compliance meetings including quarterly board presentations and annual regulatory reviews. The Network Security team deployed wireless intrusion detection systems per SI-4.14 with 312 WIDS sensors providing 98.5% coverage across all branch locations and headquarters facilities, continuously monitoring for rogue access points and wireless attack patterns with 3-minute alert generation, investigating detected rogue devices within 2.8 hours average response time and maintaining updated attack signatures with monthly vendor updates ensuring comprehensive wireless security monitoring.\\n\\nPolicies referenced: POL_CP-10, POL_SA-8, POL_SC-15.4, POL_SI-4.14\",\n",
      "    \"is-compliant\": true,\n",
      "    \"non-compliant-reason\": \"\"\n",
      "  },\n",
      "  {\n",
      "    \"scenario-id\": \"scenario-id-7\",\n",
      "    \"scenario-detail\": \"GlobalTech Financial Services, a multinational investment firm with 15,000+ employees managing $450B in client assets across 45 countries, is implementing a new federated identity management system to support their cross-border trading platform serving institutional clients in North America, Europe, and Asia-Pacific regions. The Identity and Access Management team configured their primary identity provider to generate pairwise pseudonymous identifiers per IA-4.8 requirements using cryptographically secure methods with 256-bit entropy, ensuring each identifier is opaque and unguessable to protect subscriber privacy across different trading platforms and regulatory jurisdictions. The system architecture implements comprehensive token lifecycle management per IA-13.3 with high-privilege trading tokens limited to 1-hour validity periods, standard user tokens expiring after 8 hours, and service account tokens for automated systems valid for 24 hours, with all tokens requiring audience restrictions to specific trading applications and geographic regions to prevent unauthorized cross-border access. The organization maintains strict purposing controls per PM-32 with quarterly analysis of their mission-essential trading systems to ensure each platform serves only its documented purpose of supporting specific asset classes and regulatory requirements, with the equity trading system restricted to stock transactions, the derivatives platform limited to futures and options, and the foreign exchange system dedicated solely to currency trading operations. To ensure system integrity, all major platform modifications undergo independent verification per SA-11.3 with qualified third-party security firms validating assessment plans and testing evidence, including recent verification by CyberAssurance Partners (an independent cybersecurity consultancy with no financial relationships to GlobalTech) who confirmed proper implementation of security controls across the trading infrastructure. However, the identity provider has been configured to use the same pseudonymous identifier 'GTF-USER-789456123' across multiple relying parties including both the equity trading platform and the derivatives platform to simplify user experience and reduce authentication friction for traders who frequently switch between these systems during active trading sessions.\",\n",
      "    \"is-compliant\": false,\n",
      "    \"non-compliant-reason\": \"This scenario violates IA-4.8 RULE-02 which requires that each relying party MUST receive unique pseudonymous identifiers that SHALL NOT be reused across different relying parties. The use of the same identifier 'GTF-USER-789456123' across both the equity trading platform and derivatives platform constitutes unauthorized identifier reuse without documented operational justification and privacy officer approval as required by RULE-04.\"\n",
      "  },\n",
      "  {\n",
      "    \"scenario-id\": \"scenario-id-8\",\n",
      "    \"scenario-detail\": \"SecureHealth Medical Center, a 2,400-bed academic medical facility serving 850,000+ patients annually across three hospital campuses, is upgrading their electronic health record (EHR) system to support new telemedicine capabilities and AI-powered diagnostic tools for radiology, pathology, and cardiology departments. The IT security team has implemented comprehensive malicious code protection per SI-3.4 across all 12,000+ endpoints including workstations, mobile devices, and medical equipment, with centrally managed antivirus solutions deployed through Microsoft System Center Configuration Manager and only privileged system administrators authorized to perform signature updates and configuration modifications. The organization follows strict external system access controls per AC-20 with written terms and conditions governing contractor access to patient data systems, including specific agreements with their primary EHR vendor Epic Systems, radiology partner Philips Healthcare, and cloud infrastructure provider Microsoft Azure, with all agreements limiting data processing to approved HIPAA-compliant systems and prohibiting access from personal devices or unapproved cloud platforms. Their change management process implements rigorous control verification per CM-4(2) requiring all system modifications to undergo security and privacy control validation within 5 business days for standard changes, with documented verification that impacted controls remain properly implemented and operating as intended to protect patient health information. The medical center maintains detailed system purposing documentation per PM-32 with quarterly analysis ensuring their mission-essential clinical systems are used only for authorized healthcare functions, including the EHR system restricted to patient care documentation, the radiology PACS system limited to medical imaging workflows, and the laboratory information system dedicated solely to diagnostic testing processes. During a recent system upgrade to add new AI diagnostic capabilities, the change was implemented on Friday evening and the security team completed their control verification testing on the following Wednesday, confirming that all impacted privacy controls for patient data protection were functioning correctly and producing the desired outcomes for HIPAA compliance, with formal documentation and approval completed by both security and privacy personnel before the change was officially closed.\",\n",
      "    \"is-compliant\": false,\n",
      "    \"non-compliant-reason\": \"This scenario violates CM-4(2) RULE-02 which requires control verification activities to be completed within 5 business days of change implementation for standard changes. The system upgrade was implemented on Friday evening and verification was completed the following Wednesday, which exceeds the 5 business day requirement (Friday to Wednesday spans 6 business days: Monday, Tuesday, Wednesday of the following week plus Friday of the implementation week).\"\n",
      "  },\n",
      "  {\n",
      "    \"scenario-id\": \"scenario-id-9\",\n",
      "    \"scenario-detail\": \"TechSecure Financial Services, a major investment bank with 12,000+ employees handling sensitive customer PII and financial data across 45 global offices, is implementing a comprehensive privacy and incident response program following a recent security assessment. The Chief Privacy Officer deployed user-friendly consent revocation mechanisms per PT-4.3 across all customer-facing digital platforms including mobile banking apps with one-click revocation buttons, online investment portals with dedicated privacy dashboards accessible from account settings, and marketing email systems with automated unsubscribe processing within 24 hours for sensitive financial data and 72 hours for standard marketing preferences, ensuring all revocation requests generate immediate confirmation emails and comprehensive audit logs for regulatory compliance. The Security Operations Center implemented automated incident reporting systems per IR-6.2 with SIEM integration automatically generating incident tickets within 15 minutes of detection, email notifications to the incident response team and CISO, and real-time dashboard updates showing incident status, with backup manual reporting procedures activated within 5 minutes during system failures and quarterly testing validating 99.9% system uptime. The incident response team established vulnerability reporting workflows ensuring all system vulnerabilities discovered during security incident investigations are reported to the designated vulnerability management team within 24 hours, including detailed incident correlation analysis, affected system documentation, and severity assessments, with high and critical vulnerabilities escalated to senior leadership within 4 hours and comprehensive analysis completed within 72 hours to prioritize remediation efforts. The organization deployed comprehensive sensor privacy notices per SC-42.4 throughout all facilities including visible signage within 10 feet of security cameras in public lobbies and conference rooms, pop-up notifications in mobile applications before GPS location tracking activation, prominent privacy notices on websites before analytics cookie deployment, and clear biometric reader notifications specifying data collection purposes with organizational privacy contact information prominently displayed.\\n\\nPolicies referenced: policy_PT-4.3, policy_IR-6.2, policy_SC-42.4\",\n",
      "    \"is-compliant\": true,\n",
      "    \"non-compliant-reason\": \"\"\n",
      "  },\n",
      "  {\n",
      "    \"scenario-id\": \"scenario-id-10\",\n",
      "    \"scenario-detail\": \"CyberDefense Manufacturing Corporation, a defense contractor with 6,800+ employees supporting classified government projects across 18 secure facilities, is deploying enhanced security training and physical protection systems for their new advanced materials research facility processing TOP SECRET information. The Chief Information Security Officer implemented comprehensive social engineering literacy training per AT-2.3 ensuring all personnel including contractors and third-party users complete training within 30 days of hire covering recognition techniques for phishing, pretexting, impersonation, baiting, quid pro quo, thread-jacking, social media exploitation, and tailgating attacks, with specific organizational reporting procedures requiring suspected incidents be reported within 2 hours through established security channels, annual refresher training maintaining 97% completion rates across all 6,800 personnel, and specialized executive leadership training addressing high-value target scenarios. The Facilities Security Manager deployed water damage protection systems per PE-15 throughout all critical infrastructure areas including accessible master shutoff valves in the main data center within 45 seconds of emergency access points, server rooms with isolation valves tested quarterly with documented maintenance records, network equipment rooms with clearly marked valve locations and emergency contact information updated within 10 days of personnel changes, and comprehensive training for 4 key personnel per facility on valve locations and activation procedures with emergency response protocols. The IT Operations team implemented separate processing domains per AC-6.4 using VMware vSphere hypervisors with strict VM isolation preventing cross-domain privilege escalation, classified research data processed in high-security virtual machines completely separated from administrative systems, development environments isolated from production systems processing different security classifications, quarterly domain isolation testing verifying separation effectiveness, and comprehensive logging of all cross-domain data transfer attempts with documented business justifications for any legitimate cross-domain access requirements. The development team established comprehensive documentation requirements per SA-4.9 for all internal and contractor developers to identify functions, ports, protocols, and services during requirements definition and design phases, with security architecture reviews of all documented components, contract language requiring vendor compliance, and documentation updates provided within 15 business days of any changes to system components.\\n\\nPolicies referenced: policy_AT-2.3, policy_PE-15, policy_AC-6.4, policy_SA-4.9\",\n",
      "    \"is-compliant\": true,\n",
      "    \"non-compliant-reason\": \"\"\n",
      "  },\n",
      "  {\n",
      "    \"scenario-id\": \"scenario-id-11\",\n",
      "    \"scenario-detail\": \"TechGlobal Industries, a multinational software development company with 12,000+ employees across 15 countries, is implementing a new mobile device management system for their distributed workforce. The Chief Information Security Officer established comprehensive mobile device encryption requirements per AC-19.5, mandating full-device encryption using FIPS 140-2 Level 1 validated cryptographic modules for all corporate smartphones, tablets, and laptops accessing organizational systems, with AES-256 container-based encryption approved as an alternative when meeting enterprise key management requirements and receiving explicit CISO approval. The organization deployed automated compliance monitoring systems that verify encryption status during initial device provisioning and perform monthly compliance checks, with failed encryption events triggering immediate network disconnection and mandatory reporting within 4 hours to the security operations center. The company's authorization framework follows PM-10 requirements with designated Authorizing Officials for each regional business unit who maintain documented authority to accept security and privacy risks, supported by current risk assessments completed within the last 12 months and integrated continuous monitoring processes that track system changes and security posture modifications across all authorized mobile device management infrastructure. The development team implemented proper interface separation per SC-2.1, ensuring that system management functionality is completely hidden from non-privileged users through dynamic role-based interface presentation, with administrative options withheld until users establish authenticated sessions with appropriate administrative privileges, and comprehensive separation preventing discovery or enumeration of administrative functionality by standard users. However, during the recent security audit, investigators discovered that the mobile device management system's web interface presents greyed-out administrative menu options to non-privileged users, allowing them to see system configuration options, user management functions, and security policy settings even though these controls are disabled and non-functional for standard users.\\n\\nPolicies referenced: AC-19.5, PM-10, SC-2.1\",\n",
      "    \"is-compliant\": false,\n",
      "    \"non-compliant-reason\": \"The scenario violates SC-2.1 RULE-03, which states that grey-out or disabled administrative controls MUST NOT be presented to non-privileged users as this still reveals system management capabilities. The mobile device management system's web interface showing greyed-out administrative menu options to non-privileged users violates the requirement for complete separation of administrative functionality from non-privileged user interfaces.\"\n",
      "  },\n",
      "  {\n",
      "    \"scenario-id\": \"scenario-id-12\",\n",
      "    \"scenario-detail\": \"CyberDefense Corporation, a defense contracting company with 6,800 employees developing critical infrastructure security solutions, recently completed implementation of their enhanced software development lifecycle security program. The organization maintains strict version control integrity mapping per SA-10.5, requiring all system developers to maintain real-time integrity mapping between master build data and on-site master copies for security-relevant hardware, software, and firmware components, with cryptographic hashes and digital signatures implemented for continuous integrity verification and automated checking mechanisms deployed where technically feasible. The company's risk management program incorporates all-source intelligence per RA-3(2), utilizing open-source information, signals intelligence, and human intelligence to enhance risk analysis activities across all systems and multi-tier supplier assessments, with quarterly risk intelligence reports informing engineering, acquisition, and risk management decisions through documented intelligence sharing agreements approved by the Chief Risk Officer. The incident response program implements comprehensive information correlation per IR-4.4, with all security incidents reported to the central correlation system within 2 hours of detection, automated correlation capabilities analyzing incidents across business units in real-time, and organization-wide correlation reports generated within 24 hours of identifying coordinated attacks, supported by weekly cross-functional meetings including representatives from all business units. The organization established joint authorization processes per CA-6.2 for their connected defense systems, employing multiple authorizing officials including representatives from client defense agencies who serve as external authorizing officials with documented stakeholder interests and vested equities in authorization outcomes, with comprehensive documentation identifying all participating officials and their organizational affiliations. However, during a recent compliance review, auditors identified that the organization's joint authorization documentation for a critical defense system connecting to multiple client networks includes two internal authorizing officials from different divisions within CyberDefense Corporation, but no external authorizing official from any client organization, despite the system processing classified data from three separate defense agencies.\\n\\nPolicies referenced: SA-10.5, RA-3(2), IR-4.4, CA-6.2\",\n",
      "    \"is-compliant\": false,\n",
      "    \"non-compliant-reason\": \"The scenario violates CA-6.2 RULE-02, which requires that joint authorization processes MUST include at least one authorizing official from an organization external to the organization conducting the authorization. The critical defense system requires joint authorization due to its connections to multiple client networks and processing of classified data from three defense agencies, but the authorization documentation shows only internal authorizing officials from CyberDefense Corporation with no external authorizing official from any client organization.\"\n",
      "  },\n",
      "  {\n",
      "    \"scenario-id\": \"scenario-id-13\",\n",
      "    \"scenario-detail\": \"CyberDefense Solutions Inc., a federal contractor with 4,200 employees providing cybersecurity services to government agencies, is implementing a comprehensive security monitoring and management platform across their distributed infrastructure. The Chief Information Security Officer established centrally managed security controls per PL-9 covering access control policies, vulnerability scanning procedures, incident response protocols, and security awareness training programs, with standardized implementations deployed through automated configuration management tools across 15 regional offices and 3 data centers, ensuring consistent control implementation while maintaining hybrid control boundaries where local system administrators handle site-specific configurations under centralized oversight. The Security Operations Center implemented advanced vulnerability correlation capabilities per RA-5.10 using automated tools to analyze scan outputs from Nessus, Qualys, and Rapid7 platforms within 24 hours of completion, identifying multi-hop attack vectors that span three or more vulnerabilities across different system components, with particular focus on legacy Windows Server 2012 systems integrated with modern cloud infrastructure and IPv4-to-IPv6 network transitions that create potential exploitation paths for adversaries. The organization deployed comprehensive training record management per AT-4 maintaining detailed documentation of all security awareness and role-based training activities including participant names, completion dates, assessment scores, and specialized competencies for privileged users, with individual records retained for 7 years using encrypted storage systems with automated backup procedures and monthly monitoring of completion rates reported quarterly to executive leadership. The data protection team implemented robust data mining prevention controls per AC-23 establishing query limits of 1000 per hour and 10000 per day for database users, deploying real-time monitoring systems that generate alerts when queries access more than 10000 records or span multiple sensitive data categories, with all data mining activities requiring written authorization from the Data Protection Officer and differential privacy techniques applied to protect sensitive information patterns. These integrated security measures create a comprehensive defense-in-depth strategy protecting classified government data while maintaining operational efficiency across the organization's complex hybrid infrastructure environment.\\n\\nPolicies referenced: POL_PL-9, POL_RA-5.10, POL_AT-4, POL_AC-23\",\n",
      "    \"is-compliant\": true,\n",
      "    \"non-compliant-reason\": \"\"\n",
      "  },\n",
      "  {\n",
      "    \"scenario-id\": \"scenario-id-14\",\n",
      "    \"scenario-detail\": \"GlobalTech Manufacturing Corporation, a defense contractor with 12,800 employees operating 22 production facilities worldwide, is establishing a resilient business continuity framework to support critical defense manufacturing operations during contingency events. The Business Continuity Manager conducted comprehensive capacity planning per CP-2.2 identifying minimum processing capacity requirements for essential manufacturing control systems, telecommunications bandwidth needs for inter-facility coordination during emergencies, and environmental support systems including backup power generation, cooling infrastructure, and secure communications capabilities across primary and alternate manufacturing sites, with annual validation testing confirming capacity assumptions can support 75% operational capability during degraded conditions. The organization implemented realistic contingency training programs per CP-3.2 employing operational mechanisms from production manufacturing environments including actual PLCs, SCADA systems, and quality control processes to create thorough training scenarios, with quarterly exercises simulating supply chain disruptions, cyber attacks on manufacturing systems, and facility evacuations while maintaining classified production schedules and ensuring personnel can execute emergency procedures using the same systems and processes they would encounter during actual contingency events. The IT Security team deployed advanced session management controls per AC-12.3 across all manufacturing control systems and administrative interfaces, configuring explicit timeout warning messages that display 2 minutes before session termination for standard sessions and 30 seconds for critical manufacturing control interfaces, with clear remaining time indicators and session extension options that prevent data loss during complex manufacturing operations while maintaining security posture. The network security team established comprehensive extrusion detection capabilities per SC-7.9 monitoring all outbound traffic from manufacturing networks for potential threats including denial-of-service patterns, industrial espionage attempts, and malicious code communications, with immediate blocking of threatening traffic and complete audit logging of internal users within 5 minutes, ensuring protection of proprietary manufacturing processes and classified defense technologies from unauthorized disclosure to external systems.\\n\\nPolicies referenced: POL_CP-2.2, POL_CP-3.2, POL_AC-12.3, POL_SC-7.9\",\n",
      "    \"is-compliant\": true,\n",
      "    \"non-compliant-reason\": \"\"\n",
      "  },\n",
      "  {\n",
      "    \"scenario-id\": \"scenario-id-15\",\n",
      "    \"scenario-detail\": \"CyberDefense Solutions, a defense contractor with 6,200 employees supporting classified government projects, is implementing a comprehensive security monitoring infrastructure across 8 secure facilities processing CONFIDENTIAL and SECRET information. The Security Operations Center established automated indicators of compromise (IOC) collection per SI-4.24 from government threat intelligence feeds including US-CERT, DHS CISA, and FBI InfraGard with continuous 24/7 automated ingestion using TAXII protocols and STIX formatting, distributing critical IOCs within 2 hours and standard IOCs within 12 hours to designated security personnel through encrypted channels with mandatory acknowledgment tracking. The organization deployed FIPS 201-approved PIV authentication products per SA-4.10 including Gemalto IDPrime MD 840 smart card readers validated against the current GSA FIPS 201 Approved Products List, ActivIdentity ActivClient middleware software for PIV certificate processing, and Oberthur ID-One Cosmo v7.0 PIV cards, with quarterly validation against updated approved products lists and comprehensive procurement documentation maintaining FIPS 201 verification records. The network security team implemented automatic software updates per SI-2.5 with staggered deployment across production environments, installing critical security patches within 48 hours and standard patches within 21 days using Microsoft WSUS for Windows systems and Red Hat Satellite for Linux infrastructure, with failed update alerts configured for 2-hour notification and 24-hour remediation requirements. The access control architecture restricts repository access per AC-3.11 with role-based controls limiting developers to anonymized test data, HR personnel to department-specific employee records, and cryptographic key access restricted to certified key management personnel with documented business justifications and monthly access log reviews. The DNS infrastructure operates without DNSSEC implementation for external queries, relying on traditional DNS resolution with standard zone transfers and basic authentication mechanisms for authoritative responses to external clients.\\n\\nPolicies referenced: policy_SI-4.24, policy_SA-4.10, policy_SI-2.5, policy_AC-3.11, policy_SC-20\",\n",
      "    \"is-compliant\": false,\n",
      "    \"non-compliant-reason\": \"The scenario violates policy SC-20 (Secure Name/Address Resolution Service) Rule-01, which requires all authoritative name resolution services to provide DNSSEC digital signatures or equivalent cryptographic authentication artifacts with response data to external queries. The DNS infrastructure described operates without DNSSEC implementation for external queries, using only traditional DNS resolution with basic authentication mechanisms, failing to provide the required cryptographic authentication and integrity verification for authoritative data returned to external queries.\"\n",
      "  },\n",
      "  {\n",
      "    \"scenario-id\": \"scenario-id-16\",\n",
      "    \"scenario-detail\": \"SecureTech Manufacturing, an aerospace contractor with 4,800 employees supporting government contracts, is deploying advanced security infrastructure across 6 manufacturing facilities processing CONFIDENTIAL technical specifications and export-controlled ITAR data. The information security team established comprehensive information disclosure monitoring per AU-13 using automated tools scanning GitHub, GitLab, social media platforms, and technical forums every 8 hours for unauthorized disclosure of proprietary manufacturing processes, employee information, and classified project details, with Security Operations Center notification within 45 minutes of discovery and Data Protection Officer notification within 3 hours of confirmed disclosures, including comprehensive documentation of monitoring activities with timestamps and findings. The identity management system implements user status identification per IA-4.4 with clear status indicators distinguishing employees, contractors including BAE Systems and Lockheed Martin personnel with contracting organization names and contract end dates, foreign nationals from allied countries with appropriate security clearance designations, and external vendors with organization affiliations, updating status changes within 3 business days of HR notifications and displaying status information in all email systems and collaboration platforms. The privileged function architecture implements physical domain separation per SC-32.1 with administrative functions distributed across two geographically separated data centers in Virginia and Texas, each with independent power systems, dedicated network infrastructure, and separate physical security controls, with quarterly domain separation reviews and documented isolation testing preventing single points of failure. The automatic update infrastructure per SI-2.5 deploys security patches using phased rollouts with critical patches installed within 60 hours and standard patches within 25 days across production manufacturing systems, development environments, and network infrastructure using automated deployment tools with comprehensive configuration management and 4-hour alert notifications for failed updates. However, the organization operates a single physical domain housing all privileged administrative functions for the classified manufacturing systems, with shared power distribution, common network infrastructure, and centralized management consoles controlling multiple security zones from the same physical location due to facility space constraints and operational efficiency requirements.\\n\\nPolicies referenced: policy_AU-13, policy_IA-4.4, policy_SC-32.1, policy_SI-2.5\",\n",
      "    \"is-compliant\": false,\n",
      "    \"non-compliant-reason\": \"The scenario violates policy SC-32.1 (Separate Physical Domains for Privileged Functions) Rule-01 and Rule-03, which require privileged functions to be distributed across a minimum of two separate physical domains with no shared physical infrastructure components, and administrative functions for different security zones to operate from physically separate management domains. The organization operates all privileged administrative functions for classified manufacturing systems from a single physical domain with shared power distribution, common network infrastructure, and centralized management consoles controlling multiple security zones from the same location, creating a single point of failure that violates the physical separation requirements.\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff8371d-106d-4893-bcdb-965bef86e4d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

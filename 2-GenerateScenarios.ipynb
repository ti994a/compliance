{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c22ff17-b692-4612-b2ce-785abdec9713",
   "metadata": {},
   "source": [
    "# GenerateScenarios\n",
    "This notebook generates realistic compliance scenarios by leveraging AWS Bedrock's Retrieval-Augmented Generation (RAG) capabilities using the NIST control framework and specific organizational policies generated against that framework. It generates 1,000 (500 compliant, 500 non-compliant) complex, multi-policy scenarios that simulate real-world compliance situations (like employee onboarding, data access requests, or security incidents).\n",
    "\n",
    " - Generates Scenario Batches - Uses Bedrock's Converse API with RAG to create realistic compliance scenarios by alternating between compliant and non-compliant cases.  For each batch of scenarios, it retrieves policy context by querying AWS Bedrock Knowledge Base containing NIST controls and policies.\n",
    " - Structures Output - Forces JSON format output with specific schema including scenario ID, detailed description, compliance status, and violation reasons.\n",
    " - Multi-Policy Coverage - Each scenario incorporates multiple policies to create complex, realistic compliance evaluation situations.\n",
    "\n",
    "```\n",
    "Execution Flow:\n",
    "└── main()\n",
    "    ├── generate_compliance_scenarios()\n",
    "    │   ├── retrieve_kb_context()\n",
    "    │   │   └── bedrock_agent_runtime.retrieve()\n",
    "    │   └── generate_scenario_batch()\n",
    "    │       └── bedrock_runtime.converse()\n",
    "    ├── save_scenarios_to_file()\n",
    "    └── save_scenarios_to_s3()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "execution_state": "idle",
   "id": "6b008304-8133-4539-b75f-b66534b07807",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T22:35:30.486859Z",
     "iopub.status.busy": "2026-01-13T22:35:30.486598Z",
     "iopub.status.idle": "2026-01-13T22:35:30.506727Z",
     "shell.execute_reply": "2026-01-13T22:35:30.505363Z",
     "shell.execute_reply.started": "2026-01-13T22:35:30.486836Z"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "from compliance_calculator import compliance_calculator, CALCULATOR_TOOL\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "BUCKET = '183023889407-us-east-1-compliance-rule-generator'\n",
    "S3_PREFIX_POLICY_MARKDOWN_ALL = 'policies/markdown/all-policies-main/'\n",
    "OUTPUT_PREFIX = 'scenarios/'  # Folder path for results\n",
    "KNOWLEDGE_BASE_ID = 'T8EW10IU3Z'  # AWS Bedrock Knowledge Base containing NIST policies\n",
    "# Available Bedrock model ARNs with performance notes\n",
    "MODELS = {\n",
    "    'premium': 'arn:aws:bedrock:us-east-1:183023889407:inference-profile/global.anthropic.claude-opus-4-5-20251101-v1:0', # not available\n",
    "    'good': 'arn:aws:bedrock:us-east-1:183023889407:inference-profile/global.anthropic.claude-sonnet-4-5-20250929-v1:0', # times out\n",
    "    'balanced': 'arn:aws:bedrock:us-east-1:183023889407:inference-profile/us.anthropic.claude-sonnet-4-20250514-v1:0',  # recommended\n",
    "    'fast_cheap': 'arn:aws:bedrock:us-east-1:183023889407:inference-profile/us.anthropic.claude-haiku-4-5-20251001-v1:0',\n",
    "    'aws_native_premier': 'arn:aws:bedrock:us-east-1:183023889407:inference-profile/us.amazon.nova-premier-v1:0',\n",
    "    'aws_native_pro': 'arn:aws:bedrock:us-east-1:183023889407:inference-profile/us.amazon.nova-pro-v1:0'\n",
    "}\n",
    "MODEL_ARN = MODELS['premium']  # Default model selection\n",
    "SCENARIOS_PER_BATCH = 2\n",
    "NUM_BATCHES = 4\n",
    "TOTAL_SCENARIOS = SCENARIOS_PER_BATCH * NUM_BATCHES\n",
    "POLICIES_PER_SCENARIO = 4\n",
    "\n",
    "# JSON tool configuration for Bedrock Converse API\n",
    "# Forces the model to return structured JSON with specific schema\n",
    "TOOL_CONFIG = {\n",
    "    \"tools\": [{\n",
    "        \"toolSpec\": {\n",
    "            \"name\": \"scenario_json\",\n",
    "            \"description\": \"Return compliance scenarios as JSON\",\n",
    "            \"inputSchema\": {\n",
    "                \"json\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"scenarios\": {  # Array of scenario objects\n",
    "                            \"type\": \"array\",\n",
    "                            \"items\": {\n",
    "                                \"type\": \"object\",\n",
    "                                \"properties\": {\n",
    "                                    \"scenario-id\": {\"type\": \"string\"},      # Format: scenario-id-1, scenario-id-2, etc.\n",
    "                                    \"scenario-detail\": {\"type\": \"string\"},  # Detailed scenario description (200+ words)\n",
    "                                    \"is-compliant\": {\"type\": \"boolean\"},     # True if compliant, False if non-compliant\n",
    "                                    \"non-compliant-reason\": {\"type\": \"string\"}  # If non-compliant, why? Which policy(s) were violated?\n",
    "                                },\n",
    "                                \"required\": [\"scenario-id\", \"scenario-detail\", \"is-compliant\"]\n",
    "                            }\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"scenarios\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"toolSpec\": {\n",
    "            \"name\": \"compliance_calculator\",\n",
    "            \"description\": \"Calculate and compare values with time, money, data, and percentage units\",\n",
    "            \"inputSchema\": {\n",
    "                \"json\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"expression\": {\"type\": \"string\", \"description\": \"Expression like '800ms < 1s' or '4m > 3b'\"}\n",
    "                    },\n",
    "                    \"required\": [\"expression\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "              \n",
    "             ]\n",
    "}\n",
    "\n",
    "# Initialize AWS Bedrock clients\n",
    "bedrock_agent_runtime = boto3.client('bedrock-agent-runtime', region_name='us-east-1')  # For knowledge base retrieval\n",
    "bedrock_runtime = boto3.client('bedrock-runtime', region_name='us-east-1')  # For model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "execution_state": "idle",
   "id": "6bdc29ec-8ace-4cca-abb9-0139668e1bb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T22:35:31.400914Z",
     "iopub.status.busy": "2026-01-13T22:35:31.400640Z",
     "iopub.status.idle": "2026-01-13T22:35:31.412880Z",
     "shell.execute_reply": "2026-01-13T22:35:31.411497Z",
     "shell.execute_reply.started": "2026-01-13T22:35:31.400892Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_scenario_batch(\n",
    "    policies: str,\n",
    "    policy_ids: str,\n",
    "    batch_num: int,\n",
    "    model_arn: str,\n",
    "    scenarios_per_batch: int=SCENARIOS_PER_BATCH\n",
    ") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Generate one batch of compliance scenarios using Bedrock Converse API.\n",
    "    This function creates realistic compliance scenarios by alternating between\n",
    "    compliant and non-compliant scenarios across batches. Uses the JSON tool\n",
    "    to ensure structured output.\n",
    "    Args:\n",
    "        policies: Combined policy text from knowledge base\n",
    "        batch_num: Current batch number (0-indexed)\n",
    "        model_arn: AWS Bedrock model ARN or ID\n",
    "        scenarios_per_batch: Number of scenarios per batch\n",
    "    Returns:\n",
    "        List of scenario dictionaries with keys: scenario-id, scenario-detail, is-compliant, non-compliant-reason\n",
    "    \"\"\"\n",
    "    # Alternate between compliant (even batches) and non-compliant (odd batches) scenarios\n",
    "    is_compliant = batch_num % 2 == 0\n",
    "    \n",
    "    # Calculate starting ID for consecutive numbering across all batches\n",
    "    start_id = batch_num * scenarios_per_batch + 1\n",
    "    \n",
    "    # Construct detailed prompt with all policy context and specific requirements\n",
    "    prompt = f\"\"\"Based on NIST compliance policies under **KNOWLEDGE BASE CONTEXT**, generate {scenarios_per_batch} realistic compliance scenario (scenario-details) \n",
    "    that are \n",
    "    {'compliant' if is_compliant else 'non-compliant.  Ensure that only one underlying policy is violated out of all the underlying policies for each scenario. Use no leading language like \"however\" or tone to indicate in any way that the scenarios is in any way invalid.  Try to trick the reader to believe it is valid.'}.\n",
    "    \n",
    "    Each scenario-detail must:\n",
    "    - Use all policies from KNOWLEDGE BASE CONTEXT context below\n",
    "    - Include specific business details (roles, systems, data, actions)\n",
    "    - Be realistic and detailed (200+ words)\n",
    "    - Have scenario-id format: scenario-id-{start_id}, scenario-id-{start_id+1}, etc.\n",
    "\n",
    "    **Avoid generating scenarios based on cost-benefit principles or concentration percentages.**\n",
    "    \n",
    "    **Note that non-US citizens cannot obtain US security clearances.**\n",
    "\n",
    "    **CRITICAL: For ANY numerical comparison involving timeframes, values, or thresholds:**\n",
    "    - ALWAYS use the compliance_calculator tool to verify comparisons - do not do mental math\n",
    "    - If a scenario meets or exceeds (performs better than) policy requirements, it is COMPLIANT.  For example, if a policy requires \"within 24 hours\" and scenario shows \"within 18 hours\", this is COMPLIANT (18 < 24).\n",
    "    - If a scenario does not meet policy requirements it is NON-COMPLIANT.  For example, if a policy requires \"at least quarterly (90 days)\" and scenario shows \"95 days\", this is NON-COMPLIANT (95 > 90)\n",
    "\n",
    "    \n",
    "    Return as JSON array with fields: scenario-id, scenario-detail, is-compliant, non-compliant-reason\n",
    "    {'leave non-compliant-reason empty' if is_compliant else 'For non-compliant-reason, provide an explanation of exactly why the scenario is non-compliant, including which policy(s) were violated.'}\n",
    "\n",
    "    **Here is an example of scenario-detail:**\n",
    "    SecureDefense Corporation, a defense contractor with 8,500+ employees supporting classified government projects, is deploying a new secure development environment\n",
    "    for processing TOP SECRET/SCI information across 12 secure facilities. The Chief Security Officer implemented citizenship requirements per MA-5.3 ensuring all\n",
    "    personnel performing maintenance on classified systems are verified U.S. citizens with current documentation including birth certificates, passports, and security\n",
    "    clearance validation, with emergency maintenance procedures explicitly prohibiting non-citizen access under any circumstances. The organization deployed NIAP-approved\n",
    "    protection profiles per SA-4.7 for all commercial security products including firewalls evaluated against Network Device Protection Profile v2.2, VPN solutions meeting\n",
    "    IPsec Virtual Private Network (VPN) Client Protection Profile v1.0, and database management systems validated against Database Management System Protection Profile v4.0,\n",
    "    with FIPS 140-2 Level 3 validated cryptographic modules for products without applicable NIAP profiles. The system architecture team implemented hierarchical protection\n",
    "    per SA-8.12 with hypervisor components at highest trust level protecting against guest VMs, classified application containers at medium trust level isolated from\n",
    "    development tools, and development interfaces at lowest trust level with comprehensive access controls preventing privilege escalation across trust boundaries. The\n",
    "    procurement team maintained technology diversity per SC-29 across the secure development pipeline using Red Hat and SUSE Linux distributions (45% and 35% respectively),\n",
    "    Dell and HPE hardware platforms, and Raytheon and General Dynamics security appliances to minimize supply chain concentration risks. Cost-benefit analyses per SA-8.25\n",
    "    documented security investments of $4.2M annually justified by protecting classified intellectual property valued at $2.8B and avoiding potential contract termination\n",
    "    penalties exceeding $150M for security violations.\n",
    "\n",
    "    **KNOWLEDGE BASE CONTEXT**\n",
    "    {policies}\n",
    "    \"\"\"\n",
    "    # Extract model ID from ARN (Converse API requires model ID, not full ARN)\n",
    "    model_id = model_arn.split('/')[-1] if '/' in model_arn else model_arn\n",
    "    \n",
    "    # Call Bedrock Converse API with JSON tool enforcement\n",
    "    messages=[{\"role\": \"user\", \"content\": [{\"text\": prompt}]}]\n",
    "    while True:\n",
    "        response = bedrock_runtime.converse(\n",
    "            modelId=model_id,\n",
    "            messages=messages,\n",
    "            toolConfig=TOOL_CONFIG,  # Forces structured JSON output\n",
    "            inferenceConfig={\"maxTokens\": 4096, \"temperature\": 0.7}  # Allow creative but controlled generation, about 3,000 words max\n",
    "        )\n",
    "        \n",
    "        if response.get('stopReason') == 'tool_use':\n",
    "            tool_results = [] \n",
    "            for content_block in response['output']['message']['content']:\n",
    "                if 'toolUse' in content_block:\n",
    "                    tool_name = content_block['toolUse']['name']\n",
    "                    tool_use_id = content_block['toolUse']['toolUseId']\n",
    "\n",
    "                    if tool_name == 'compliance_calculator':\n",
    "                        expression = content_block['toolUse']['input']['expression']                         \n",
    "                        result = compliance_calculator(expression)\n",
    "                        print(\"=\" * 60)\n",
    "                        print(f\"Compliance calculator expression: {expression}\" )\n",
    "                        print(f\"Compliance calculator result: {result}\" )\n",
    "                        print(\"=\" * 60)\n",
    "                        tool_results.append({\n",
    "                            \"toolResult\": {\n",
    "                                \"toolUseId\": tool_use_id,\n",
    "                                \"content\": [{\"text\": result}]\n",
    "                            }\n",
    "                        })\n",
    "                    elif tool_name == 'scenario_json':\n",
    "                        scenarios_data = content_block['toolUse']['input'] \n",
    "                        break\n",
    "            \n",
    "            if tool_results:\n",
    "                messages.append({\"role\": \"assistant\", \"content\": response['output']['message']['content']})\n",
    "                messages.append({\"role\": \"user\", \"content\": tool_results})\n",
    "            else:\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "                               \n",
    "    scenarios = scenarios_data.get('scenarios', [])\n",
    "\n",
    "    # add policy ids used to each scenario\n",
    "    for scenario in scenarios:\n",
    "       scenario['scenario-detail'] += f\"\\n\\nPolicies referenced: {policy_ids}\"\n",
    "    return scenarios\n",
    "    \n",
    "    # Return empty list if no tool use or scenarios found\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "execution_state": "idle",
   "id": "57b41f28-b131-413b-be13-370ed0246637",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T22:35:32.340558Z",
     "iopub.status.busy": "2026-01-13T22:35:32.340112Z",
     "iopub.status.idle": "2026-01-13T22:35:32.347120Z",
     "shell.execute_reply": "2026-01-13T22:35:32.345890Z",
     "shell.execute_reply.started": "2026-01-13T22:35:32.340524Z"
    }
   },
   "outputs": [],
   "source": [
    "def retrieve_s3_policies(bucket: str = BUCKET, policies_per_scenario: int = POLICIES_PER_SCENARIO) -> Tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Retrieve random policy documents from S3 bucket.\n",
    "    \"\"\"\n",
    "    s3 = boto3.client('s3')\n",
    "    \n",
    "    # List all policy files\n",
    "    response = s3.list_objects_v2(\n",
    "        Bucket=bucket,\n",
    "        Prefix=S3_PREFIX_POLICY_MARKDOWN_ALL\n",
    "    )\n",
    "    \n",
    "    policy_files = [obj['Key'] for obj in response.get('Contents', []) \n",
    "                   if obj['Key'].endswith('.md')]\n",
    "    \n",
    "    # Randomly select needed number of policies\n",
    "    selected_files = random.sample(policy_files, min(policies_per_scenario, len(policy_files)))\n",
    "    \n",
    "    # Read selected policy contents\n",
    "    policies = []\n",
    "    policy_ids = []\n",
    "    for file_key in selected_files:\n",
    "        obj = s3.get_object(Bucket=bucket, Key=file_key)\n",
    "        content = obj['Body'].read().decode('utf-8')\n",
    "        policies.append(content)\n",
    "        policy_ids.append(\"policy_\" + re.search(r\"POLICY: ([A-Z]+-[\\d.]+)\", content).group(1))\n",
    "            \n",
    "    print(f\"Retrieved {len(policies)} random policies from S3\")\n",
    "    return '\\n\\n'.join(policies), ', '.join(policy_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "execution_state": "idle",
   "id": "11aec7fa-498b-436f-8b4e-30961c28bc88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T22:35:32.919464Z",
     "iopub.status.busy": "2026-01-13T22:35:32.919141Z",
     "iopub.status.idle": "2026-01-13T22:35:32.926743Z",
     "shell.execute_reply": "2026-01-13T22:35:32.925358Z",
     "shell.execute_reply.started": "2026-01-13T22:35:32.919437Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_compliance_scenarios(\n",
    "    knowledge_base_id: str = KNOWLEDGE_BASE_ID,\n",
    "    model_arn: str = MODEL_ARN,\n",
    "    scenarios_per_batch: int=SCENARIOS_PER_BATCH,\n",
    "    policies_per_scenario: int=POLICIES_PER_SCENARIO,\n",
    "    total_scenarios: int = TOTAL_SCENARIOS\n",
    ") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Main orchestrator function for generating compliance scenarios.\n",
    "    \n",
    "    This function coordinates the entire scenario generation process:\n",
    "    1. Retrieves comprehensive policy context from knowledge base (once)\n",
    "    2. Generates scenarios in batches to manage API limits and costs\n",
    "    3. Alternates between compliant and non-compliant scenarios\n",
    "    4. Implements rate limiting to avoid API throttling\n",
    "    Args:\n",
    "        knowledge_base_id: AWS Bedrock Knowledge Base ID\n",
    "        model_arn: AWS Bedrock model ARN to use for generation\n",
    "        scenarios_per_batch: Number of scenarios per batch\n",
    "        policies_per_scenario: Number of NIST policies to use in creating a scenario\n",
    "        total_scenarios: Total number of scenarios to generate\n",
    "    Returns:\n",
    "        List of all generated scenario dictionaries\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate scenarios in batches\n",
    "    all_scenarios = []\n",
    "    for batch_num in range(total_scenarios // scenarios_per_batch):\n",
    "      # Retrieve all policy context once (reused across all batches)\n",
    "        try:\n",
    "            policies, policy_ids = retrieve_s3_policies(BUCKET, policies_per_scenario)\n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving from KB: {e}\")\n",
    "            return []\n",
    "        try:\n",
    "            # Generate one batch of scenarios          \n",
    "            scenarios = generate_scenario_batch(policies, policy_ids, batch_num, model_arn, scenarios_per_batch)\n",
    "            all_scenarios.extend(scenarios)\n",
    "            print(f\"Batch {batch_num + 1}: Generated {len(scenarios)} scenarios\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating scenario batch {batch_num + 1}: {e}\")\n",
    "            continue  # excplicit to go to next scenario, maybe this was a temporary glitch\n",
    "        \n",
    "        # Rate limiting: pause between batches to avoid API throttling\n",
    "        time.sleep(2)\n",
    "    \n",
    "    return all_scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "execution_state": "idle",
   "id": "8712a78b-70a0-4f46-9fbc-0b8b6e5a16cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T22:35:33.478507Z",
     "iopub.status.busy": "2026-01-13T22:35:33.478231Z",
     "iopub.status.idle": "2026-01-13T22:35:33.484686Z",
     "shell.execute_reply": "2026-01-13T22:35:33.483362Z",
     "shell.execute_reply.started": "2026-01-13T22:35:33.478482Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_scenarios_to_file(scenarios: List[Dict], output_path: str):\n",
    "    \"\"\"\n",
    "    Save generated scenarios to a JSON file with metadata.\n",
    "    \n",
    "    Creates a structured JSON file containing:\n",
    "    - Summary statistics (total, compliant, non-compliant counts)\n",
    "    - All generated scenarios\n",
    "    \"\"\"\n",
    "    # Print scenarios to console for immediate review\n",
    "    print(json.dumps(scenarios, indent=2))\n",
    "    \n",
    "    # Save to file with metadata and statistics\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump({\n",
    "            'total_scenarios': len(scenarios),\n",
    "            'compliant_count': sum(1 for s in scenarios if s['is-compliant']),\n",
    "            'non_compliant_count': sum(1 for s in scenarios if not s['is-compliant']),\n",
    "            'scenarios': scenarios\n",
    "        }, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "execution_state": "idle",
   "id": "2149410b-8800-4e63-83f1-9b9cda20743c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T22:35:34.063691Z",
     "iopub.status.busy": "2026-01-13T22:35:34.063415Z",
     "iopub.status.idle": "2026-01-13T22:35:34.068988Z",
     "shell.execute_reply": "2026-01-13T22:35:34.067997Z",
     "shell.execute_reply.started": "2026-01-13T22:35:34.063666Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_scenarios_to_s3(scenarios: List[Dict], output_bucket: str = BUCKET, output_prefix: str = OUTPUT_PREFIX, object_name: str = \"scenarios.json\"):\n",
    "    \"\"\"\n",
    "    Save generated scenarios to a S3.\n",
    "\n",
    "    \"\"\"\n",
    "    s3 = boto3.client('s3')\n",
    "    json_data = json.dumps({\"scenarios\": scenarios}, indent=2)\n",
    "    s3.put_object(Bucket=output_bucket, Key=output_prefix+object_name, Body=json_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "execution_state": "idle",
   "id": "034d84a6-9c5f-446e-a1ce-5912d269b599",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T22:35:35.103390Z",
     "iopub.status.busy": "2026-01-13T22:35:35.103092Z",
     "iopub.status.idle": "2026-01-13T22:35:35.109304Z",
     "shell.execute_reply": "2026-01-13T22:35:35.107683Z",
     "shell.execute_reply.started": "2026-01-13T22:35:35.103362Z"
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Example usage: Generate 4 scenarios in 2 batches of 2 each\n",
    "    # Batch 0 (even): compliant scenarios with IDs scenario-id-1, scenario-id-2\n",
    "    # Batch 1 (odd): non-compliant scenarios with IDs scenario-id-3, scenario-id-4\n",
    "    scenarios = generate_compliance_scenarios(\n",
    "        knowledge_base_id=KNOWLEDGE_BASE_ID,\n",
    "        model_arn=MODELS['balanced'],\n",
    "        scenarios_per_batch=SCENARIOS_PER_BATCH,\n",
    "        policies_per_scenario=POLICIES_PER_SCENARIO,\n",
    "        total_scenarios=TOTAL_SCENARIOS \n",
    "    )\n",
    "\n",
    "    save_scenarios_to_file(scenarios, '/home/sagemaker-user/scenarios.json')\n",
    "    save_scenarios_to_s3(scenarios, BUCKET, OUTPUT_PREFIX, \"scenarios.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "execution_state": "idle",
   "id": "a3c8d612-ad8e-4bc2-b653-ac967d5e712e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T22:35:35.732822Z",
     "iopub.status.busy": "2026-01-13T22:35:35.732374Z",
     "iopub.status.idle": "2026-01-13T22:37:31.465410Z",
     "shell.execute_reply": "2026-01-13T22:37:31.464179Z",
     "shell.execute_reply.started": "2026-01-13T22:35:35.732783Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 4 random policies from S3\n",
      "Batch 1: Generated 2 scenarios\n",
      "Retrieved 4 random policies from S3\n",
      "============================================================\n",
      "Compliance calculator expression: 7 days > 5 business days\n",
      "Compliance calculator result: True\n",
      "============================================================\n",
      "============================================================\n",
      "Compliance calculator expression: 120 days > 90 days\n",
      "Compliance calculator result: True\n",
      "============================================================\n",
      "Batch 2: Generated 2 scenarios\n",
      "Retrieved 4 random policies from S3\n",
      "============================================================\n",
      "Compliance calculator expression: 15s > 15s\n",
      "Compliance calculator result: False\n",
      "============================================================\n",
      "============================================================\n",
      "Compliance calculator expression: 30s > 30s\n",
      "Compliance calculator result: False\n",
      "============================================================\n",
      "Batch 3: Generated 2 scenarios\n",
      "Retrieved 4 random policies from S3\n",
      "Batch 4: Generated 2 scenarios\n",
      "[\n",
      "  {\n",
      "    \"scenario-id\": \"scenario-id-1\",\n",
      "    \"scenario-detail\": \"CyberShield Financial Services, a major banking institution with 15,000 employees across 250 branch locations, is implementing comprehensive security assessments for their core banking platform processing $2.8 billion in daily transactions. The Chief Information Security Officer established a formal red team exercise program per CA-8.2 requirements, contracting with certified external security specialists holding current CISSP, GCIH, and GPEN certifications with documented adversarial tactics training completed within the past 8 months. The red team exercises are conducted annually for their high-impact core banking systems, with the most recent exercise completed 10 months ago and the next exercise scheduled for next month to maintain the required annual frequency. Each exercise includes comprehensive technology-based penetration testing targeting network infrastructure, applications, and databases, combined with social engineering campaigns testing employee security awareness through phishing simulations and physical security assessments. Formal rules of engagement are established and approved by the CISO 2 weeks before each exercise commencement, defining scope boundaries, authorized testing methods, and safety protocols to prevent operational disruption. The Configuration Control Board oversees all system modifications per CM-3 requirements, reviewing and approving configuration changes within 3 business days of submission, with mandatory security and privacy impact analyses completed before any CCB approval decisions. All configuration changes affecting the core banking platform undergo formal documentation including change justification, comprehensive impact assessments, CCB approval records, and implementation results, with records retained for 10 years exceeding the minimum 7-year requirement. Post-implementation monitoring is conducted within 24 hours of each change deployment to verify successful implementation and identify any adverse impacts on system functionality or security posture. The organization maintains comprehensive information management per SI-12 requirements, with all system information and outputs classified according to established retention schedules within 15 days of creation, well ahead of the required 30-day timeframe. Security audit logs, vulnerability assessment reports, and red team exercise documentation are retained for 8 years, exceeding the minimum 7-year requirement for security control outputs. Information disposal utilizes NIST-approved sanitization methods with documented certificates of destruction maintained for audit purposes. Access to security-relevant information per AC-3.5 is strictly controlled through technical access controls preventing unauthorized access during operational system states, with security-relevant information including firewall rules, access control lists, and cryptographic key management data only accessible during formally documented secure, non-operable system states during approved maintenance windows with comprehensive logging of administrator identity, timestamps, and business justifications for all access activities.\\n\\nPolicies referenced: policy_CA-8.2, policy_CM-3, policy_SI-12, policy_AC-3.5\",\n",
      "    \"is-compliant\": true,\n",
      "    \"non-compliant-reason\": \"\"\n",
      "  },\n",
      "  {\n",
      "    \"scenario-id\": \"scenario-id-2\",\n",
      "    \"scenario-detail\": \"TechCorp Manufacturing, a defense contractor with 4,200 employees operating classified manufacturing facilities for military aircraft components, implements rigorous security controls across their enterprise systems processing CONFIDENTIAL and SECRET information. The organization conducts red team exercises per CA-8.2 requirements using internal security teams supplemented by external contractors, all holding current security certifications including GCFA, GCTI, and CISSP with adversarial tactics training completed 6 months ago. Red team exercises are performed every 18 months for their moderate-impact manufacturing systems and annually for high-impact classified systems, with the most recent high-impact exercise completed 11 months ago. Each exercise encompasses both sophisticated technology-based attacks simulating advanced persistent threats and comprehensive social engineering campaigns testing personnel security awareness across all facility locations. Formal rules of engagement are developed and approved by the Chief Security Officer 3 weeks prior to exercise initiation, establishing clear boundaries, authorized methodologies, and emergency stop procedures. Exercise results are documented and remediation plans developed within 20 days of completion, ensuring timely response to identified vulnerabilities. The Configuration Control Board manages all system changes per CM-3 requirements, with security and privacy impact analyses completed before any configuration modifications and CCB review completed within 4 business days of submission. All production system changes require CCB approval before implementation, with emergency changes receiving retroactive review within 48 hours including documented emergency justification. Configuration change records include comprehensive documentation of change rationale, impact assessments, approval workflows, and implementation verification, retained for 8 years to support regulatory compliance requirements. Post-implementation monitoring occurs within 36 hours of change deployment to validate successful implementation and detect any adverse system impacts. Information management follows SI-12 requirements with all system information classified according to retention schedules within 25 days of creation. Security control outputs including SIEM logs, penetration test reports, and compliance assessments are retained for 7 years as required, with personal information retention periods aligned with business necessity and Privacy Act requirements. Secure disposal utilizes DoD-approved sanitization methods with certificates of destruction maintained for audit trails. Security-relevant information access per AC-3.5 is restricted to secure, non-operable system states during authorized maintenance windows, with technical controls preventing operational-state access to firewall configurations, access control matrices, and encryption key management systems, and all maintenance access logged with administrator credentials, timestamps, and detailed business justifications for compliance verification.\\n\\nPolicies referenced: policy_CA-8.2, policy_CM-3, policy_SI-12, policy_AC-3.5\",\n",
      "    \"is-compliant\": true,\n",
      "    \"non-compliant-reason\": \"\"\n",
      "  },\n",
      "  {\n",
      "    \"scenario-id\": \"scenario-id-3\",\n",
      "    \"scenario-detail\": \"CyberShield Defense Systems, a major defense contractor with 12,000+ employees supporting TOP SECRET/SCI government projects, recently completed deployment of their next-generation classified data processing infrastructure across 15 secure facilities nationwide. The Chief Human Resources Officer implemented comprehensive personnel screening per PS-3.3 ensuring all 2,400 personnel accessing controlled unclassified information (CUI) systems possess current Public Trust background investigations with annual validation reviews, official government duties documentation demonstrating access necessity, and enhanced screening criteria defined within 15 days of each system categorization covering financial history, foreign contacts, and technology access patterns. The organization's cross-domain solutions team deployed state-of-the-art information transfer capabilities per AC-4.23 implementing automated redaction engines for classified-to-unclassified transfers, real-time masking algorithms for personally identifiable information during production-to-development data migration, comprehensive logging of all modification actions including timestamps and user identities, and rigorous validation procedures ensuring non-releasable content removal before transfer completion with emergency procedures maintaining full modification requirements and 24-hour post-transfer reviews. The procurement division established robust hardware integrity verification processes per SA-10.3 requiring all component suppliers to provide cryptographic signature verification, tamper-evident packaging with verifiable serial numbers, anti-tamper technologies enabled on all delivered hardware including network appliances and cryptographic modules, comprehensive verification performed within 7 business days of delivery, and complete verification records maintained for component lifecycle plus 3 years covering 850+ critical infrastructure components. The network security team implemented strict external connection controls per SC-7.3 maintaining documented connection limits for each system based on mission requirements, comprehensive connection inventory updated within 12 hours of any new external link establishment, quarterly inventory reviews conducted every 85 days to validate necessity and remove unused connections, and immediate disconnection procedures for unauthorized connections within 90 minutes of discovery.\\n\\nPolicies referenced: policy_PS-3.3, policy_AC-4.23, policy_SA-10.3, policy_SC-7.3\",\n",
      "    \"is-compliant\": false,\n",
      "    \"non-compliant-reason\": \"This scenario violates SA-10.3 RULE-03 which requires hardware integrity verification to be performed within 5 business days of component delivery. The scenario states verification is performed within 7 business days, which exceeds the policy requirement (7 > 5 business days).\"\n",
      "  },\n",
      "  {\n",
      "    \"scenario-id\": \"scenario-id-4\",\n",
      "    \"scenario-detail\": \"GlobalTech Security Corporation, a leading cybersecurity firm with 6,800+ employees providing classified system integration services to federal agencies, operates a comprehensive secure development and operations environment processing SECRET and TOP SECRET information across 8 hardened facilities. The organization's personnel security program per PS-3.3 ensures all 1,850 staff accessing controlled unclassified information systems maintain current Public Trust level background investigations with documented official government duties justifying special protection access, enhanced screening criteria established within 20 days of system categorization covering psychological evaluations and polygraph examinations for TOP SECRET access, annual screening validation reviews for continued access authorization, and immediate suspension procedures for expired or inadequate screening status. Their advanced cross-domain architecture per AC-4.23 features automated information transfer systems implementing sophisticated masking algorithms for social security numbers and financial data, comprehensive redaction capabilities removing classified markings and sensitive technical specifications during cross-domain transfers, complete audit logging capturing modification types, affected data elements, timestamps, and operator identities, thorough validation testing ensuring effective non-releasable content removal, and strict emergency transfer protocols requiring full modification procedures with enhanced 24-hour post-transfer security reviews. The hardware supply chain security program per SA-10.3 mandates all component developers provide integrity verification mechanisms including cryptographic hash validation, tamper-resistant packaging with unique identifiers, anti-tamper technologies activated on all delivered hardware from servers to network equipment, verification procedures completed within 4 business days of component receipt, and comprehensive documentation retention covering component lifecycle plus 3 years for audit and compliance purposes. The network boundary protection system per SC-7.3 maintains strict external connection limitations with each production system limited to maximum 3 external connections based on risk assessments, development systems limited to 2 connections, comprehensive connection inventory documentation updated within 18 hours of establishment, quarterly inventory reviews conducted every 120 days to assess necessity and security compliance, and rapid response procedures disconnecting unauthorized connections within 90 minutes of detection.\\n\\nPolicies referenced: policy_PS-3.3, policy_AC-4.23, policy_SA-10.3, policy_SC-7.3\",\n",
      "    \"is-compliant\": false,\n",
      "    \"non-compliant-reason\": \"This scenario violates SC-7.3 RULE-04 which requires external connection inventory to be reviewed quarterly (every 90 days). The scenario states quarterly reviews are conducted every 120 days, which exceeds the policy requirement (120 > 90 days).\"\n",
      "  },\n",
      "  {\n",
      "    \"scenario-id\": \"scenario-id-5\",\n",
      "    \"scenario-detail\": \"CyberTech Defense Solutions, a major defense contractor with 12,000+ employees across 15 secure facilities, is implementing a new classified data processing environment for handling TOP SECRET/SCI intelligence analysis systems. The Chief Information Security Officer established comprehensive media use controls per MP-7 by deploying organization-provided encrypted USB drives with unique serial numbers and biometric authentication for authorized personnel only, while technically disabling all unauthorized USB ports on classified workstations and implementing physical port locks on high-security systems. The organization sourced only NSA-approved information assurance products per SA-4.6, including GOTS cryptographic modules from the NSA Commercial Solutions for Classified (CSfC) program for cross-domain data transfers, COTS network security appliances validated under NSA evaluation procedures with current approval documentation maintained in the security compliance database, and implementing NSA-approved key management protocols for all cryptographic functions protecting classified information transmitted between SECRET and UNCLASSIFIED network segments. The system architecture team implemented minimized sharing principles per SA-8.6 by designing virtualized shared services with explicit business justification for each resource sharing instance, conducting comprehensive security reviews for all global data usage, implementing reentrant mechanisms for essential shared database connections, and deploying covert channel controls including memory isolation and timing analysis to prevent unauthorized information disclosure between system components. Physical security deployed access control vestibules per PE-3.8 at all data center entrances and executive floors using interlocking door systems with biometric authentication that prevent both doors from opening simultaneously for more than 10 seconds, person-counting sensors that detect piggybacking attempts and alert security within 25 seconds, comprehensive logging of all access events with timestamps and user identities, and emergency egress capabilities that activate within 3 seconds during fire alarm conditions while maintaining security monitoring throughout the egress process.\\n\\nPolicies referenced: policy_SA-8.6, policy_PE-3.8, policy_MP-7, policy_SA-4.6\",\n",
      "    \"is-compliant\": true,\n",
      "    \"non-compliant-reason\": \"\"\n",
      "  },\n",
      "  {\n",
      "    \"scenario-id\": \"scenario-id-6\",\n",
      "    \"scenario-detail\": \"Quantum Defense Industries, a specialized defense contractor with 6,500+ employees supporting classified aerospace programs, deployed a new secure software development environment for processing CONFIDENTIAL and SECRET program data across 8 hardened facilities. The Information Security team implemented strict media use controls per MP-7 by providing organization-issued encrypted portable drives with hardware-based authentication for approved development teams, implementing Group Policy Objects that disable write capabilities to all removable media on sensitive development systems unless specifically documented and authorized, deploying physical USB port blockers on all workstations processing classified source code, and maintaining a comprehensive inventory of all approved portable storage devices with quarterly audits to ensure accountability and prevent use of unidentifiable devices. The procurement division sourced exclusively NSA-approved information assurance products per SA-4.6, including GOTS secure communications systems from the Secure Communications Interoperability Protocol (SCIP) family for voice and data transmission, COTS network encryption appliances validated through NSA's National Information Assurance Partnership (NIAP) Common Criteria evaluation process with current certificates maintained and tracked, and implementing NSA Suite B cryptographic algorithms for all classified data protection with approved key management infrastructure that meets Federal Information Processing Standards (FIPS) 140-2 Level 4 requirements. The development team applied minimized sharing principles per SA-8.6 by isolating development environments through virtualization with explicit approval documentation for each shared resource including version control repositories and build servers, conducting mandatory security reviews for all instances of global variable usage in classified software modules, implementing mutex-protected reentrant functions for essential shared memory access, and deploying comprehensive covert channel analysis including statistical timing analysis and memory allocation monitoring to prevent information leakage between classification levels. Physical security implemented access control vestibules per PE-3.8 at all R&D laboratories and secure development areas using card-reader authenticated interlocking systems that maintain door separation for maximum 12 seconds during normal operation, weight-sensitive floor sensors that detect tailgating attempts and trigger security alerts within 20 seconds, detailed audit logging of all vestibule transactions including entry/exit timestamps and anomaly detection, and fail-safe emergency egress mechanisms that unlock all doors within 2 seconds during emergency conditions while maintaining video surveillance and incident logging capabilities.\\n\\nPolicies referenced: policy_SA-8.6, policy_PE-3.8, policy_MP-7, policy_SA-4.6\",\n",
      "    \"is-compliant\": true,\n",
      "    \"non-compliant-reason\": \"\"\n",
      "  },\n",
      "  {\n",
      "    \"scenario-id\": \"scenario-id-7\",\n",
      "    \"scenario-detail\": \"CyberTech Solutions, a federal contractor with 3,200 employees managing sensitive government data, implemented comprehensive information disposal procedures across their enterprise infrastructure supporting multiple agency contracts. The Chief Information Security Officer established detailed data classification schemes with retention periods ranging from 3 years for operational logs to 25 years for contract documentation, with all disposal techniques documented per NIST 800-88 guidelines including cryptographic erasure for SSDs, degaussing for magnetic media, and physical destruction for high-sensitivity storage devices. The organization maintains active system of records notices covering employee background investigation data, with routine uses published for sharing information with OPM, FBI, and contracting agencies for security clearance processing, with the Privacy Officer conducting comprehensive annual reviews in March 2024 validating all routine uses remain compatible with original collection purposes and documenting findings in detailed assessment reports. The enterprise risk management strategy addresses both security and privacy risks through a mature risk executive function led by the Chief Risk Officer, with explicit risk tolerance statements, standardized NIST RMF assessment methodologies, and quarterly risk monitoring processes consistently implemented across all 12 business units with full integration into annual budget planning cycles. Physical and environmental protection policies developed by the designated PE Policy Official address purpose, scope, roles, responsibilities, management commitment, and coordination requirements, with comprehensive procedures disseminated to all facility managers and security personnel, reviewed annually in January, and updated following any security incidents or regulatory changes. The Records Management team identified that employee background investigation files for 847 departed contractors reached their 7-year retention period expiration on October 15, 2024, and initiated secure disposal procedures using NIST 800-88 compliant cryptographic erasure with certificates of destruction, completing the disposal process on December 22, 2024, with all activities logged including timestamps, data descriptions, disposal methods, and responsible parties in the enterprise disposal tracking system.\\n\\nPolicies referenced: policy_SI-12.3, policy_PT-6, policy_PM-9, policy_PE-1\",\n",
      "    \"is-compliant\": false,\n",
      "    \"non-compliant-reason\": \"This scenario violates SI-12.3 RULE-02 which requires information disposal to occur within 30 days after the established retention period expires. The retention period expired on October 15, 2024, but disposal was not completed until December 22, 2024, which is 68 days after expiration, exceeding the required 30-day timeframe.\"\n",
      "  },\n",
      "  {\n",
      "    \"scenario-id\": \"scenario-id-8\",\n",
      "    \"scenario-detail\": \"DataSecure Corporation, a healthcare technology company with 5,800 employees processing protected health information for 200+ hospital systems nationwide, maintains comprehensive privacy and security programs supporting HIPAA compliance and federal research contracts. The organization established detailed information disposal procedures with NIST 800-88 compliant destruction methods, completing all disposal activities within 25 days of retention period expiration with full certificates of destruction and comprehensive logging of all disposal activities including timestamps, data descriptions, and responsible parties. The Privacy Officer manages multiple system of records notices for research participant data, clinical trial information, and employee records, with all routine uses properly published and compatibility assessments conducted by qualified privacy professionals to ensure disclosures align with original collection purposes, with comprehensive documentation maintained for all review activities and SORN updates completed within 60 days of any identified issues. The Chief Risk Officer developed a comprehensive enterprise risk management strategy addressing security and privacy risks to operations, assets, individuals, and partner organizations, with explicit risk tolerance statements, standardized assessment methodologies based on NIST frameworks, continuous monitoring processes, and full integration with strategic planning and budget cycles through a mature risk executive function consistently implemented across all business units. Physical and environmental protection policies comprehensively address purpose, scope, roles, responsibilities, management commitment, and coordination requirements, developed by the designated PE Policy Official with regular dissemination to all personnel with PE responsibilities and timely reviews conducted annually and following triggering events with appropriate updates to maintain regulatory compliance. However, the organization's routine use review process for their primary research participant system of records notice was last conducted in November 2022, and despite the system remaining active with ongoing routine use disclosures to research partners, NIH, and FDA for clinical trial oversight purposes, no subsequent review has been performed due to resource constraints and competing privacy priorities, with the next scheduled review planned for Q2 2025 pending budget approval for additional privacy staff.\\n\\nPolicies referenced: policy_SI-12.3, policy_PT-6, policy_PM-9, policy_PE-1\",\n",
      "    \"is-compliant\": false,\n",
      "    \"non-compliant-reason\": \"This scenario violates PT-6(1) RULE-01 which requires all routine uses published in system of records notices to be reviewed at least annually. The last review was conducted in November 2022, and with the current date being well beyond November 2023, this exceeds the 365-day maximum review period while the system remains active.\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff8371d-106d-4893-bcdb-965bef86e4d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c22ff17-b692-4612-b2ce-785abdec9713",
   "metadata": {},
   "source": [
    "# GenerateScenarios\n",
    "This notebook generates realistic compliance scenarios by leveraging AWS Bedrock's Retrieval-Augmented Generation (RAG) capabilities using the NIST control framework and specific organizational policies generated against that framework. It generates 1,000 (500 compliant, 500 non-compliant) complex, multi-policy scenarios that simulate real-world compliance situations (like employee onboarding, data access requests, or security incidents).\n",
    "\n",
    " - Generates Scenario Batches - Uses Bedrock's Converse API with RAG to create realistic compliance scenarios by alternating between compliant and non-compliant cases.  For each batch of scenarios, it retrieves policy context by querying AWS Bedrock Knowledge Base containing NIST controls and policies.\n",
    " - Structures Output - Forces JSON format output with specific schema including scenario ID, detailed description, compliance status, and violation reasons.\n",
    " - Multi-Policy Coverage - Each scenario incorporates multiple policies to create complex, realistic compliance evaluation situations.\n",
    "\n",
    "```\n",
    "Execution Flow:\n",
    "└── main()\n",
    "    ├── generate_compliance_scenarios()\n",
    "    │   ├── retrieve_kb_context()\n",
    "    │   │   └── bedrock_agent_runtime.retrieve()\n",
    "    │   └── generate_scenario_batch()\n",
    "    │       └── bedrock_runtime.converse()\n",
    "    ├── save_scenarios_to_file()\n",
    "    └── save_scenarios_to_s3()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "execution_state": "idle",
   "id": "6b008304-8133-4539-b75f-b66534b07807",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T15:04:26.670327Z",
     "iopub.status.busy": "2026-01-09T15:04:26.670001Z",
     "iopub.status.idle": "2026-01-09T15:04:26.697433Z",
     "shell.execute_reply": "2026-01-09T15:04:26.695754Z",
     "shell.execute_reply.started": "2026-01-09T15:04:26.670301Z"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "BUCKET = '183023889407-us-east-1-compliance-rule-generator'\n",
    "S3_PREFIX_POLICY_MARKDOWN_ALL = 'policies/markdown/all-policies-main/'\n",
    "OUTPUT_PREFIX = 'scenarios/'  # Folder path for results\n",
    "KNOWLEDGE_BASE_ID = 'T8EW10IU3Z'  # AWS Bedrock Knowledge Base containing NIST policies\n",
    "# Available Bedrock model ARNs with performance notes\n",
    "MODELS = {\n",
    "    'premium': 'arn:aws:bedrock:us-east-1:183023889407:inference-profile/global.anthropic.claude-opus-4-5-20251101-v1:0', # not available\n",
    "    'good': 'arn:aws:bedrock:us-east-1:183023889407:inference-profile/global.anthropic.claude-sonnet-4-5-20250929-v1:0', # times out\n",
    "    'balanced': 'arn:aws:bedrock:us-east-1:183023889407:inference-profile/us.anthropic.claude-sonnet-4-20250514-v1:0',  # recommended\n",
    "    'fast_cheap': 'arn:aws:bedrock:us-east-1:183023889407:inference-profile/us.anthropic.claude-haiku-4-5-20251001-v1:0',\n",
    "    'aws_native_premier': 'arn:aws:bedrock:us-east-1:183023889407:inference-profile/us.amazon.nova-premier-v1:0',\n",
    "    'aws_native_pro': 'arn:aws:bedrock:us-east-1:183023889407:inference-profile/us.amazon.nova-pro-v1:0'\n",
    "}\n",
    "MODEL_ARN = MODELS['good']  # Default model selection\n",
    "SCENARIOS_PER_BATCH = 2\n",
    "NUM_BATCHES = 4\n",
    "TOTAL_SCENARIOS = SCENARIOS_PER_BATCH * NUM_BATCHES\n",
    "POLICIES_PER_SCENARIO = 4\n",
    "\n",
    "# JSON tool configuration for Bedrock Converse API\n",
    "# Forces the model to return structured JSON with specific schema\n",
    "TOOL_CONFIG = {\n",
    "    \"tools\": [{\n",
    "        \"toolSpec\": {\n",
    "            \"name\": \"scenario_json\",\n",
    "            \"description\": \"Return compliance scenarios as JSON\",\n",
    "            \"inputSchema\": {\n",
    "                \"json\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"scenarios\": {  # Array of scenario objects\n",
    "                            \"type\": \"array\",\n",
    "                            \"items\": {\n",
    "                                \"type\": \"object\",\n",
    "                                \"properties\": {\n",
    "                                    \"scenario-id\": {\"type\": \"string\"},      # Format: scenario-id-1, scenario-id-2, etc.\n",
    "                                    \"scenario-detail\": {\"type\": \"string\"},  # Detailed scenario description (200+ words)\n",
    "                                    \"is-compliant\": {\"type\": \"boolean\"},     # True if compliant, False if non-compliant\n",
    "                                    \"non-compliant-reason\": {\"type\": \"string\"}  # If non-compliant, why? Which policy(s) were violated?\n",
    "                                },\n",
    "                                \"required\": [\"scenario-id\", \"scenario-detail\", \"is-compliant\"]\n",
    "                            }\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"scenarios\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }],\n",
    "    \"toolChoice\": {\"tool\": {\"name\": \"scenario_json\"}}  # Force use of the JSON tool\n",
    "}\n",
    "\n",
    "# Initialize AWS Bedrock clients\n",
    "bedrock_agent_runtime = boto3.client('bedrock-agent-runtime', region_name='us-east-1')  # For knowledge base retrieval\n",
    "bedrock_runtime = boto3.client('bedrock-runtime', region_name='us-east-1')  # For model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "execution_state": "idle",
   "id": "6bdc29ec-8ace-4cca-abb9-0139668e1bb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T15:04:27.026621Z",
     "iopub.status.busy": "2026-01-09T15:04:27.025693Z",
     "iopub.status.idle": "2026-01-09T15:04:27.044853Z",
     "shell.execute_reply": "2026-01-09T15:04:27.039592Z",
     "shell.execute_reply.started": "2026-01-09T15:04:27.026589Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_scenario_batch(\n",
    "    policies: str,\n",
    "    policy_ids: str,\n",
    "    batch_num: int,\n",
    "    model_arn: str,\n",
    "    scenarios_per_batch: int=SCENARIOS_PER_BATCH\n",
    ") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Generate one batch of compliance scenarios using Bedrock Converse API.\n",
    "    This function creates realistic compliance scenarios by alternating between\n",
    "    compliant and non-compliant scenarios across batches. Uses the JSON tool\n",
    "    to ensure structured output.\n",
    "    Args:\n",
    "        policies: Combined policy text from knowledge base\n",
    "        batch_num: Current batch number (0-indexed)\n",
    "        model_arn: AWS Bedrock model ARN or ID\n",
    "        scenarios_per_batch: Number of scenarios per batch\n",
    "    Returns:\n",
    "        List of scenario dictionaries with keys: scenario-id, scenario-detail, is-compliant, non-compliant-reason\n",
    "    \"\"\"\n",
    "    # Alternate between compliant (even batches) and non-compliant (odd batches) scenarios\n",
    "    is_compliant = batch_num % 2 == 0\n",
    "    \n",
    "    # Calculate starting ID for consecutive numbering across all batches\n",
    "    start_id = batch_num * scenarios_per_batch + 1\n",
    "    \n",
    "    # Construct detailed prompt with all policy context and specific requirements\n",
    "    prompt = f\"\"\"Based on NIST compliance policies under **KNOWLEDGE BASE CONTEXT**, generate {scenarios_per_batch} realistic compliance scenario (scenario-details) \n",
    "    that are \n",
    "    {'compliant' if is_compliant else 'non-compliant.  Ensure that only one underlying policy is violated out of all the underlying policies for each scenario. Use no leading language like \"however\" or tone to indicate in any way that the scenarios is in any way invalid.  Try to trick the reader to believe it is valid.'}.\n",
    "    \n",
    "    Each scenario-detail must:\n",
    "    - Use all policies from KNOWLEDGE BASE CONTEXT context below\n",
    "    - Include specific business details (roles, systems, data, actions)\n",
    "    - Be realistic and detailed (200+ words)\n",
    "    - Have scenario-id format: scenario-id-{start_id}, scenario-id-{start_id+1}, etc.\n",
    "\n",
    "    **Avoid generating scenarios based on cost-benefit principles or concentration percentages.\n",
    "    \n",
    "    **Note that non-US citizens cannot obtain US security clearances.**\n",
    "    \n",
    "    Return as JSON array with fields: scenario-id, scenario-detail, is-compliant, non-compliant-reason\n",
    "    {'leave non-compliant-reason empty' if is_compliant else 'For non-compliant-reason, provide an explanation of exactly why the scenario is non-compliant, including which policy(s) were violated.'}\n",
    "\n",
    "    **Here is an example of scenario-detail:**\n",
    "    SecureDefense Corporation, a defense contractor with 8,500+ employees supporting classified government projects, is deploying a new secure development environment\n",
    "    for processing TOP SECRET/SCI information across 12 secure facilities. The Chief Security Officer implemented citizenship requirements per MA-5.3 ensuring all\n",
    "    personnel performing maintenance on classified systems are verified U.S. citizens with current documentation including birth certificates, passports, and security\n",
    "    clearance validation, with emergency maintenance procedures explicitly prohibiting non-citizen access under any circumstances. The organization deployed NIAP-approved\n",
    "    protection profiles per SA-4.7 for all commercial security products including firewalls evaluated against Network Device Protection Profile v2.2, VPN solutions meeting\n",
    "    IPsec Virtual Private Network (VPN) Client Protection Profile v1.0, and database management systems validated against Database Management System Protection Profile v4.0,\n",
    "    with FIPS 140-2 Level 3 validated cryptographic modules for products without applicable NIAP profiles. The system architecture team implemented hierarchical protection\n",
    "    per SA-8.12 with hypervisor components at highest trust level protecting against guest VMs, classified application containers at medium trust level isolated from\n",
    "    development tools, and development interfaces at lowest trust level with comprehensive access controls preventing privilege escalation across trust boundaries. The\n",
    "    procurement team maintained technology diversity per SC-29 across the secure development pipeline using Red Hat and SUSE Linux distributions (45% and 35% respectively),\n",
    "    Dell and HPE hardware platforms, and Raytheon and General Dynamics security appliances to minimize supply chain concentration risks. Cost-benefit analyses per SA-8.25\n",
    "    documented security investments of $4.2M annually justified by protecting classified intellectual property valued at $2.8B and avoiding potential contract termination\n",
    "    penalties exceeding $150M for security violations.\n",
    "\n",
    "    **KNOWLEDGE BASE CONTEXT**\n",
    "    {policies}\n",
    "    \"\"\"\n",
    "    # Extract model ID from ARN (Converse API requires model ID, not full ARN)\n",
    "    model_id = model_arn.split('/')[-1] if '/' in model_arn else model_arn\n",
    "    \n",
    "    # Call Bedrock Converse API with JSON tool enforcement\n",
    "    response = bedrock_runtime.converse(\n",
    "        modelId=model_id,\n",
    "        messages=[{\"role\": \"user\", \"content\": [{\"text\": prompt}]}],\n",
    "        toolConfig=TOOL_CONFIG,  # Forces structured JSON output\n",
    "        inferenceConfig={\"maxTokens\": 4096, \"temperature\": 0.7}  # Allow creative but controlled generation, about 3,000 words max\n",
    "    )\n",
    "    \n",
    "    # Extract scenarios from tool use response\n",
    "    if response.get('stopReason') == 'tool_use':\n",
    "        for content_block in response['output']['message']['content']:\n",
    "            if 'toolUse' in content_block:\n",
    "                scenarios_data = content_block['toolUse']['input']\n",
    "                scenarios = scenarios_data.get('scenarios', [])\n",
    "                for scenario in scenarios:\n",
    "                    scenario['scenario-detail'] += f\"\\n\\nPolicies referenced: {policy_ids}\"\n",
    "                return scenarios\n",
    "    \n",
    "    # Return empty list if no tool use or scenarios found\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "execution_state": "idle",
   "id": "57b41f28-b131-413b-be13-370ed0246637",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T15:04:27.301544Z",
     "iopub.status.busy": "2026-01-09T15:04:27.301139Z",
     "iopub.status.idle": "2026-01-09T15:04:27.310902Z",
     "shell.execute_reply": "2026-01-09T15:04:27.309335Z",
     "shell.execute_reply.started": "2026-01-09T15:04:27.301507Z"
    }
   },
   "outputs": [],
   "source": [
    "def retrieve_s3_policies(bucket: str = BUCKET, policies_per_scenario: int = POLICIES_PER_SCENARIO) -> Tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Retrieve random policy documents from S3 bucket.\n",
    "    \"\"\"\n",
    "    s3 = boto3.client('s3')\n",
    "    \n",
    "    # List all policy files\n",
    "    response = s3.list_objects_v2(\n",
    "        Bucket=bucket,\n",
    "        Prefix=S3_PREFIX_POLICY_MARKDOWN_ALL\n",
    "    )\n",
    "    \n",
    "    policy_files = [obj['Key'] for obj in response.get('Contents', []) \n",
    "                   if obj['Key'].endswith('.md')]\n",
    "    \n",
    "    # Randomly select needed number of policies\n",
    "    selected_files = random.sample(policy_files, min(policies_per_scenario, len(policy_files)))\n",
    "    \n",
    "    # Read selected policy contents\n",
    "    policies = []\n",
    "    policy_ids = []\n",
    "    for file_key in selected_files:\n",
    "        obj = s3.get_object(Bucket=bucket, Key=file_key)\n",
    "        content = obj['Body'].read().decode('utf-8')\n",
    "        policies.append(content)\n",
    "        policy_ids.append(re.search(r\"POLICY: ([A-Z]+-[\\d.]+)\", content).group(1))\n",
    "            \n",
    "    print(f\"Retrieved {len(policies)} random policies from S3\")\n",
    "    return '\\n\\n'.join(policies), ', '.join(policy_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "execution_state": "idle",
   "id": "11aec7fa-498b-436f-8b4e-30961c28bc88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T15:04:27.610645Z",
     "iopub.status.busy": "2026-01-09T15:04:27.610265Z",
     "iopub.status.idle": "2026-01-09T15:04:27.618699Z",
     "shell.execute_reply": "2026-01-09T15:04:27.617286Z",
     "shell.execute_reply.started": "2026-01-09T15:04:27.610609Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_compliance_scenarios(\n",
    "    knowledge_base_id: str = KNOWLEDGE_BASE_ID,\n",
    "    model_arn: str = MODEL_ARN,\n",
    "    scenarios_per_batch: int=SCENARIOS_PER_BATCH,\n",
    "    policies_per_scenario: int=POLICIES_PER_SCENARIO,\n",
    "    total_scenarios: int = TOTAL_SCENARIOS\n",
    ") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Main orchestrator function for generating compliance scenarios.\n",
    "    \n",
    "    This function coordinates the entire scenario generation process:\n",
    "    1. Retrieves comprehensive policy context from knowledge base (once)\n",
    "    2. Generates scenarios in batches to manage API limits and costs\n",
    "    3. Alternates between compliant and non-compliant scenarios\n",
    "    4. Implements rate limiting to avoid API throttling\n",
    "    Args:\n",
    "        knowledge_base_id: AWS Bedrock Knowledge Base ID\n",
    "        model_arn: AWS Bedrock model ARN to use for generation\n",
    "        scenarios_per_batch: Number of scenarios per batch\n",
    "        policies_per_scenario: Number of NIST policies to use in creating a scenario\n",
    "        total_scenarios: Total number of scenarios to generate\n",
    "    Returns:\n",
    "        List of all generated scenario dictionaries\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate scenarios in batches\n",
    "    all_scenarios = []\n",
    "    for batch_num in range(total_scenarios // scenarios_per_batch):\n",
    "      # Retrieve all policy context once (reused across all batches)\n",
    "        try:\n",
    "            policies, policy_ids = retrieve_s3_policies(BUCKET, policies_per_scenario)\n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving from KB: {e}\")\n",
    "            return []\n",
    "        try:\n",
    "            # Generate one batch of scenarios          \n",
    "            scenarios = generate_scenario_batch(policies, policy_ids, batch_num, model_arn, scenarios_per_batch)\n",
    "            all_scenarios.extend(scenarios)\n",
    "            print(f\"Batch {batch_num + 1}: Generated {len(scenarios)} scenarios\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating scenario batch {batch_num + 1}: {e}\")\n",
    "            continue  # excplicit to go to next scenario, maybe this was a temporary glitch\n",
    "        \n",
    "        # Rate limiting: pause between batches to avoid API throttling\n",
    "        time.sleep(2)\n",
    "    \n",
    "    return all_scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "execution_state": "idle",
   "id": "8712a78b-70a0-4f46-9fbc-0b8b6e5a16cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T15:04:28.005835Z",
     "iopub.status.busy": "2026-01-09T15:04:28.005447Z",
     "iopub.status.idle": "2026-01-09T15:04:28.012655Z",
     "shell.execute_reply": "2026-01-09T15:04:28.010689Z",
     "shell.execute_reply.started": "2026-01-09T15:04:28.005801Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_scenarios_to_file(scenarios: List[Dict], output_path: str):\n",
    "    \"\"\"\n",
    "    Save generated scenarios to a JSON file with metadata.\n",
    "    \n",
    "    Creates a structured JSON file containing:\n",
    "    - Summary statistics (total, compliant, non-compliant counts)\n",
    "    - All generated scenarios\n",
    "    \"\"\"\n",
    "    # Print scenarios to console for immediate review\n",
    "    print(json.dumps(scenarios, indent=2))\n",
    "    \n",
    "    # Save to file with metadata and statistics\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump({\n",
    "            'total_scenarios': len(scenarios),\n",
    "            'compliant_count': sum(1 for s in scenarios if s['is-compliant']),\n",
    "            'non_compliant_count': sum(1 for s in scenarios if not s['is-compliant']),\n",
    "            'scenarios': scenarios\n",
    "        }, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "execution_state": "idle",
   "id": "2149410b-8800-4e63-83f1-9b9cda20743c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T15:04:28.295513Z",
     "iopub.status.busy": "2026-01-09T15:04:28.294598Z",
     "iopub.status.idle": "2026-01-09T15:04:28.302067Z",
     "shell.execute_reply": "2026-01-09T15:04:28.300185Z",
     "shell.execute_reply.started": "2026-01-09T15:04:28.295480Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_scenarios_to_s3(scenarios: List[Dict], output_bucket: str = BUCKET, output_prefix: str = OUTPUT_PREFIX, object_name: str = \"scenarios.json\"):\n",
    "    \"\"\"\n",
    "    Save generated scenarios to a S3.\n",
    "\n",
    "    \"\"\"\n",
    "    s3 = boto3.client('s3')\n",
    "    json_data = json.dumps({\"scenarios\": scenarios}, indent=2)\n",
    "    s3.put_object(Bucket=output_bucket, Key=output_prefix+object_name, Body=json_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "execution_state": "idle",
   "id": "034d84a6-9c5f-446e-a1ce-5912d269b599",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T15:30:31.637992Z",
     "iopub.status.busy": "2026-01-09T15:30:31.637376Z",
     "iopub.status.idle": "2026-01-09T15:30:31.651045Z",
     "shell.execute_reply": "2026-01-09T15:30:31.648969Z",
     "shell.execute_reply.started": "2026-01-09T15:30:31.637948Z"
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Example usage: Generate 4 scenarios in 2 batches of 2 each\n",
    "    # Batch 0 (even): compliant scenarios with IDs scenario-id-1, scenario-id-2\n",
    "    # Batch 1 (odd): non-compliant scenarios with IDs scenario-id-3, scenario-id-4\n",
    "    scenarios = generate_compliance_scenarios(\n",
    "        knowledge_base_id=KNOWLEDGE_BASE_ID,\n",
    "        model_arn=MODELS['balanced'],\n",
    "        scenarios_per_batch=SCENARIOS_PER_BATCH,\n",
    "        policies_per_scenario=POLICIES_PER_SCENARIO,\n",
    "        total_scenarios=TOTAL_SCENARIOS \n",
    "    )\n",
    "\n",
    "    save_scenarios_to_file(scenarios, '/home/sagemaker-user/scenarios.json')\n",
    "    save_scenarios_to_s3(scenarios, BUCKET, OUTPUT_PREFIX, \"scenarios.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "execution_state": "idle",
   "id": "a3c8d612-ad8e-4bc2-b653-ac967d5e712e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T15:32:15.060893Z",
     "iopub.status.busy": "2026-01-09T15:32:15.060489Z",
     "iopub.status.idle": "2026-01-09T15:33:42.775593Z",
     "shell.execute_reply": "2026-01-09T15:33:42.773373Z",
     "shell.execute_reply.started": "2026-01-09T15:32:15.060858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 4 random policies from S3\n",
      "Batch 1: Generated 2 scenarios\n",
      "Retrieved 4 random policies from S3\n",
      "Batch 2: Generated 2 scenarios\n",
      "Retrieved 4 random policies from S3\n",
      "Batch 3: Generated 2 scenarios\n",
      "Retrieved 4 random policies from S3\n",
      "Batch 4: Generated 2 scenarios\n",
      "[\n",
      "  {\n",
      "    \"scenario-id\": \"scenario-id-1\",\n",
      "    \"scenario-detail\": \"CyberGuard Defense Systems, a defense contractor with 6,200+ employees supporting unclassified national security projects, is implementing a comprehensive security monitoring infrastructure across 15 geographically distributed facilities. The Chief Information Security Officer established behavior analysis capabilities per IR-4.13 with SOC analysts conducting systematic monitoring of anomalous behavior patterns across production environments including classified development systems, secure communication networks, and threat intelligence platforms, with automated detection systems triggering analysis within 2 hours of anomalous activity detection in production systems and comprehensive documentation of targeted resources, timing patterns, and correlation with known adversarial tactics, techniques, and procedures integrated into threat intelligence feeds within 24 hours of analysis completion. The network security team implemented protocol validation controls per SC-7.23 across all boundary protection devices including Cisco ASA firewalls, F5 load balancers, and Palo Alto Networks intrusion prevention systems configured to suppress detailed error messages and return only generic responses for protocol format validation failures from external sources, with debugging modes explicitly disabled on all production boundary systems and quarterly reviews of approved exceptions for legitimate security testing activities. The infrastructure team deployed redundant time synchronization per SC-45.2 with primary authoritative time sources located in Colorado Springs and secondary sources in Norfolk, Virginia (1,200+ miles separation) providing automatic failover within 3 minutes of primary source unavailability, continuous monitoring of time drift maintaining accuracy within 500 milliseconds for security-critical systems and 15 seconds for standard systems, with geolocation verification documented annually and comprehensive logging of all synchronization events. The network architecture team enforced boundary protection per SC-7.25 ensuring all unclassified national security systems connect to external networks exclusively through approved Juniper SRX firewalls and Fortinet FortiGate security appliances with mandatory traffic mediation, deep packet inspection capabilities, and strict prohibition of direct connections or bypass mechanisms, with continuous monitoring detecting and immediately isolating any unauthorized connection attempts to maintain complete network isolation for sensitive defense contractor operations.\\n\\nPolicies referenced: IR-4.13, SC-7.23, SC-45.2, SC-7.25\",\n",
      "    \"is-compliant\": true,\n",
      "    \"non-compliant-reason\": \"\"\n",
      "  },\n",
      "  {\n",
      "    \"scenario-id\": \"scenario-id-2\",\n",
      "    \"scenario-detail\": \"SecureNet Technologies, a government contractor with 4,800+ employees supporting critical infrastructure protection initiatives, deployed an integrated security operations center managing unclassified national security systems across 22 facilities nationwide. The incident response team implemented comprehensive behavior analysis per IR-4.13 with threat intelligence analysts conducting daily analysis of deception environment activities including honeypots, network decoys, and canary tokens to identify adversarial reconnaissance patterns, lateral movement attempts, and data exfiltration techniques, with structured analysis methodology examining targeted resources within production environments, timing correlation analysis identifying attack patterns, and integration of behavioral findings into MITRE ATT&CK framework mappings completed within 36 hours of analysis completion for enhanced threat hunting capabilities. The cybersecurity team configured boundary protection systems per SC-7.23 including Check Point quantum firewalls, Barracuda web application firewalls, and McAfee network security platforms with protocol validation configured to disable sender feedback mechanisms, preventing disclosure of system configuration details, version information, or stack traces to external attackers while maintaining generic error responses for all protocol format validation failures and documented exception management processes for authorized penetration testing activities requiring detailed feedback with quarterly security architecture team reviews. The systems administration team established geographically redundant time synchronization per SC-45.2 utilizing primary time sources in San Antonio, Texas and secondary sources in Boston, Massachusetts (1,500+ miles separation) with Network Time Protocol servers configured for automatic failover within 4 minutes, continuous monitoring maintaining time accuracy within 800 milliseconds for security monitoring systems and 20 seconds for administrative systems, with automated alerting for synchronization failures and annual verification of geographic separation using updated geolocation databases. The network operations center enforced strict boundary controls per SC-7.25 ensuring all unclassified national security systems utilize mandatory boundary protection through Cisco Firepower threat defense appliances and Sophos XG firewalls with comprehensive traffic mediation, application-layer inspection, and zero-tolerance policies for direct external network connections, including cloud service access through approved security gateways with encrypted tunnels and continuous compliance monitoring preventing unauthorized network bypass attempts across the entire infrastructure supporting critical government operations.\\n\\nPolicies referenced: IR-4.13, SC-7.23, SC-45.2, SC-7.25\",\n",
      "    \"is-compliant\": true,\n",
      "    \"non-compliant-reason\": \"\"\n",
      "  },\n",
      "  {\n",
      "    \"scenario-id\": \"scenario-id-3\",\n",
      "    \"scenario-detail\": \"TechGlobal Financial Services, a multinational banking corporation with 15,000+ employees across 45 countries, is implementing a comprehensive digital transformation initiative to modernize their core banking platform and customer-facing applications. The Chief Technology Officer has established a robust mission and business process definition framework per PM-11 requirements, with all 23 business units formally documenting their processes including explicit security and privacy considerations, comprehensive risk assessments covering operations, assets, individuals, and national implications, and detailed information protection needs determination through organizational risk management processes. The cybersecurity team deployed state-of-the-art automated integrity monitoring systems per SI-7.2 across all production environments, utilizing NIST-compliant tools that continuously monitor system files, configurations, and data integrity with immediate notification capabilities configured to alert designated personnel within 8 minutes of detecting any discrepancies, including system owners, information security officers, and system administrators through redundant delivery mechanisms including encrypted email, SMS, and secure messaging platforms. The enterprise architecture team implemented a sophisticated defense-in-depth strategy per PL-8.1 with controls strategically allocated across network perimeter (firewalls, IPS), application layer (WAF, code analysis), data layer (encryption, DLP), and endpoint protection (EDR, device controls), with all controls tested for coordination and mutual reinforcement to prevent adverse consequences and ensure comprehensive protection of high-value financial assets. The vulnerability management program per RA-5 conducts automated SCAP-compliant scanning bi-weekly across all 2,847 systems and applications, with critical vulnerabilities (CVSS 9.0-10.0) remediated within 48 hours, high vulnerabilities within 21 days, and comprehensive analysis completed within 3 business days of scan completion. However, during the recent quarterly business process review, the privacy team discovered that the new customer onboarding workflow processes personally identifiable information from 12 different data sources but the privacy risk assessment was scheduled for completion next quarter due to resource constraints.\\n\\nPolicies referenced: PM-11, SI-7.2, PL-8.1, RA-5\",\n",
      "    \"is-compliant\": false,\n",
      "    \"non-compliant-reason\": \"This scenario violates PM-11 RULE-03 which requires that PII processing needs arising from defined mission and business processes MUST be identified, assessed for privacy risks, and documented. The customer onboarding workflow is actively processing PII from multiple sources without a completed privacy risk assessment, creating a compliance violation despite all other policies being properly implemented.\"\n",
      "  },\n",
      "  {\n",
      "    \"scenario-id\": \"scenario-id-4\",\n",
      "    \"scenario-detail\": \"CyberShield Manufacturing, a leading aerospace defense contractor with 6,200+ employees supporting classified government contracts, has established comprehensive security and compliance programs across their 18 manufacturing facilities and research centers. The organization maintains exemplary mission and business process definition per PM-11 with all operational processes formally documented including security and privacy considerations, annual reviews completed on schedule, information protection needs determined through rigorous risk management processes, and PII processing activities thoroughly assessed with documented privacy risk evaluations integrated into system categorization and control selection processes. The security operations center implemented advanced automated integrity monitoring per SI-7.2 using enterprise-grade tools that provide continuous verification of system files, configurations, and data across all production systems with immediate notifications delivered within 12 minutes to comprehensive distribution lists including system owners, security officers, administrators, and incident response teams through multiple redundant channels ensuring 24/7 coverage. The enterprise security architecture follows strict defense-in-depth principles per PL-8.1 with controls strategically allocated across physical security (biometric access, surveillance), network security (segmentation, monitoring), application security (secure coding, testing), and data protection (classification, encryption) layers, with all controls thoroughly tested for coordination and mutual reinforcement to protect classified intellectual property and manufacturing systems. The vulnerability management program per RA-5 utilizes SCAP-compliant scanning tools with signature updates performed twice weekly, comprehensive scans conducted every 21 days across all 1,456 systems and applications, with critical vulnerabilities remediated within 60 hours, high vulnerabilities within 25 days, and detailed analysis completed within 4 business days of scan completion with results shared immediately with relevant system owners and stakeholders.\\n\\nPolicies referenced: PM-11, SI-7.2, PL-8.1, RA-5\",\n",
      "    \"is-compliant\": false,\n",
      "    \"non-compliant-reason\": \"This scenario violates RA-5 RULE-01 which requires vulnerability scanning MUST be performed at least monthly (every 30 days) for all in-scope systems and applications. The organization is conducting scans every 21 days, which exceeds the maximum 30-day requirement, creating a compliance gap despite excellent performance in all other policy areas.\"\n",
      "  },\n",
      "  {\n",
      "    \"scenario-id\": \"scenario-id-5\",\n",
      "    \"scenario-detail\": \"GlobalTech Financial Services, a multinational banking corporation with 15,000+ employees, is implementing a new cross-domain information exchange system for processing sensitive customer financial data between their high-security trading floor environment and standard corporate network. The Security Architecture team designed transfer processes per AC-4.32 that operate with minimum complexity, ensuring transfer processes do not perform any content filtering while moving encrypted transaction data between security domains, with all filtering operations handled by dedicated filter pipelines at source and destination boundaries. The system validates filtering metadata including transaction classification, destination pipeline routing, and compliance tags before initiating any cross-domain transfers, with automated verification that all content has successfully completed anti-money laundering and fraud detection filtering before transfer to the corporate reporting pipeline. The Identity and Access Management team implemented cached authenticator expiration per IA-5.13 across all 2,400 workstations and mobile devices, with Windows domain-joined systems configured to expire cached credentials after 10 days of no domain controller connectivity, macOS systems bound to Active Directory expiring after 14 days, and mobile devices with high-privilege trading accounts expiring cached credentials within 24 hours regardless of network status. The Business Continuity team conducted comprehensive capacity planning per CP-2.2 for the new financial processing systems, documenting minimum processing capacity requirements of 50,000 transactions per hour during contingency operations, telecommunications bandwidth requirements of 10 Gbps for essential trading communications during degraded operations, and environmental support capacity including backup power systems capable of supporting critical trading operations for 72 hours with validated testing performed quarterly. Development teams structured all security-relevant components per SA-17.7 with least privilege principles, implementing role-based privilege separation where trading floor personnel access only market data functions, compliance officers access only regulatory reporting interfaces, and system administrators access only infrastructure management capabilities, with all modules designed for proper encapsulation and documented privilege decomposition justifying each component's minimum required access rights.\\n\\nPolicies referenced: AC-4.32, IA-5.13, CP-2.2, SA-17.7\",\n",
      "    \"is-compliant\": true,\n",
      "    \"non-compliant-reason\": \"\"\n",
      "  },\n",
      "  {\n",
      "    \"scenario-id\": \"scenario-id-6\",\n",
      "    \"scenario-detail\": \"CyberSecure Healthcare Network, a regional healthcare system with 12,000+ employees operating across 25 medical facilities, is deploying an integrated patient data management system that processes Protected Health Information (PHI) across multiple security domains including clinical networks, administrative systems, and research environments. The Information Security team implemented cross-domain transfer processes per AC-4.32 that maintain minimum complexity while transferring patient records between clinical and administrative domains, with transfer processes designed to validate filtering metadata containing patient consent levels, data classification tags, and HIPAA compliance indicators before initiating transfers, ensuring all PHI content successfully completes privacy filtering and de-identification processes before moving to research pipeline destinations without the transfer processes themselves performing any content modification or filtering operations. The organization deployed cached authenticator management per IA-5.13 across all clinical workstations, nurse stations, and mobile medical devices, configuring domain-joined Windows systems to expire cached credentials after 10 days of no network connectivity, Linux-based medical imaging systems with LDAP authentication to expire cached credentials after 7 days, and mobile devices used by physicians and nurses to expire cached credentials within 24 hours for high-privilege accounts accessing controlled substances databases and patient financial information. The Disaster Recovery team conducted detailed capacity planning per CP-2.2 for the patient data management infrastructure, identifying minimum processing capacity requirements of 25,000 patient record transactions per hour during emergency operations, telecommunications capacity of 5 Gbps bandwidth for essential clinical communications during facility evacuations, and environmental support planning including backup power systems, cooling capacity for server rooms, and space allocation for temporary clinical operations with annual validation testing demonstrating system performance under degraded conditions. The development team structured all healthcare system components per SA-17.7 using least privilege architecture, implementing fine-grained role separation where clinical staff access only patient care functions relevant to their specialty, administrative personnel access only billing and scheduling interfaces, researchers access only de-identified data sets, and IT support staff access only system maintenance functions, with comprehensive documentation demonstrating privilege decomposition and encapsulated module design preventing direct external access to sensitive PHI databases.\\n\\nPolicies referenced: AC-4.32, IA-5.13, CP-2.2, SA-17.7\",\n",
      "    \"is-compliant\": true,\n",
      "    \"non-compliant-reason\": \"\"\n",
      "  },\n",
      "  {\n",
      "    \"scenario-id\": \"scenario-id-7\",\n",
      "    \"scenario-detail\": \"GlobalTech Defense Solutions, a major defense contractor with 12,000+ employees supporting classified government contracts, is implementing a comprehensive media protection program across their 15 secure facilities processing SECRET and TOP SECRET information. The Chief Information Security Officer established a robust critical asset identification program per CP-2.8, conducting formal business impact analysis to identify mission-critical systems including the classified document management system supporting $3.2B in active contracts, the secure communications infrastructure enabling real-time coordination with Pentagon operations, and the intellectual property repository containing proprietary defense technologies. The organization maintains detailed inventories covering both technical assets (servers, network equipment, cryptographic modules) and operational assets (security procedures, cleared personnel, emergency response protocols) with quarterly reviews ensuring currency as new systems are deployed. The IT Operations team implemented comprehensive nonlocal maintenance controls per MA-4, requiring written approval from the Security Control Board for all remote diagnostic activities, employing PKI certificates with hardware tokens for multi-factor authentication, and maintaining continuous monitoring through their Security Operations Center with detailed session logging retained for 18 months. All remote maintenance sessions are immediately terminated upon completion with automated connection cleanup preventing residual access. The organization deployed linear content filter pipelines per AC-4.28 for all cross-domain information transfers between their unclassified development network and classified production environment, implementing non-bypassable filtering architecture with both discretionary access controls based on user clearance levels and mandatory access controls enforcing classification labels, ensuring consistent policy application across all filter stages. However, their media downgrading equipment used for declassifying technical documentation has not undergone testing for the past 14 months, despite the organizationally defined testing frequency of every 12 months, with the Media Protection Officer documenting equipment usage but deferring testing due to operational demands and vendor scheduling conflicts.\\n\\nPolicies referenced: MP-8.2, CP-2.8, MA-4, AC-4.28\",\n",
      "    \"is-compliant\": false,\n",
      "    \"non-compliant-reason\": \"The scenario violates MP-8.2 RULE-03 which requires equipment testing to be conducted according to the defined frequency and SHALL NOT exceed the maximum interval without documented risk acceptance. The media downgrading equipment has not been tested for 14 months, exceeding the 12-month defined frequency, and there is no documented risk acceptance for this delay.\"\n",
      "  },\n",
      "  {\n",
      "    \"scenario-id\": \"scenario-id-8\",\n",
      "    \"scenario-detail\": \"SecureVault Corporation, a financial services company with 6,800+ employees managing classified financial intelligence systems for federal agencies, is deploying advanced security controls across their hybrid cloud infrastructure supporting TOP SECRET/SCI operations. The organization implemented comprehensive critical asset identification per CP-2.8, conducting detailed business impact analysis to identify mission-critical components including their real-time threat intelligence platform processing classified financial data, the secure trading infrastructure supporting $8.7B in daily transactions, and the customer identity management system containing sensitive personal and financial records. The Chief Security Officer maintains current inventories encompassing both technical elements (database clusters, network security appliances, encryption systems) and operational elements (incident response procedures, cleared analyst teams, business continuity protocols) with semi-annual reviews triggered by significant infrastructure changes or new regulatory requirements. The company established rigorous nonlocal maintenance protocols per MA-4, mandating Security Review Board approval for all remote diagnostic activities, implementing RSA SecurID tokens with biometric authentication for vendor access, and deploying continuous session monitoring through their 24/7 Security Operations Center with comprehensive audit trails maintained for 15 months per regulatory requirements. All remote connections are automatically terminated within 5 minutes of maintenance completion using automated scripts preventing unauthorized persistence. The organization deployed sophisticated linear content filter pipelines per AC-4.28 for cross-domain transfers between their commercial banking network and classified intelligence systems, implementing mandatory access controls enforcing strict classification policies and discretionary access controls based on personnel clearance verification, with non-bypassable architecture ensuring all data passes through sequential filtering stages. Their media downgrading equipment undergoes rigorous monthly testing per organizational policy, with the last successful test completed 3 weeks ago and comprehensive documentation maintained by the Media Protection team. However, the critical asset identification process focuses exclusively on technical system components including servers, databases, and network infrastructure, but fails to identify operational aspects such as security procedures, personnel roles, and business processes that support mission and business functions.\\n\\nPolicies referenced: MP-8.2, CP-2.8, MA-4, AC-4.28\",\n",
      "    \"is-compliant\": false,\n",
      "    \"non-compliant-reason\": \"The scenario violates CP-2.8 RULE-02 which requires critical asset identification to include both technical aspects AND operational aspects. While technical assets are properly identified, the scenario explicitly states that operational aspects such as security procedures, personnel roles, and business processes are not included in the critical asset identification process.\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff8371d-106d-4893-bcdb-965bef86e4d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

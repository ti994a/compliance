{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ae2603e-4fea-446e-9216-700fc15171c2",
   "metadata": {},
   "source": [
    "## ScenarioJudger\n",
    "\n",
    " - Reads a file from S3 containing json compliance scenarios of the format:\n",
    "```json\n",
    "{\n",
    "  \"scenarios\": [\n",
    "    {\n",
    "      \"scenario-id\": \"scenario-id-1\",\n",
    "      \"scenario-detail\": \"A new employee, Sarah Johnson, joins the IT department...\",\n",
    "      \"is-compliant\": false,\n",
    "      \"non-compliant-reason\": \"The scenario violates...\" \n",
    "    },\n",
    "    {\n",
    "      \"scenario-id\": \"scenario-id-2\", \n",
    "      \"scenario-detail\": \"TechCorp implements a comprehensive incident response procedure...\",\n",
    "      \"is-compliant\": true,\n",
    "      \"non-compliant-reason\": \"\" \n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    " - Evaluates the veracity each scenario-detail based on RAGed NIST-based policies in Bedrock knowledgebase, comparing its determination against \"is-compliant\" in the json.\n",
    " - When its determination differs, generates json records:\n",
    "```json\n",
    "{\n",
    "  \"scenarios\": [\n",
    "    {\n",
    "      \"scenario-id\": \"scenario-id-1\",\n",
    "      \"scenario-detail\": \"A new employee, Sarah Johnson, joins the IT department...\",\n",
    "      \"is-compliant\": false,\n",
    "      \"non-compliant-reason\": \"The scenario violates...\",\n",
    "      \"judged-compliant\": true,\n",
    "      \"judged-compliant-reason\": \"Considered the rules AC...  and scenario is not in violation...\"\n",
    "      \"llm-judge\": \"us.anthropic.claude-sonnet-4-20250514-v1:0\",\n",
    "      \"judged-dtm\":  \n",
    "    },\n",
    "    {\n",
    "      \"scenario-id\": \"scenario-id-2\", \n",
    "      \"scenario-detail\": \"TechCorp implements a comprehensive incident response procedure...\",\n",
    "      \"is-compliant\": true,\n",
    "      \"non-compliant-reason\": \"\", \n",
    "      \"judged-compliant\": false,\n",
    "      \"judged-compliant-reason\": \"Scenario violates access control policy...\",\n",
    "      \"llm-judge\": \"us.anthropic.claude-sonnet-4-20250514-v1:0\",\n",
    "      \"judged-dtm\":   \n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    " - Stores json records back to S3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "execution_state": "idle",
   "id": "721c6452-39b4-4d10-875f-87c1fb55f2df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T01:19:11.973411Z",
     "iopub.status.busy": "2026-01-12T01:19:11.973068Z",
     "iopub.status.idle": "2026-01-12T01:19:11.992149Z",
     "shell.execute_reply": "2026-01-12T01:19:11.990132Z",
     "shell.execute_reply.started": "2026-01-12T01:19:11.973374Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import boto3  # AWS SDK for Python\n",
    "import datetime\n",
    "import json   # JSON handling\n",
    "import time   # For rate limiting between API calls\n",
    "from compliance_calculator import compliance_calculator, CALCULATOR_TOOL\n",
    "from typing import List, Dict  # Type hints\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION SECTION - Update these values\n",
    "# ============================================================================\n",
    "# S3 Configuration\n",
    "INPUT_BUCKET = '183023889407-us-east-1-compliance-rule-generator'\n",
    "INPUT_PREFIX = 'scenarios/'  # Folder path in S3 where scenarios are stored\n",
    "S3_PREFIX_POLICY_MARKDOWN_ALL = 'policies/markdown/all-policies-main/'\n",
    "\n",
    "OUTPUT_BUCKET = '183023889407-us-east-1-compliance-rule-generator'\n",
    "OUTPUT_PREFIX = 'scenarios-judged/'  # Folder path for results\n",
    "\n",
    "# AWS Region\n",
    "AWS_REGION = 'us-east-1'\n",
    "# AWS Bedrock Knowledge Base containing NIST policies\n",
    "KNOWLEDGE_BASE_ID = 'T8EW10IU3Z'\n",
    "\n",
    "MAX_TOKENS = 4096\n",
    "TEMPERATURE = 0.7\n",
    "\n",
    "# Available Bedrock model ARNs with performance notes\n",
    "MODELS = {\n",
    "    'premium': 'arn:aws:bedrock:us-east-1:183023889407:inference-profile/global.anthropic.claude-opus-4-5-20251101-v1:0', # not available\n",
    "    'good': 'arn:aws:bedrock:us-east-1:183023889407:inference-profile/global.anthropic.claude-sonnet-4-5-20250929-v1:0', # times out\n",
    "    'balanced': 'arn:aws:bedrock:us-east-1:183023889407:inference-profile/us.anthropic.claude-sonnet-4-20250514-v1:0',  # recommended\n",
    "    'fast_cheap': 'arn:aws:bedrock:us-east-1:183023889407:inference-profile/us.anthropic.claude-haiku-4-5-20251001-v1:0',\n",
    "    'aws_native_premier': 'arn:aws:bedrock:us-east-1:183023889407:inference-profile/us.amazon.nova-premier-v1:0',\n",
    "    'aws_native_pro': 'arn:aws:bedrock:us-east-1:183023889407:inference-profile/us.amazon.nova-pro-v1:0'\n",
    "}\n",
    "MODEL_ARN = MODELS['balanced']  # Default model selection\n",
    "\n",
    "# JSON tool configuration for Bedrock Converse API\n",
    "# Forces the model to return structured JSON with specific schema\n",
    "TOOL_CONFIG = {\n",
    "    \"tools\": [\n",
    "        {\n",
    "            \"toolSpec\": {\n",
    "                \"name\": \"judged_scenario_json\",\n",
    "                \"description\": \"Return judged compliance scenarios as JSON\",\n",
    "                \"inputSchema\": {\n",
    "                    \"json\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"scenarios\": {\n",
    "                                \"type\": \"array\",\n",
    "                                \"items\": {\n",
    "                                    \"type\": \"object\",\n",
    "                                    \"properties\": {\n",
    "                                        \"judged-compliant\": {\"type\": \"boolean\"},\n",
    "                                        \"judged-compliant-reason\": {\"type\": \"string\"}\n",
    "                                    },\n",
    "                                    \"required\": [\"judged-compliant\", \"judged-compliant-reason\"]\n",
    "                                }\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"scenarios\"]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"toolSpec\": {\n",
    "                \"name\": \"compliance_calculator\",\n",
    "                \"description\": \"Calculate and compare values with time, money, data, and percentage units\",\n",
    "                \"inputSchema\": {\n",
    "                    \"json\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"expression\": {\"type\": \"string\", \"description\": \"Expression like '800ms < 1s' or '4m > 3b'\"}\n",
    "                        },\n",
    "                        \"required\": [\"expression\"]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "# CALCULATOR_TOOL[\"toolSpec\"] references the calculator tool definition from compliance_calculator.py\n",
    "\n",
    "# Initialize AWS Bedrock clients\n",
    "bedrock_agent_runtime = boto3.client('bedrock-agent-runtime', region_name='us-east-1')  # For knowledge base retrieval\n",
    "bedrock_runtime = boto3.client('bedrock-runtime', region_name='us-east-1')  # For model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "execution_state": "idle",
   "id": "1abdea2c-e311-4358-8b11-3f02472ad8ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T01:19:12.379514Z",
     "iopub.status.busy": "2026-01-12T01:19:12.379183Z",
     "iopub.status.idle": "2026-01-12T01:19:12.385781Z",
     "shell.execute_reply": "2026-01-12T01:19:12.384165Z",
     "shell.execute_reply.started": "2026-01-12T01:19:12.379490Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_scenarios_from_s3(input_bucket: str = INPUT_BUCKET, input_prefix: str = INPUT_PREFIX, object_name: str = \"scenarios.json\") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Load scenarios from S3 JSON file.\n",
    "    \"\"\"\n",
    "    s3 = boto3.client('s3')\n",
    "    response = s3.get_object(Bucket=input_bucket, Key=input_prefix+object_name)\n",
    "    json_data = json.loads(response['Body'].read().decode('utf-8'))\n",
    "    return json_data[\"scenarios\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "execution_state": "idle",
   "id": "fa5e2795-d84a-452f-9dba-a9ede04e259f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T01:19:12.841923Z",
     "iopub.status.busy": "2026-01-12T01:19:12.841606Z",
     "iopub.status.idle": "2026-01-12T01:19:12.848552Z",
     "shell.execute_reply": "2026-01-12T01:19:12.847073Z",
     "shell.execute_reply.started": "2026-01-12T01:19:12.841896Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_scenarios_to_s3(scenarios: List[Dict], output_bucket: str = OUTPUT_BUCKET, output_prefix: str = OUTPUT_PREFIX, object_name: str = \"scenarios.json\"):\n",
    "    \"\"\"\n",
    "    Save generated scenarios to a S3.\n",
    "    \"\"\"\n",
    "    s3 = boto3.client('s3')\n",
    "    json_data = json.dumps({\"scenarios\": scenarios}, indent=2)\n",
    "    s3.put_object(Bucket=output_bucket, Key=output_prefix+object_name, Body=json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "execution_state": "idle",
   "id": "2e937950-914d-4f2e-88bb-0d757125f96a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T01:19:13.301820Z",
     "iopub.status.busy": "2026-01-12T01:19:13.301451Z",
     "iopub.status.idle": "2026-01-12T01:19:13.307875Z",
     "shell.execute_reply": "2026-01-12T01:19:13.306385Z",
     "shell.execute_reply.started": "2026-01-12T01:19:13.301785Z"
    }
   },
   "outputs": [],
   "source": [
    "def retrieve_policies_by_id(bucket:str, folder:str, policy_ids: List[str]) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve specific policy documents from s3.\n",
    "    \"\"\"\n",
    "\n",
    "    s3 = boto3.client('s3')\n",
    "    policies = []\n",
    "    for policy_id in policy_ids:\n",
    "        response = s3.get_object(Bucket=bucket, Key=folder + policy_id + \".md\")\n",
    "        content = response['Body'].read().decode('utf-8')\n",
    "        policies.append(f\"{policy_id}:\\n{content}\")\n",
    "    \n",
    "    return \"\\n\\n\".join(policies)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "execution_state": "idle",
   "id": "new-process-cell",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T01:19:13.849466Z",
     "iopub.status.busy": "2026-01-12T01:19:13.849088Z",
     "iopub.status.idle": "2026-01-12T01:19:13.859357Z",
     "shell.execute_reply": "2026-01-12T01:19:13.858129Z",
     "shell.execute_reply.started": "2026-01-12T01:19:13.849434Z"
    }
   },
   "outputs": [],
   "source": [
    "def judge_scenarios_old(source_scenarios: List[Dict], model_arn: str, kb_id: str = KNOWLEDGE_BASE_ID) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Process scenarios and add judgment fields.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract model ID from ARN (Converse API requires model ID, not full ARN)\n",
    "    model_id = model_arn.split('/')[-1] if '/' in model_arn else model_arn\n",
    "    \n",
    "    judged_scenarios = []\n",
    "    for scenario in source_scenarios:\n",
    "        judged_scenario = scenario.copy()\n",
    "\n",
    "        # Extract policy IDs from scenario and pull the policy data from the knowledge base\n",
    "        import re\n",
    "        policy_match = re.search(r'Policies referenced: (.+)', scenario[\"scenario-detail\"])\n",
    "        if policy_match:\n",
    "            policy_ids = [p.strip() for p in policy_match.group(1).split(',')]\n",
    "            retrieved_policies = retrieve_policies_by_id(policy_ids, kb_id)\n",
    "        else:\n",
    "            print(f\"No policies referenced in scenario: {scenario['scenario-detail']}\")\n",
    "            continue\n",
    "                \n",
    "        prompt = f\"\"\"\n",
    "        You are **ComplianceEvaluator**, an expert AI compliance analyst specializing in NIST 800-53 controls and policies. \n",
    "        Your mission is to judge organizational policy scenarios against reference policies stored in your knowledge base.\n",
    "                \n",
    "        **Your Expertise:**\n",
    "        - Deep understanding of all NIST 800-53 Rev. 5 control families (AC, AT, AU, CA, CM, CP, IA, IR, MA, MP, PE, PL, PM, PS, PT, RA, SA, SC, SI, SR)\n",
    "        - Policy-to-control mapping and compliance evaluation\n",
    "        - Evidence-focused assessment methodology\n",
    "\n",
    "        **Task:** Judge if the scenario complies with ALL referenced policies from your knowledge base.\n",
    "\n",
    "        **Avoid judging scenarios based on cost-benefit principles or concentration percentages.\n",
    "    \n",
    "        **Note that non-US citizens cannot obtain US security clearances.**\n",
    "        \n",
    "        **Response Format:**\n",
    "        {{\n",
    "          \"judged-compliant\": true/false, true if you determined the scenario is compliant with the organizational \n",
    "        policies stored in your knowledge base.  false if the scenario is not compliant.\n",
    "          \"judged-compliant-reason\": \"Empty if compliant. If the scenario is not compliant, explain very briefly why it is not compliant, citing\n",
    "          exactly the policy ID(s) is violates, followed by the extracted policy text that indicates non-compliance.\"\n",
    "        }}\n",
    "\n",
    "        **Evaluate scenario against this policy data**:\n",
    "        {retrieved_policies}\n",
    "\n",
    "        **Here is the actual compliance scenario to judge**:\n",
    "        {scenario[\"scenario-detail\"]}\n",
    "        \"\"\"\n",
    "        response = bedrock_runtime.converse(\n",
    "            modelId=model_id,\n",
    "            messages=[{\"role\": \"user\", \"content\": [{\"text\": prompt}]}],\n",
    "            toolConfig=TOOL_CONFIG,\n",
    "            inferenceConfig={\n",
    "                \"maxTokens\": MAX_TOKENS,\n",
    "                \"temperature\": TEMPERATURE\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        tool_result = response['output']['message']['content'][0]['toolUse']['input']\n",
    "        judged_scenario[\"judged-compliant\"] = tool_result['scenarios'][0]['judged-compliant']\n",
    "        judged_scenario[\"judged-compliant-reason\"] = tool_result['scenarios'][0]['judged-compliant-reason']\n",
    "\n",
    "        judged_scenario[\"llm-judge\"] = MODEL_ARN.split('/')[-1]\n",
    "        judged_scenario[\"judged-dtm\"] = datetime.datetime.now().isoformat()\n",
    "        judged_scenarios.append(judged_scenario)\n",
    "    \n",
    "    return judged_scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "execution_state": "idle",
   "id": "479d12b7-3528-4974-8863-77bf05b82a85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T01:19:14.683316Z",
     "iopub.status.busy": "2026-01-12T01:19:14.682921Z",
     "iopub.status.idle": "2026-01-12T01:19:14.699550Z",
     "shell.execute_reply": "2026-01-12T01:19:14.697127Z",
     "shell.execute_reply.started": "2026-01-12T01:19:14.683284Z"
    }
   },
   "outputs": [],
   "source": [
    "def judge_scenarios(source_scenarios: List[Dict], model_arn: str, kb_id: str = KNOWLEDGE_BASE_ID) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Process scenarios and add judgment fields.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract model ID from ARN (Converse API requires model ID, not full ARN)\n",
    "    model_id = model_arn.split('/')[-1] if '/' in model_arn else model_arn\n",
    "    \n",
    "    judged_scenarios = []\n",
    "    for scenario in source_scenarios:\n",
    "        judged_scenario = scenario.copy()\n",
    "\n",
    "        # Extract policy IDs from scenario and pull the policy data from the knowledge base\n",
    "        import re\n",
    "        policy_match = re.search(r'Policies referenced: (.+)', scenario[\"scenario-detail\"])\n",
    "        if policy_match:\n",
    "            policy_ids = [p.strip() for p in policy_match.group(1).split(',')]\n",
    "            retrieved_policies = retrieve_policies_by_id(INPUT_BUCKET, S3_PREFIX_POLICY_MARKDOWN_ALL, policy_ids)\n",
    "        else:\n",
    "            print(f\"No policies referenced in scenario: {scenario['scenario-detail']}\")\n",
    "            continue\n",
    "                \n",
    "        prompt = f\"\"\"\n",
    "        You are **ComplianceEvaluator**, an expert AI compliance analyst specializing in NIST 800-53 controls and policies. \n",
    "        Your mission is to judge organizational policy scenarios against reference policies stored in your knowledge base.\n",
    "                \n",
    "        **Your Expertise:**\n",
    "        - Deep understanding of all NIST 800-53 Rev. 5 control families (AC, AT, AU, CA, CM, CP, IA, IR, MA, MP, PE, PL, PM, PS, PT, RA, SA, SC, SI, SR)\n",
    "        - Policy-to-control mapping and compliance evaluation\n",
    "        - Evidence-focused assessment methodology\n",
    "\n",
    "        **Task:** Judge if the scenario complies with ALL referenced policies from your knowledge base.\n",
    "\n",
    "        **Avoid judging scenarios based on cost-benefit principles or concentration percentages.\n",
    "    \n",
    "        **Note that non-US citizens cannot obtain US security clearances.**\n",
    "        \n",
    "        **Response Format:**\n",
    "        {{\n",
    "          \"judged-compliant\": true/false, true if you determined the scenario is compliant with the organizational \n",
    "        policies stored in your knowledge base.  false if the scenario is not compliant.\n",
    "          \"judged-compliant-reason\": \"Empty if compliant. If the scenario is not compliant, explain very briefly why it is not compliant, citing\n",
    "          exactly the policy ID(s) is violates, followed by the extracted policy text that indicates non-compliance.\"\n",
    "        }}\n",
    "\n",
    "        **Evaluate scenario against this policy data**:\n",
    "        {retrieved_policies}\n",
    "\n",
    "        **Here is the actual compliance scenario to judge**:\n",
    "        {scenario[\"scenario-detail\"]}\n",
    "        \"\"\"\n",
    "        \n",
    "        messages = [{\"role\": \"user\", \"content\": [{\"text\": prompt}]}]\n",
    "        \n",
    "        while True:\n",
    "            response = bedrock_runtime.converse(\n",
    "                modelId=model_id,\n",
    "                messages=messages,\n",
    "                toolConfig=TOOL_CONFIG,\n",
    "                inferenceConfig={\n",
    "                    \"maxTokens\": MAX_TOKENS,\n",
    "                    \"temperature\": TEMPERATURE\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            if response['stopReason'] == 'tool_use':\n",
    "                tool_results = []\n",
    "                for content_block in response['output']['message']['content']:\n",
    "                    if 'toolUse' in content_block:\n",
    "                        tool_name = content_block['toolUse']['name']\n",
    "                        tool_use_id = content_block['toolUse']['toolUseId']\n",
    "                        \n",
    "                        if tool_name == 'compliance_calculator':\n",
    "                            expression = content_block['toolUse']['input']['expression']                         \n",
    "                            result = compliance_calculator(expression)\n",
    "                            print(\"=\" * 60)\n",
    "                            print(f\"Compliance calculator expression: {expression}\" )\n",
    "                            print(f\"Compliance calculator result: {result}\" )\n",
    "                            print(\"=\" * 60)\n",
    "                            tool_results.append({\n",
    "                                \"toolResult\": {\n",
    "                                    \"toolUseId\": tool_use_id,\n",
    "                                    \"content\": [{\"text\": result}]\n",
    "                                }\n",
    "                            })\n",
    "                        elif tool_name == 'judged_scenario_json':\n",
    "                            tool_result = content_block['toolUse']['input']\n",
    "                            judged_scenario[\"judged-compliant\"] = tool_result['scenarios'][0]['judged-compliant']\n",
    "                            judged_scenario[\"judged-compliant-reason\"] = tool_result['scenarios'][0]['judged-compliant-reason']\n",
    "                            break\n",
    "                \n",
    "                if tool_results:\n",
    "                    messages.append({\"role\": \"assistant\", \"content\": response['output']['message']['content']})\n",
    "                    messages.append({\"role\": \"user\", \"content\": tool_results})\n",
    "                else:\n",
    "                    break\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        judged_scenario[\"llm-judge\"] = MODEL_ARN.split('/')[-1]\n",
    "        judged_scenario[\"judged-dtm\"] = datetime.datetime.now().isoformat()\n",
    "        judged_scenarios.append(judged_scenario)\n",
    "    \n",
    "    return judged_scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "execution_state": "idle",
   "id": "b17b51d7-4d3c-4258-bd1b-58e80adb8763",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T01:19:15.480727Z",
     "iopub.status.busy": "2026-01-12T01:19:15.480421Z",
     "iopub.status.idle": "2026-01-12T01:19:15.492584Z",
     "shell.execute_reply": "2026-01-12T01:19:15.489743Z",
     "shell.execute_reply.started": "2026-01-12T01:19:15.480702Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_scenarios_to_file(scenarios: List[Dict], output_path: str):\n",
    "    \n",
    "    # Print scenarios to console for immediate review\n",
    "    print(json.dumps(scenarios, indent=2))\n",
    "    \n",
    "    # Save to file with metadata and statistics\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump({\n",
    "            'total_scenarios': len(scenarios),\n",
    "            'compliant_count': sum(1 for s in scenarios if s['is-compliant']),\n",
    "            'non_compliant_count': sum(1 for s in scenarios if not s['is-compliant']),\n",
    "            'judged compliant_count': sum(1 for s in scenarios if s['judged-compliant']),\n",
    "            'judged non_compliant_count': sum(1 for s in scenarios if not s['judged-compliant']),\n",
    "            'scenarios': scenarios\n",
    "        }, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "execution_state": "idle",
   "id": "8b5a5088-bba4-4786-82b1-44374c091b26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T01:19:17.396721Z",
     "iopub.status.busy": "2026-01-12T01:19:17.396344Z",
     "iopub.status.idle": "2026-01-12T01:19:57.301528Z",
     "shell.execute_reply": "2026-01-12T01:19:57.300049Z",
     "shell.execute_reply.started": "2026-01-12T01:19:17.396697Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"scenario-id\": \"scenario-id-1\",\n",
      "    \"scenario-detail\": \"TechGuard Financial Services, a major financial institution with 12,000+ employees processing customer PII across 45 branch locations, implemented a comprehensive privacy and security framework for their new mobile banking platform serving 2.8 million customers. The Chief Privacy Officer established rigorous PII disclosure accounting per PM-21, requiring all customer data disclosures to regulatory agencies, credit bureaus, and third-party processors be recorded within 24 hours in their automated Privacy Management System, with detailed records including disclosure date, specific data elements shared (account balances, transaction history, personal identifiers), business purpose (regulatory compliance, credit verification, fraud prevention), and complete recipient contact information including designated privacy officers at each receiving organization. The system maintains comprehensive audit trails of all record access and modifications, with disclosure accounting records retained for seven years (exceeding the five-year minimum) and automated responses to customer requests for disclosure accounting delivered within 15 days. The Business Continuity Manager conducted extensive capacity planning per CP-2.2, documenting minimum processing requirements of 50,000 concurrent users during contingency operations (reduced from normal 150,000 capacity), telecommunications bandwidth requirements of 2.5 Gbps for essential banking services during degraded operations, and environmental support specifications including backup power systems capable of supporting 72 hours of operations across primary and alternate data centers. Annual capacity validation testing confirmed the ability to maintain core banking functions including account access, bill payments, and fraud monitoring during simulated disaster scenarios. The organization deployed comprehensive sensor usage controls per SC-42.2 for their mobile app location services and biometric authentication systems, with documented authorized uses limited to fraud prevention, regulatory compliance, and customer-requested services, supported by contractual restrictions with third-party analytics providers explicitly prohibiting customer behavior profiling or marketing data sales. Development teams maintained strict integrity mapping per SA-10.5 between master build repositories and production deployments, with automated cryptographic hash verification performed within 12 hours of any security-relevant component updates, comprehensive documentation of all version control activities, and immediate resolution protocols for any mapping discrepancies affecting the mobile banking platform's security functions.\\n\\nPolicies referenced: policy_PM-21, policy_CP-2.2, policy_SC-42.2, policy_SA-10.5\",\n",
      "    \"is-compliant\": true,\n",
      "    \"non-compliant-reason\": \"\",\n",
      "    \"judged-compliant\": true,\n",
      "    \"judged-compliant-reason\": \"\",\n",
      "    \"llm-judge\": \"us.anthropic.claude-sonnet-4-20250514-v1:0\",\n",
      "    \"judged-dtm\": \"2026-01-12T01:19:21.430455\"\n",
      "  },\n",
      "  {\n",
      "    \"scenario-id\": \"scenario-id-2\",\n",
      "    \"scenario-detail\": \"MedSecure Healthcare Network, a multi-state healthcare provider with 6,800 employees managing patient records across 28 medical facilities, deployed an integrated patient monitoring and electronic health record system processing sensitive medical information for 450,000+ patients. The Data Protection Officer implemented comprehensive PII disclosure accounting per PM-21 for all patient data sharing with insurance providers, specialist physicians, and medical research institutions, utilizing an automated Health Information Exchange tracking system that records every disclosure within 8 hours including specific medical data categories shared (diagnostic results, treatment histories, prescription records), disclosure purposes (treatment coordination, insurance claims processing, approved research studies), complete recipient healthcare provider information with NPI numbers and HIPAA compliance certifications, and maintains audit trails accessible to patients within 20 days of valid requests. All disclosure records are retained for ten years per healthcare regulations, exceeding the five-year minimum requirement. The Business Continuity Manager established detailed capacity planning per CP-2.2 addressing critical patient care systems, with documented minimum processing capacity of 15,000 concurrent electronic health record users during emergency operations (reduced from normal 35,000), telecommunications requirements ensuring 1.8 Gbps bandwidth for telemedicine and emergency communications during degraded operations, and environmental support planning including medical-grade power systems with 96-hour backup capacity and specialized cooling systems for medical equipment across primary and disaster recovery sites. Quarterly capacity testing validates the ability to maintain life-critical patient monitoring, emergency department operations, and pharmaceutical management during contingency scenarios. The organization deployed strict sensor authorization controls per SC-42.2 for patient monitoring devices, security cameras in restricted areas, and mobile health applications, with authorized uses explicitly limited to patient care, facility security, and regulatory compliance, supported by vendor contracts containing specific restrictions prohibiting patient data use for commercial purposes or unauthorized research. The development team maintains rigorous version control integrity mapping per SA-10.5 for all medical device software and security components, performing automated SHA-256 hash verification within 6 hours of any updates to life-critical systems, maintaining detailed change documentation with medical device compliance tracking, and implementing immediate escalation procedures for any integrity discrepancies affecting patient safety systems or PHI security controls.\\n\\nPolicies referenced: policy_PM-21, policy_CP-2.2, policy_SC-42.2, policy_SA-10.5\",\n",
      "    \"is-compliant\": true,\n",
      "    \"non-compliant-reason\": \"\",\n",
      "    \"judged-compliant\": false,\n",
      "    \"judged-compliant-reason\": \"Violates POL_PM-21 [RULE-01] and [RULE-04]. [RULE-01] states 'All PII disclosures MUST be recorded in the accounting system within 24 hours of the disclosure event' but the scenario shows disclosure recording within 8 hours, which is compliant. However, [RULE-04] states 'Accounting records MUST be provided to data subjects within 30 days of a valid request' but the scenario provides records within 20 days, which actually exceeds the requirement and is compliant. Upon re-evaluation, the scenario appears compliant with all policies: PM-21 (8-hour recording < 24-hour requirement, 20-day response < 30-day requirement, 10-year retention > 5-year minimum), CP-2.2 (documented capacity planning with testing), SC-42.2 (authorized use controls with contractual restrictions), and SA-10.5 (6-hour verification < 24-hour requirement with proper documentation).\",\n",
      "    \"llm-judge\": \"us.anthropic.claude-sonnet-4-20250514-v1:0\",\n",
      "    \"judged-dtm\": \"2026-01-12T01:19:26.673229\"\n",
      "  },\n",
      "  {\n",
      "    \"scenario-id\": \"scenario-id-3\",\n",
      "    \"scenario-detail\": \"TechnoSecure Industries, a leading cybersecurity firm with 3,200 employees, is conducting comprehensive control assessments for their flagship cloud security platform serving Fortune 500 clients. The Chief Information Security Officer has established a robust assessment program with certified control assessors possessing CISSP and CISA credentials with 5+ years of experience conducting independent assessments. The assessment team developed detailed assessment plans documenting scope covering 247 security controls, standardized testing procedures aligned with NIST SP 800-53A, comprehensive environment analysis including cloud and hybrid components, qualified team composition with specialized expertise areas, and clear roles and responsibilities matrix approved by the Authorizing Official within required timeframes. The organization maintains strict assessment frequencies with high-impact systems assessed annually, moderate-impact systems every 18 months, and low-impact systems every 3 years, with continuous monitoring capabilities providing real-time control effectiveness validation. Assessment reports document detailed findings with control implementation status, operational effectiveness ratings, and compliance determinations distributed to system owners, security teams, and executive leadership within 15 days of assessment completion. The audit record review program operates with Security Operations Center analysts performing daily reviews of high-impact system logs, weekly analysis of moderate-impact systems, and monthly reviews for low-impact systems, utilizing SIEM correlation rules to identify failed authentication attempts, privilege escalation events, unauthorized configuration changes, and anomalous data access patterns. When the organization's threat intelligence team received credible information about advanced persistent threats targeting similar organizations, the audit review frequency was immediately increased for all internet-facing systems and notification procedures were enhanced to ensure security findings are escalated to incident response teams within 12 hours. All developers contracted for system components provide comprehensive functional property descriptions focusing on externally visible security control interfaces, API specifications, and user-accessible functionality while properly excluding internal implementation algorithms and proprietary code structures, with all documentation reviewed and approved by system owners and the CISO before deployment authorization. The organization's privacy program ensures that when personally identifiable information requires correction or deletion, automated notification systems immediately alert all affected individuals within 8 business days and notify authorized recipients including data processors, business partners, and regulatory agencies within 3 business days, maintaining comprehensive notification records for 5 years to demonstrate compliance with privacy requirements.\\n\\nPolicies referenced: policy_SI-18.5, policy_SA-4.1, policy_AU-6, policy_CA-2\",\n",
      "    \"is-compliant\": false,\n",
      "    \"non-compliant-reason\": \"This scenario violates AU-6 RULE-01 which requires high-impact systems to have audit records reviewed at frequencies not exceeding 7 days. The scenario states that high-impact systems receive daily reviews, but when threat intelligence was received about advanced persistent threats, the audit review frequency was 'immediately increased for all internet-facing systems' rather than being adjusted within the required 30-day timeframe as specified in RULE-04. While the scenario appears compliant on the surface with daily reviews, the failure to formally adjust the documented review procedures within 30 days of receiving credible threat intelligence constitutes a violation.\",\n",
      "    \"judged-compliant\": true,\n",
      "    \"judged-compliant-reason\": \"\",\n",
      "    \"llm-judge\": \"us.anthropic.claude-sonnet-4-20250514-v1:0\",\n",
      "    \"judged-dtm\": \"2026-01-12T01:19:30.248218\"\n",
      "  },\n",
      "  {\n",
      "    \"scenario-id\": \"scenario-id-4\",\n",
      "    \"scenario-detail\": \"DataGuard Corporation, a healthcare technology company with 4,800 employees managing electronic health records for 2.3 million patients across 450 medical facilities, has implemented comprehensive compliance programs across their HIPAA-regulated infrastructure. The organization's control assessment program utilizes certified assessors with appropriate independence levels, including external third-party assessors for initial authorizations and qualified internal assessors for ongoing monitoring activities, all possessing healthcare cybersecurity certifications and 7+ years of relevant experience. Assessment plans are meticulously developed including detailed scope definitions covering all 324 implemented security and privacy controls, standardized assessment procedures based on NIST SP 800-53A methodology, comprehensive environment documentation encompassing cloud, on-premises, and hybrid components, qualified assessment team composition with healthcare domain expertise, and clearly defined roles and responsibilities matrices. The Authorizing Official reviews and approves all assessment plans within established timeframes, with assessment execution occurring annually for high-impact systems, every 18 months for moderate-impact systems, and every 3 years for low-impact systems. Assessment reports provide detailed documentation of control implementation status, operational effectiveness determinations, and compliance findings distributed to appropriate stakeholders including system owners, privacy officers, and executive leadership within 20 days of assessment completion. The audit record review program operates through a 24/7 Security Operations Center with analysts performing real-time monitoring of critical healthcare systems, daily analysis of high-impact systems processing protected health information, weekly reviews of moderate-impact administrative systems, and monthly analysis of low-impact support systems. When personally identifiable information requires correction or deletion, the organization's automated privacy management system ensures affected individuals receive notification within 8 business days and all authorized recipients including healthcare partners, insurance providers, and regulatory bodies are notified within 4 business days, with comprehensive notification records maintained for 7 years. The organization's secure development program requires all system developers and component vendors to provide detailed functional property descriptions focusing on externally visible security control interfaces, healthcare interoperability standards compliance, user authentication mechanisms, and audit logging capabilities while appropriately excluding proprietary algorithms and internal processing logic. All functional property documentation undergoes thorough review by system owners and receives formal approval from the Chief Information Security Officer before system deployment or service activation, ensuring complete alignment with healthcare regulatory requirements and organizational security standards.\\n\\nPolicies referenced: policy_SI-18.5, policy_SA-4.1, policy_AU-6, policy_CA-2\",\n",
      "    \"is-compliant\": false,\n",
      "    \"non-compliant-reason\": \"This scenario violates SI-18.5 RULE-03 which requires all authorized recipients of corrected or deleted PII to be notified within 5 business days of the correction or deletion action. The scenario states that authorized recipients including healthcare partners, insurance providers, and regulatory bodies are notified within 4 business days, which appears compliant. However, the scenario also mentions that the organization maintains notification records for 7 years, when RULE-04 only requires notification records to be maintained for a minimum of 3 years. While maintaining records longer than required is not itself a violation, the scenario violates RULE-03 by stating notifications occur within 4 business days when the rule requires 5 business days - this creates an impossible standard that cannot be consistently met.\",\n",
      "    \"judged-compliant\": false,\n",
      "    \"judged-compliant-reason\": \"Violates policy_AU-6 [RULE-01]: High-impact systems processing protected health information are reviewed daily, but RULE-01 requires high-impact systems to be reviewed at frequencies not exceeding 7 days. Daily review (1 day) complies. However, moderate-impact systems are reviewed every 18 months for assessments and weekly for audit records, but low-impact systems have monthly audit record review which exceeds the 30-day maximum frequency required by RULE-01 for standard systems.\",\n",
      "    \"llm-judge\": \"us.anthropic.claude-sonnet-4-20250514-v1:0\",\n",
      "    \"judged-dtm\": \"2026-01-12T01:19:36.412636\"\n",
      "  },\n",
      "  {\n",
      "    \"scenario-id\": \"scenario-id-5\",\n",
      "    \"scenario-detail\": \"TechnoSecure Industries, a financial technology company with 3,200 employees processing sensitive customer financial data, is implementing a comprehensive security awareness program across their distributed workforce spanning 15 locations. The Chief Information Security Officer established mandatory practical exercises per AT-3.3 ensuring all security training programs include hands-on simulations with software developers completing secure coding exercises annually focusing on SQL injection prevention, cross-site scripting mitigation, and buffer overflow protection using vulnerable code laboratories and penetration testing scenarios. Senior executives and C-level leadership participate in quarterly targeted phishing simulation exercises designed to mimic advanced persistent threat campaigns, with failure rates tracked and remedial training provided within 30 days of unsuccessful attempts. Privacy personnel complete annual practical exercises on conducting privacy impact assessments using real-world data processing scenarios and PII handling simulations with performance metrics measuring identification accuracy and response time to privacy incidents. The organization obtained comprehensive system documentation per SA-5 for all critical financial processing systems including administrator documentation describing secure configuration of payment processing gateways, fraud detection algorithms, and encryption key management systems, with user documentation provided to customer service representatives detailing secure methods for accessing customer accounts and handling sensitive financial information. When third-party vendor documentation was unavailable for legacy mainframe systems, documented attempts to obtain missing materials were completed within 30 days and remediation actions implemented including reverse-engineering configuration guides and establishing internal knowledge transfer sessions. The infrastructure team implemented priority-based resource allocation per SC-6 with payment processing systems receiving highest priority allocation of CPU, memory, and network bandwidth, customer service applications at medium priority, and development environments at lowest priority with resource quotas preventing any single process from consuming more than 60% of available system resources. Audit log transfer mechanisms per AU-4.1 automatically transfer security logs from critical payment processing systems to alternate storage every 4 hours with verification checksums confirming successful delivery, while standard business applications transfer logs daily to cloud-based SIEM systems with automated alerts generated for any transfer failures within 2 hours.\\n\\nPolicies referenced: policy_AT-3.3, policy_SA-5, policy_SC-6, policy_AU-4.1\",\n",
      "    \"is-compliant\": true,\n",
      "    \"non-compliant-reason\": \"\",\n",
      "    \"judged-compliant\": true,\n",
      "    \"judged-compliant-reason\": \"\",\n",
      "    \"llm-judge\": \"us.anthropic.claude-sonnet-4-20250514-v1:0\",\n",
      "    \"judged-dtm\": \"2026-01-12T01:19:39.567517\"\n",
      "  },\n",
      "  {\n",
      "    \"scenario-id\": \"scenario-id-6\",\n",
      "    \"scenario-detail\": \"GlobalMed Healthcare Systems, a healthcare provider network with 12,000 employees managing electronic health records across 45 medical facilities, deployed an integrated security and privacy training program addressing HIPAA compliance requirements and cybersecurity threats. The Training Manager implemented comprehensive practical exercises per AT-3.3 with all healthcare staff participating in annual hands-on simulations including phishing email identification workshops, medical device security scenarios, and patient data breach response exercises with pass/fail criteria requiring 85% accuracy rates and mandatory remedial training for failures. Software development teams building electronic health record systems complete quarterly secure coding exercises addressing healthcare-specific vulnerabilities including HL7 message injection attacks, FHIR API security flaws, and medical device communication protocols with performance metrics tracking vulnerability detection rates and secure coding implementation scores. Executive leadership including Chief Medical Officer and Chief Privacy Officer participate in monthly targeted phishing simulations using healthcare-themed social engineering attacks with immediate feedback and security awareness reinforcement. Privacy officers complete semi-annual practical exercises on HIPAA risk assessments, patient consent management scenarios, and breach notification procedures using simulated patient data incidents. The organization maintains complete system documentation per SA-5 for all medical information systems including detailed administrator documentation for electronic health record databases describing secure patient data encryption, access control configurations, and audit trail management, with user documentation provided to medical staff explaining secure login procedures, patient data access protocols, and privacy protection responsibilities. Third-party medical device documentation was systematically obtained from manufacturers with documented attempts for legacy equipment and remediation plans including vendor security assessments and internal configuration documentation. Infrastructure teams implemented priority-based resource allocation per SC-6 ensuring critical patient monitoring systems receive maximum CPU and network priority, electronic health records maintain high priority allocation, and administrative systems operate at standard priority levels with resource quotas limiting individual applications to 40% of server capacity to prevent system interference. Audit log management per AU-4.1 transfers security logs from patient monitoring systems and medical devices to HIPAA-compliant alternate storage every 2 hours with cryptographic verification, while administrative systems transfer logs every 6 hours to secure cloud storage with automated monitoring detecting transfer failures and generating alerts within 1 hour for immediate investigation by the security operations center.\\n\\nPolicies referenced: policy_AT-3.3, policy_SA-5, policy_SC-6, policy_AU-4.1\",\n",
      "    \"is-compliant\": true,\n",
      "    \"non-compliant-reason\": \"\",\n",
      "    \"judged-compliant\": false,\n",
      "    \"judged-compliant-reason\": \"Violates policy_AT-3.3 [RULE-04]: Senior leaders and executives MUST participate in targeted phishing simulation exercises at least quarterly. The scenario states executive leadership participates in 'monthly' simulations, but policy requires 'quarterly' (every 90 days). Monthly frequency (30 days) exceeds the maximum allowed interval of 90 days, creating a compliance violation.\",\n",
      "    \"llm-judge\": \"us.anthropic.claude-sonnet-4-20250514-v1:0\",\n",
      "    \"judged-dtm\": \"2026-01-12T01:19:44.172864\"\n",
      "  },\n",
      "  {\n",
      "    \"scenario-id\": \"scenario-id-7\",\n",
      "    \"scenario-detail\": \"TechnoSphere Industries, a Fortune 500 technology company with 15,000+ employees across 25 global offices, is implementing a comprehensive security modernization initiative for their enterprise infrastructure. The IT Security Manager established detailed software installation policies per CM-11 governing all workstations, servers, and mobile devices, with explicit definitions of permitted software sources including Microsoft Store for Business, Apple App Store for Business, and pre-approved vendor portals like Adobe Creative Cloud and Atlassian marketplace. Users can install security patches from official vendor sites, business-approved applications from organizational app stores, and development tools with proper approval documentation. The organization deployed automated enforcement through Microsoft System Center Configuration Manager and Group Policy Objects preventing installation of unauthorized software, with quarterly compliance monitoring generating detailed reports of all installation attempts. All software installation activities are logged through centralized SIEM systems capturing timestamps, user identities, software names, and approval status. The Information Disposal program follows SI-12.3 requirements with NIST 800-88 compliant destruction methods for high-sensitivity data including employee records, financial data, and customer PII using certified destruction services with certificates of destruction. Retention schedules are established by data type with automatic disposal triggers 30 days after retention period expiration unless legal holds apply. The cryptographic infrastructure implements SC-12.2 controls using FIPS 140-2 validated Hardware Security Modules from Thales and SafeNet for all symmetric key operations including AES-256 encryption keys for database encryption, SSL/TLS certificates, and VPN tunneling. Key generation, distribution, and lifecycle management processes are fully documented and audited quarterly. Physical security controls per PE-5.2 require badge authentication on all 847 network printers and multifunction devices across facilities, with unclaimed documents automatically purged after 4 hours for sensitive materials. However, the development team recently installed Python interpreters and various open-source libraries directly from PyPI and GitHub repositories on production servers without formal approval documentation to accelerate a critical customer deliverable, bypassing the standard software request process that requires written approval for non-standard software installations.\\n\\nPolicies referenced: policy_CM-11, policy_SI-12.3, policy_SC-12.2, policy_PE-5.2\",\n",
      "    \"is-compliant\": false,\n",
      "    \"non-compliant-reason\": \"This scenario violates CM-11 RULE-07 which requires users to obtain written approval before installing non-standard software. The development team installed Python interpreters and open-source libraries from PyPI and GitHub without formal approval documentation, bypassing the standard software request process. While the organization has comprehensive policies and controls in place for software installation, the specific installation of development tools without written approval constitutes a policy violation.\",\n",
      "    \"judged-compliant\": false,\n",
      "    \"judged-compliant-reason\": \"Violates POL_CM-11 [RULE-03] and [RULE-07]. RULE-03 states 'Users MUST NOT install software with unknown pedigree, open source software without approval, or applications from unauthorized sources.' RULE-07 states 'Users requiring non-standard software MUST obtain written approval before installation.' The development team installed Python interpreters and open-source libraries from PyPI and GitHub without formal approval documentation, violating both rules regarding unauthorized software sources and missing written approval for non-standard software.\",\n",
      "    \"llm-judge\": \"us.anthropic.claude-sonnet-4-20250514-v1:0\",\n",
      "    \"judged-dtm\": \"2026-01-12T01:19:49.521151\"\n",
      "  },\n",
      "  {\n",
      "    \"scenario-id\": \"scenario-id-8\",\n",
      "    \"scenario-detail\": \"CyberGuard Financial Services, a regional banking institution with 3,200 employees serving 500,000+ customers across 180 branch locations, maintains strict compliance with federal banking regulations and cybersecurity frameworks. The organization implemented comprehensive software installation governance per CM-11 with written policies defining permitted software sources including approved vendor portals, security patch repositories, and organizational app stores. Automated enforcement mechanisms through Microsoft Intune and endpoint detection systems prevent unauthorized installations, with monthly compliance reviews generating violation reports. All software installation attempts are logged with detailed audit trails including user identity, timestamp, software details, and approval status. The company's secure information disposal program follows SI-12.3 requirements using NIST 800-88 compliant methods for customer financial records, transaction data, and employee information with documented retention schedules and automated disposal triggers. High-sensitivity PII disposal requires certified destruction services with certificates of destruction, and all disposal activities are logged with responsible party identification. Cryptographic operations implement SC-12.2 controls using FIPS 140-2 validated key management systems from IBM and Entrust for symmetric key production, control, and distribution supporting customer transaction encryption, secure communications, and data protection. The key management infrastructure maintains current FIPS validation status with quarterly assessments and comprehensive documentation. Physical output device security per PE-5.2 requires smart card authentication on all 340 network printers, copiers, and multifunction devices across branch locations and corporate facilities, with failed authentication alerts and automatic document purging after 4 hours for sensitive materials. However, the organization's legacy mainframe system containing 15 years of archived customer transaction records continues operating beyond the 7-year regulatory retention period without formal disposal, as the disposal activities have been delayed for 8 months past the retention expiration date due to ongoing system migration planning, with no legal holds currently active on the archived data.\\n\\nPolicies referenced: policy_CM-11, policy_SI-12.3, policy_SC-12.2, policy_PE-5.2\",\n",
      "    \"is-compliant\": false,\n",
      "    \"non-compliant-reason\": \"This scenario violates SI-12.3 RULE-02 which requires information disposal to occur within 30 days after the established retention period expires unless legal hold applies. The archived customer transaction records have exceeded their 7-year retention period by 8 months (240 days) without disposal, and no legal holds are active. The 30-day disposal deadline has been significantly exceeded, making this a clear policy violation despite the organization's otherwise comprehensive compliance program.\",\n",
      "    \"judged-compliant\": false,\n",
      "    \"judged-compliant-reason\": \"Violates POL_SI-12.3 [RULE-02]: Information disposal MUST occur within 30 days after the established retention period expires unless legal hold applies. The legacy mainframe system data disposal has been delayed 8 months past the 7-year retention period expiration with no legal holds active, far exceeding the required 30-day disposal window.\",\n",
      "    \"llm-judge\": \"us.anthropic.claude-sonnet-4-20250514-v1:0\",\n",
      "    \"judged-dtm\": \"2026-01-12T01:19:56.958716\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "source_scenarios_file = \"scenarios.json\"\n",
    "judged_scenarios_file = \"judged_scenarios.json\"\n",
    "\n",
    "source_scenarios = load_scenarios_from_s3(INPUT_BUCKET, INPUT_PREFIX, source_scenarios_file)\n",
    "\n",
    "judged_scenarios = judge_scenarios(\n",
    "    source_scenarios,\n",
    "    MODEL_ARN,\n",
    "    KNOWLEDGE_BASE_ID\n",
    ")\n",
    "save_scenarios_to_file(judged_scenarios, '/home/sagemaker-user/' + judged_scenarios_file)\n",
    "save_scenarios_to_s3(judged_scenarios, OUTPUT_BUCKET, OUTPUT_PREFIX, judged_scenarios_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "execution_state": "idle",
   "id": "93818d94-146b-4a31-bdf9-1e25bc916410",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ae2603e-4fea-446e-9216-700fc15171c2",
   "metadata": {},
   "source": [
    "## ScenarioJudger\n",
    "\n",
    " - Reads a file from S3 containing json compliance scenarios of the format:\n",
    "```json\n",
    "{\n",
    "  \"scenarios\": [\n",
    "    {\n",
    "      \"scenario-id\": \"scenario-id-1\",\n",
    "      \"scenario-detail\": \"A new employee, Sarah Johnson, joins the IT department...\",\n",
    "      \"is-compliant\": false,\n",
    "      \"non-compliant-reason\": \"The scenario violates...\" \n",
    "    },\n",
    "    {\n",
    "      \"scenario-id\": \"scenario-id-2\", \n",
    "      \"scenario-detail\": \"TechCorp implements a comprehensive incident response procedure...\",\n",
    "      \"is-compliant\": true,\n",
    "      \"non-compliant-reason\": \"\" \n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    " - Evaluates the veracity each scenario-detail based on RAGed NIST-based policies in Bedrock knowledgebase, comparing its determination against \"is-compliant\" in the json.\n",
    " - When its determination differs, generates json records:\n",
    "```json\n",
    "{\n",
    "  \"scenarios\": [\n",
    "    {\n",
    "      \"scenario-id\": \"scenario-id-1\",\n",
    "      \"scenario-detail\": \"A new employee, Sarah Johnson, joins the IT department...\",\n",
    "      \"is-compliant\": false,\n",
    "      \"non-compliant-reason\": \"The scenario violates...\",\n",
    "      \"judged-compliant\": true,\n",
    "      \"judged-compliant-reason\": \"Considered the rules AC...  and scenario is not in violation...\"\n",
    "      \"llm-judge\": \"us.anthropic.claude-sonnet-4-20250514-v1:0\",\n",
    "      \"judged-dtm\":  \n",
    "    },\n",
    "    {\n",
    "      \"scenario-id\": \"scenario-id-2\", \n",
    "      \"scenario-detail\": \"TechCorp implements a comprehensive incident response procedure...\",\n",
    "      \"is-compliant\": true,\n",
    "      \"non-compliant-reason\": \"\", \n",
    "      \"judged-compliant\": false,\n",
    "      \"judged-compliant-reason\": \"Scenario violates access control policy...\",\n",
    "      \"llm-judge\": \"us.anthropic.claude-sonnet-4-20250514-v1:0\",\n",
    "      \"judged-dtm\":   \n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    " - Stores json records back to S3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "execution_state": "idle",
   "id": "721c6452-39b4-4d10-875f-87c1fb55f2df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T15:16:35.124077Z",
     "iopub.status.busy": "2026-01-09T15:16:35.123874Z",
     "iopub.status.idle": "2026-01-09T15:16:35.246409Z",
     "shell.execute_reply": "2026-01-09T15:16:35.244134Z",
     "shell.execute_reply.started": "2026-01-09T15:16:35.124057Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import boto3  # AWS SDK for Python\n",
    "import datetime\n",
    "import json   # JSON handling\n",
    "import time   # For rate limiting between API calls\n",
    "from compliance_calculator import compliance_calculator, CALCULATOR_TOOL\n",
    "from typing import List, Dict  # Type hints\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION SECTION - Update these values\n",
    "# ============================================================================\n",
    "# S3 Configuration\n",
    "INPUT_BUCKET = '183023889407-us-east-1-compliance-rule-generator'\n",
    "INPUT_PREFIX = 'scenarios/'  # Folder path in S3 where scenarios are stored\n",
    "OUTPUT_BUCKET = '183023889407-us-east-1-compliance-rule-generator'\n",
    "OUTPUT_PREFIX = 'scenarios-judged/'  # Folder path for results\n",
    "# AWS Region\n",
    "AWS_REGION = 'us-east-1'\n",
    "# AWS Bedrock Knowledge Base containing NIST policies\n",
    "KNOWLEDGE_BASE_ID = 'T8EW10IU3Z'\n",
    "\n",
    "MAX_TOKENS = 4096\n",
    "TEMPERATURE = 0.7\n",
    "\n",
    "# Available Bedrock model ARNs with performance notes\n",
    "MODELS = {\n",
    "    'premium': 'arn:aws:bedrock:us-east-1:183023889407:inference-profile/global.anthropic.claude-opus-4-5-20251101-v1:0', # not available\n",
    "    'good': 'arn:aws:bedrock:us-east-1:183023889407:inference-profile/global.anthropic.claude-sonnet-4-5-20250929-v1:0', # times out\n",
    "    'balanced': 'arn:aws:bedrock:us-east-1:183023889407:inference-profile/us.anthropic.claude-sonnet-4-20250514-v1:0',  # recommended\n",
    "    'fast_cheap': 'arn:aws:bedrock:us-east-1:183023889407:inference-profile/us.anthropic.claude-haiku-4-5-20251001-v1:0',\n",
    "    'aws_native_premier': 'arn:aws:bedrock:us-east-1:183023889407:inference-profile/us.amazon.nova-premier-v1:0',\n",
    "    'aws_native_pro': 'arn:aws:bedrock:us-east-1:183023889407:inference-profile/us.amazon.nova-pro-v1:0'\n",
    "}\n",
    "MODEL_ARN = MODELS['balanced']  # Default model selection\n",
    "\n",
    "# JSON tool configuration for Bedrock Converse API\n",
    "# Forces the model to return structured JSON with specific schema\n",
    "TOOL_CONFIG = {\n",
    "    \"tools\": [{\n",
    "        \"toolSpec\": {\n",
    "            \"name\": \"judged_scenario_json\",\n",
    "            \"description\": \"Return judged compliance scenarios as JSON\",\n",
    "            \"inputSchema\": {\n",
    "                \"json\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"scenarios\": {  # Array of scenario objects\n",
    "                            \"type\": \"array\",\n",
    "                            \"items\": {\n",
    "                                \"type\": \"object\",\n",
    "                                \"properties\": {\n",
    "                                    \"judged-compliant\": {\"type\": \"boolean\"},\n",
    "                                    \"judged-compliant-reason\": {\"type\": \"string\"}\n",
    "                                },\n",
    "                                \"required\": [\"judged-compliant\", \"judged-compliant-reason\"]\n",
    "                            }\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"scenarios\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }],\n",
    "    \"toolChoice\": {\"tool\": {\"name\": \"judged_scenario_json\"}}  # Force use of the JSON tool\n",
    "}\n",
    "\n",
    "# Initialize AWS Bedrock clients\n",
    "bedrock_agent_runtime = boto3.client('bedrock-agent-runtime', region_name='us-east-1')  # For knowledge base retrieval\n",
    "bedrock_runtime = boto3.client('bedrock-runtime', region_name='us-east-1')  # For model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "execution_state": "idle",
   "id": "1abdea2c-e311-4358-8b11-3f02472ad8ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T15:16:35.248016Z",
     "iopub.status.busy": "2026-01-09T15:16:35.247590Z",
     "iopub.status.idle": "2026-01-09T15:16:35.256314Z",
     "shell.execute_reply": "2026-01-09T15:16:35.254550Z",
     "shell.execute_reply.started": "2026-01-09T15:16:35.247989Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_scenarios_from_s3(input_bucket: str = INPUT_BUCKET, input_prefix: str = INPUT_PREFIX, object_name: str = \"scenarios.json\") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Load scenarios from S3 JSON file.\n",
    "    \"\"\"\n",
    "    s3 = boto3.client('s3')\n",
    "    response = s3.get_object(Bucket=input_bucket, Key=input_prefix+object_name)\n",
    "    json_data = json.loads(response['Body'].read().decode('utf-8'))\n",
    "    return json_data[\"scenarios\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "execution_state": "idle",
   "id": "fa5e2795-d84a-452f-9dba-a9ede04e259f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T15:16:35.257481Z",
     "iopub.status.busy": "2026-01-09T15:16:35.257082Z",
     "iopub.status.idle": "2026-01-09T15:16:35.266728Z",
     "shell.execute_reply": "2026-01-09T15:16:35.263626Z",
     "shell.execute_reply.started": "2026-01-09T15:16:35.257453Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_scenarios_to_s3(scenarios: List[Dict], output_bucket: str = OUTPUT_BUCKET, output_prefix: str = OUTPUT_PREFIX, object_name: str = \"scenarios.json\"):\n",
    "    \"\"\"\n",
    "    Save generated scenarios to a S3.\n",
    "    \"\"\"\n",
    "    s3 = boto3.client('s3')\n",
    "    json_data = json.dumps({\"scenarios\": scenarios}, indent=2)\n",
    "    s3.put_object(Bucket=output_bucket, Key=output_prefix+object_name, Body=json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "execution_state": "idle",
   "id": "2e937950-914d-4f2e-88bb-0d757125f96a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T15:16:35.271511Z",
     "iopub.status.busy": "2026-01-09T15:16:35.270738Z",
     "iopub.status.idle": "2026-01-09T15:16:35.283102Z",
     "shell.execute_reply": "2026-01-09T15:16:35.281350Z",
     "shell.execute_reply.started": "2026-01-09T15:16:35.271285Z"
    }
   },
   "outputs": [],
   "source": [
    "def retrieve_policies_by_id(policy_ids: List[str], kb_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve specific policies from knowledge base by exact ID match.\n",
    "    \"\"\"\n",
    "    \n",
    "    policies = []\n",
    "    for policy_id in policy_ids:\n",
    "        response = bedrock_agent_runtime.retrieve(\n",
    "            knowledgeBaseId=kb_id,\n",
    "            retrievalQuery={'text': policy_id},\n",
    "            retrievalConfiguration={'vectorSearchConfiguration': {'numberOfResults': 4}} # return 4 results because vector search might not return the exact policy document as the first result.\n",
    "        )\n",
    "        for result in response['retrievalResults']:\n",
    "            if policy_id in result['content']['text']:\n",
    "                policies.append(f\"{policy_id}:\\n{result['content']['text']}\")\n",
    "                break\n",
    "    return \"\\n\\n\".join(policies)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "execution_state": "idle",
   "id": "new-process-cell",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T15:16:35.288020Z",
     "iopub.status.busy": "2026-01-09T15:16:35.287693Z",
     "iopub.status.idle": "2026-01-09T15:16:35.309644Z",
     "shell.execute_reply": "2026-01-09T15:16:35.304345Z",
     "shell.execute_reply.started": "2026-01-09T15:16:35.287986Z"
    }
   },
   "outputs": [],
   "source": [
    "def judge_scenarios(source_scenarios: List[Dict], model_arn: str, kb_id: str = KNOWLEDGE_BASE_ID) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Process scenarios and add judgment fields.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract model ID from ARN (Converse API requires model ID, not full ARN)\n",
    "    model_id = model_arn.split('/')[-1] if '/' in model_arn else model_arn\n",
    "    \n",
    "    judged_scenarios = []\n",
    "    for scenario in source_scenarios:\n",
    "        judged_scenario = scenario.copy()\n",
    "\n",
    "        # Extract policy IDs from scenario and pull the policy data from the knowledge base\n",
    "        import re\n",
    "        policy_match = re.search(r'Policies referenced: (.+)', scenario[\"scenario-detail\"])\n",
    "        if policy_match:\n",
    "            policy_ids = [p.strip().replace('policy_', '') for p in policy_match.group(1).split(',')]\n",
    "            retrieved_policies = retrieve_policies_by_id(policy_ids, kb_id)\n",
    "        else:\n",
    "            print(f\"No policies referenced in scenario: {scenario['scenario-detail']}\")\n",
    "            continue\n",
    "                \n",
    "        prompt = f\"\"\"\n",
    "        You are **ComplianceEvaluator**, an expert AI compliance analyst specializing in NIST 800-53 controls and policies. \n",
    "        Your mission is to judge organizational policy scenarios against reference policies stored in your knowledge base.\n",
    "                \n",
    "        **Your Expertise:**\n",
    "        - Deep understanding of all NIST 800-53 Rev. 5 control families (AC, AT, AU, CA, CM, CP, IA, IR, MA, MP, PE, PL, PM, PS, PT, RA, SA, SC, SI, SR)\n",
    "        - Policy-to-control mapping and compliance evaluation\n",
    "        - Evidence-focused assessment methodology\n",
    "\n",
    "        **Task:** Judge if the scenario complies with ALL referenced policies from your knowledge base.\n",
    "\n",
    "        **Avoid judging scenarios based on cost-benefit principles or concentration percentages.\n",
    "    \n",
    "        **Note that non-US citizens cannot obtain US security clearances.**\n",
    "        \n",
    "        **Response Format:**\n",
    "        {{\n",
    "          \"judged-compliant\": true/false, true if you determined the scenario is compliant with the organizational \n",
    "        policies stored in your knowledge base.  false if the scenario is not compliant.\n",
    "          \"judged-compliant-reason\": \"Empty if compliant. If the scenario is not compliant, explain very briefly why it is not compliant, citing\n",
    "          exactly the policy ID(s) is violates, followed by the extracted policy text that indicates non-compliance.\"\n",
    "        }}\n",
    "\n",
    "        **Evaluate scenario against this policy data**:\n",
    "        {retrieved_policies}\n",
    "\n",
    "        **Here is the actual compliance scenario to judge**:\n",
    "        {scenario[\"scenario-detail\"]}\n",
    "        \"\"\"\n",
    "        response = bedrock_runtime.converse(\n",
    "            modelId=model_id,\n",
    "            messages=[{\"role\": \"user\", \"content\": [{\"text\": prompt}]}],\n",
    "            toolConfig=TOOL_CONFIG,\n",
    "            inferenceConfig={\n",
    "                \"maxTokens\": MAX_TOKENS,\n",
    "                \"temperature\": TEMPERATURE\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        tool_result = response['output']['message']['content'][0]['toolUse']['input']\n",
    "        judged_scenario[\"judged-compliant\"] = tool_result['scenarios'][0]['judged-compliant']\n",
    "        judged_scenario[\"judged-compliant-reason\"] = tool_result['scenarios'][0]['judged-compliant-reason']\n",
    "\n",
    "        judged_scenario[\"llm-judge\"] = MODEL_ARN.split('/')[-1]\n",
    "        judged_scenario[\"judged-dtm\"] = datetime.datetime.now().isoformat()\n",
    "        judged_scenarios.append(judged_scenario)\n",
    "    \n",
    "    return judged_scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "execution_state": "idle",
   "id": "b17b51d7-4d3c-4258-bd1b-58e80adb8763",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T15:16:35.310564Z",
     "iopub.status.busy": "2026-01-09T15:16:35.310304Z",
     "iopub.status.idle": "2026-01-09T15:16:35.321446Z",
     "shell.execute_reply": "2026-01-09T15:16:35.320317Z",
     "shell.execute_reply.started": "2026-01-09T15:16:35.310541Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_scenarios_to_file(scenarios: List[Dict], output_path: str):\n",
    "    \n",
    "    # Print scenarios to console for immediate review\n",
    "    print(json.dumps(scenarios, indent=2))\n",
    "    \n",
    "    # Save to file with metadata and statistics\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump({\n",
    "            'total_scenarios': len(scenarios),\n",
    "            'compliant_count': sum(1 for s in scenarios if s['is-compliant']),\n",
    "            'non_compliant_count': sum(1 for s in scenarios if not s['is-compliant']),\n",
    "            'judged compliant_count': sum(1 for s in scenarios if s['judged-compliant']),\n",
    "            'judged non_compliant_count': sum(1 for s in scenarios if not s['judged-compliant']),\n",
    "            'scenarios': scenarios\n",
    "        }, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "execution_state": "idle",
   "id": "8b5a5088-bba4-4786-82b1-44374c091b26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T15:34:27.559886Z",
     "iopub.status.busy": "2026-01-09T15:34:27.558853Z",
     "iopub.status.idle": "2026-01-09T15:35:05.115409Z",
     "shell.execute_reply": "2026-01-09T15:35:05.109738Z",
     "shell.execute_reply.started": "2026-01-09T15:34:27.559853Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"scenario-id\": \"scenario-id-1\",\n",
      "    \"scenario-detail\": \"CyberGuard Defense Systems, a defense contractor with 6,200+ employees supporting unclassified national security projects, is implementing a comprehensive security monitoring infrastructure across 15 geographically distributed facilities. The Chief Information Security Officer established behavior analysis capabilities per IR-4.13 with SOC analysts conducting systematic monitoring of anomalous behavior patterns across production environments including classified development systems, secure communication networks, and threat intelligence platforms, with automated detection systems triggering analysis within 2 hours of anomalous activity detection in production systems and comprehensive documentation of targeted resources, timing patterns, and correlation with known adversarial tactics, techniques, and procedures integrated into threat intelligence feeds within 24 hours of analysis completion. The network security team implemented protocol validation controls per SC-7.23 across all boundary protection devices including Cisco ASA firewalls, F5 load balancers, and Palo Alto Networks intrusion prevention systems configured to suppress detailed error messages and return only generic responses for protocol format validation failures from external sources, with debugging modes explicitly disabled on all production boundary systems and quarterly reviews of approved exceptions for legitimate security testing activities. The infrastructure team deployed redundant time synchronization per SC-45.2 with primary authoritative time sources located in Colorado Springs and secondary sources in Norfolk, Virginia (1,200+ miles separation) providing automatic failover within 3 minutes of primary source unavailability, continuous monitoring of time drift maintaining accuracy within 500 milliseconds for security-critical systems and 15 seconds for standard systems, with geolocation verification documented annually and comprehensive logging of all synchronization events. The network architecture team enforced boundary protection per SC-7.25 ensuring all unclassified national security systems connect to external networks exclusively through approved Juniper SRX firewalls and Fortinet FortiGate security appliances with mandatory traffic mediation, deep packet inspection capabilities, and strict prohibition of direct connections or bypass mechanisms, with continuous monitoring detecting and immediately isolating any unauthorized connection attempts to maintain complete network isolation for sensitive defense contractor operations.\\n\\nPolicies referenced: IR-4.13, SC-7.23, SC-45.2, SC-7.25\",\n",
      "    \"is-compliant\": true,\n",
      "    \"non-compliant-reason\": \"\",\n",
      "    \"judged-compliant\": false,\n",
      "    \"judged-compliant-reason\": \"Policy IR-4.13 [RULE-02] violation: Analysis start time exceeds 4-hour requirement for production environments. The scenario states analysis begins within 2 hours, which complies, but SC-45.2 [RULE-02] violation: Failover time of 3 minutes exceeds the 60-second requirement. 'Systems MUST automatically failover to the secondary time source within 60 seconds when the primary source becomes unavailable.'\",\n",
      "    \"llm-judge\": \"us.anthropic.claude-sonnet-4-20250514-v1:0\",\n",
      "    \"judged-dtm\": \"2026-01-09T15:34:34.243876\"\n",
      "  },\n",
      "  {\n",
      "    \"scenario-id\": \"scenario-id-2\",\n",
      "    \"scenario-detail\": \"SecureNet Technologies, a government contractor with 4,800+ employees supporting critical infrastructure protection initiatives, deployed an integrated security operations center managing unclassified national security systems across 22 facilities nationwide. The incident response team implemented comprehensive behavior analysis per IR-4.13 with threat intelligence analysts conducting daily analysis of deception environment activities including honeypots, network decoys, and canary tokens to identify adversarial reconnaissance patterns, lateral movement attempts, and data exfiltration techniques, with structured analysis methodology examining targeted resources within production environments, timing correlation analysis identifying attack patterns, and integration of behavioral findings into MITRE ATT&CK framework mappings completed within 36 hours of analysis completion for enhanced threat hunting capabilities. The cybersecurity team configured boundary protection systems per SC-7.23 including Check Point quantum firewalls, Barracuda web application firewalls, and McAfee network security platforms with protocol validation configured to disable sender feedback mechanisms, preventing disclosure of system configuration details, version information, or stack traces to external attackers while maintaining generic error responses for all protocol format validation failures and documented exception management processes for authorized penetration testing activities requiring detailed feedback with quarterly security architecture team reviews. The systems administration team established geographically redundant time synchronization per SC-45.2 utilizing primary time sources in San Antonio, Texas and secondary sources in Boston, Massachusetts (1,500+ miles separation) with Network Time Protocol servers configured for automatic failover within 4 minutes, continuous monitoring maintaining time accuracy within 800 milliseconds for security monitoring systems and 20 seconds for administrative systems, with automated alerting for synchronization failures and annual verification of geographic separation using updated geolocation databases. The network operations center enforced strict boundary controls per SC-7.25 ensuring all unclassified national security systems utilize mandatory boundary protection through Cisco Firepower threat defense appliances and Sophos XG firewalls with comprehensive traffic mediation, application-layer inspection, and zero-tolerance policies for direct external network connections, including cloud service access through approved security gateways with encrypted tunnels and continuous compliance monitoring preventing unauthorized network bypass attempts across the entire infrastructure supporting critical government operations.\\n\\nPolicies referenced: IR-4.13, SC-7.23, SC-45.2, SC-7.25\",\n",
      "    \"is-compliant\": true,\n",
      "    \"non-compliant-reason\": \"\",\n",
      "    \"judged-compliant\": false,\n",
      "    \"judged-compliant-reason\": \"The scenario violates POL_SC-45.2 [RULE-02] which states 'Systems MUST automatically synchronize internal clocks to the secondary authoritative time source within 5 minutes when the primary source becomes unavailable.' The scenario describes failover within 4 minutes, but the rule requires failover within 5 minutes or less. However, the scenario also violates POL_SC-45.2 [RULE-05] which states 'Maximum acceptable time drift between system clocks and authoritative time sources SHALL NOT exceed 1 second for security-critical systems and 30 seconds for standard systems.' The scenario shows time accuracy of 800 milliseconds for security monitoring systems, which exceeds the 1 second limit for security-critical systems.\",\n",
      "    \"llm-judge\": \"us.anthropic.claude-sonnet-4-20250514-v1:0\",\n",
      "    \"judged-dtm\": \"2026-01-09T15:34:39.203680\"\n",
      "  },\n",
      "  {\n",
      "    \"scenario-id\": \"scenario-id-3\",\n",
      "    \"scenario-detail\": \"TechGlobal Financial Services, a multinational banking corporation with 15,000+ employees across 45 countries, is implementing a comprehensive digital transformation initiative to modernize their core banking platform and customer-facing applications. The Chief Technology Officer has established a robust mission and business process definition framework per PM-11 requirements, with all 23 business units formally documenting their processes including explicit security and privacy considerations, comprehensive risk assessments covering operations, assets, individuals, and national implications, and detailed information protection needs determination through organizational risk management processes. The cybersecurity team deployed state-of-the-art automated integrity monitoring systems per SI-7.2 across all production environments, utilizing NIST-compliant tools that continuously monitor system files, configurations, and data integrity with immediate notification capabilities configured to alert designated personnel within 8 minutes of detecting any discrepancies, including system owners, information security officers, and system administrators through redundant delivery mechanisms including encrypted email, SMS, and secure messaging platforms. The enterprise architecture team implemented a sophisticated defense-in-depth strategy per PL-8.1 with controls strategically allocated across network perimeter (firewalls, IPS), application layer (WAF, code analysis), data layer (encryption, DLP), and endpoint protection (EDR, device controls), with all controls tested for coordination and mutual reinforcement to prevent adverse consequences and ensure comprehensive protection of high-value financial assets. The vulnerability management program per RA-5 conducts automated SCAP-compliant scanning bi-weekly across all 2,847 systems and applications, with critical vulnerabilities (CVSS 9.0-10.0) remediated within 48 hours, high vulnerabilities within 21 days, and comprehensive analysis completed within 3 business days of scan completion. However, during the recent quarterly business process review, the privacy team discovered that the new customer onboarding workflow processes personally identifiable information from 12 different data sources but the privacy risk assessment was scheduled for completion next quarter due to resource constraints.\\n\\nPolicies referenced: PM-11, SI-7.2, PL-8.1, RA-5\",\n",
      "    \"is-compliant\": false,\n",
      "    \"non-compliant-reason\": \"This scenario violates PM-11 RULE-03 which requires that PII processing needs arising from defined mission and business processes MUST be identified, assessed for privacy risks, and documented. The customer onboarding workflow is actively processing PII from multiple sources without a completed privacy risk assessment, creating a compliance violation despite all other policies being properly implemented.\",\n",
      "    \"judged-compliant\": false,\n",
      "    \"judged-compliant-reason\": \"Policy PM-11 violation: [RULE-03] states 'PII processing needs arising from defined mission and business processes MUST be determined through privacy risk assessments and documented in the PII inventory.' The scenario indicates that the new customer onboarding workflow processes PII from 12 different data sources but the privacy risk assessment was scheduled for completion next quarter, meaning the process is operational without the required privacy risk assessment being completed.\",\n",
      "    \"llm-judge\": \"us.anthropic.claude-sonnet-4-20250514-v1:0\",\n",
      "    \"judged-dtm\": \"2026-01-09T15:34:43.448010\"\n",
      "  },\n",
      "  {\n",
      "    \"scenario-id\": \"scenario-id-4\",\n",
      "    \"scenario-detail\": \"CyberShield Manufacturing, a leading aerospace defense contractor with 6,200+ employees supporting classified government contracts, has established comprehensive security and compliance programs across their 18 manufacturing facilities and research centers. The organization maintains exemplary mission and business process definition per PM-11 with all operational processes formally documented including security and privacy considerations, annual reviews completed on schedule, information protection needs determined through rigorous risk management processes, and PII processing activities thoroughly assessed with documented privacy risk evaluations integrated into system categorization and control selection processes. The security operations center implemented advanced automated integrity monitoring per SI-7.2 using enterprise-grade tools that provide continuous verification of system files, configurations, and data across all production systems with immediate notifications delivered within 12 minutes to comprehensive distribution lists including system owners, security officers, administrators, and incident response teams through multiple redundant channels ensuring 24/7 coverage. The enterprise security architecture follows strict defense-in-depth principles per PL-8.1 with controls strategically allocated across physical security (biometric access, surveillance), network security (segmentation, monitoring), application security (secure coding, testing), and data protection (classification, encryption) layers, with all controls thoroughly tested for coordination and mutual reinforcement to protect classified intellectual property and manufacturing systems. The vulnerability management program per RA-5 utilizes SCAP-compliant scanning tools with signature updates performed twice weekly, comprehensive scans conducted every 21 days across all 1,456 systems and applications, with critical vulnerabilities remediated within 60 hours, high vulnerabilities within 25 days, and detailed analysis completed within 4 business days of scan completion with results shared immediately with relevant system owners and stakeholders.\\n\\nPolicies referenced: PM-11, SI-7.2, PL-8.1, RA-5\",\n",
      "    \"is-compliant\": false,\n",
      "    \"non-compliant-reason\": \"This scenario violates RA-5 RULE-01 which requires vulnerability scanning MUST be performed at least monthly (every 30 days) for all in-scope systems and applications. The organization is conducting scans every 21 days, which exceeds the maximum 30-day requirement, creating a compliance gap despite excellent performance in all other policy areas.\",\n",
      "    \"judged-compliant\": false,\n",
      "    \"judged-compliant-reason\": \"POL_RA-5 [RULE-01]: Vulnerability scanning MUST be performed at least monthly for all in-scope systems and applications. The scenario states scans are conducted every 21 days, which is less frequent than the required monthly (30-day maximum) interval.\",\n",
      "    \"llm-judge\": \"us.anthropic.claude-sonnet-4-20250514-v1:0\",\n",
      "    \"judged-dtm\": \"2026-01-09T15:34:48.595871\"\n",
      "  },\n",
      "  {\n",
      "    \"scenario-id\": \"scenario-id-5\",\n",
      "    \"scenario-detail\": \"GlobalTech Financial Services, a multinational banking corporation with 15,000+ employees, is implementing a new cross-domain information exchange system for processing sensitive customer financial data between their high-security trading floor environment and standard corporate network. The Security Architecture team designed transfer processes per AC-4.32 that operate with minimum complexity, ensuring transfer processes do not perform any content filtering while moving encrypted transaction data between security domains, with all filtering operations handled by dedicated filter pipelines at source and destination boundaries. The system validates filtering metadata including transaction classification, destination pipeline routing, and compliance tags before initiating any cross-domain transfers, with automated verification that all content has successfully completed anti-money laundering and fraud detection filtering before transfer to the corporate reporting pipeline. The Identity and Access Management team implemented cached authenticator expiration per IA-5.13 across all 2,400 workstations and mobile devices, with Windows domain-joined systems configured to expire cached credentials after 10 days of no domain controller connectivity, macOS systems bound to Active Directory expiring after 14 days, and mobile devices with high-privilege trading accounts expiring cached credentials within 24 hours regardless of network status. The Business Continuity team conducted comprehensive capacity planning per CP-2.2 for the new financial processing systems, documenting minimum processing capacity requirements of 50,000 transactions per hour during contingency operations, telecommunications bandwidth requirements of 10 Gbps for essential trading communications during degraded operations, and environmental support capacity including backup power systems capable of supporting critical trading operations for 72 hours with validated testing performed quarterly. Development teams structured all security-relevant components per SA-17.7 with least privilege principles, implementing role-based privilege separation where trading floor personnel access only market data functions, compliance officers access only regulatory reporting interfaces, and system administrators access only infrastructure management capabilities, with all modules designed for proper encapsulation and documented privilege decomposition justifying each component's minimum required access rights.\\n\\nPolicies referenced: AC-4.32, IA-5.13, CP-2.2, SA-17.7\",\n",
      "    \"is-compliant\": true,\n",
      "    \"non-compliant-reason\": \"\",\n",
      "    \"judged-compliant\": true,\n",
      "    \"judged-compliant-reason\": \"\",\n",
      "    \"llm-judge\": \"us.anthropic.claude-sonnet-4-20250514-v1:0\",\n",
      "    \"judged-dtm\": \"2026-01-09T15:34:51.504832\"\n",
      "  },\n",
      "  {\n",
      "    \"scenario-id\": \"scenario-id-6\",\n",
      "    \"scenario-detail\": \"CyberSecure Healthcare Network, a regional healthcare system with 12,000+ employees operating across 25 medical facilities, is deploying an integrated patient data management system that processes Protected Health Information (PHI) across multiple security domains including clinical networks, administrative systems, and research environments. The Information Security team implemented cross-domain transfer processes per AC-4.32 that maintain minimum complexity while transferring patient records between clinical and administrative domains, with transfer processes designed to validate filtering metadata containing patient consent levels, data classification tags, and HIPAA compliance indicators before initiating transfers, ensuring all PHI content successfully completes privacy filtering and de-identification processes before moving to research pipeline destinations without the transfer processes themselves performing any content modification or filtering operations. The organization deployed cached authenticator management per IA-5.13 across all clinical workstations, nurse stations, and mobile medical devices, configuring domain-joined Windows systems to expire cached credentials after 10 days of no network connectivity, Linux-based medical imaging systems with LDAP authentication to expire cached credentials after 7 days, and mobile devices used by physicians and nurses to expire cached credentials within 24 hours for high-privilege accounts accessing controlled substances databases and patient financial information. The Disaster Recovery team conducted detailed capacity planning per CP-2.2 for the patient data management infrastructure, identifying minimum processing capacity requirements of 25,000 patient record transactions per hour during emergency operations, telecommunications capacity of 5 Gbps bandwidth for essential clinical communications during facility evacuations, and environmental support planning including backup power systems, cooling capacity for server rooms, and space allocation for temporary clinical operations with annual validation testing demonstrating system performance under degraded conditions. The development team structured all healthcare system components per SA-17.7 using least privilege architecture, implementing fine-grained role separation where clinical staff access only patient care functions relevant to their specialty, administrative personnel access only billing and scheduling interfaces, researchers access only de-identified data sets, and IT support staff access only system maintenance functions, with comprehensive documentation demonstrating privilege decomposition and encapsulated module design preventing direct external access to sensitive PHI databases.\\n\\nPolicies referenced: AC-4.32, IA-5.13, CP-2.2, SA-17.7\",\n",
      "    \"is-compliant\": true,\n",
      "    \"non-compliant-reason\": \"\",\n",
      "    \"judged-compliant\": true,\n",
      "    \"judged-compliant-reason\": \"\",\n",
      "    \"llm-judge\": \"us.anthropic.claude-sonnet-4-20250514-v1:0\",\n",
      "    \"judged-dtm\": \"2026-01-09T15:34:55.492188\"\n",
      "  },\n",
      "  {\n",
      "    \"scenario-id\": \"scenario-id-7\",\n",
      "    \"scenario-detail\": \"GlobalTech Defense Solutions, a major defense contractor with 12,000+ employees supporting classified government contracts, is implementing a comprehensive media protection program across their 15 secure facilities processing SECRET and TOP SECRET information. The Chief Information Security Officer established a robust critical asset identification program per CP-2.8, conducting formal business impact analysis to identify mission-critical systems including the classified document management system supporting $3.2B in active contracts, the secure communications infrastructure enabling real-time coordination with Pentagon operations, and the intellectual property repository containing proprietary defense technologies. The organization maintains detailed inventories covering both technical assets (servers, network equipment, cryptographic modules) and operational assets (security procedures, cleared personnel, emergency response protocols) with quarterly reviews ensuring currency as new systems are deployed. The IT Operations team implemented comprehensive nonlocal maintenance controls per MA-4, requiring written approval from the Security Control Board for all remote diagnostic activities, employing PKI certificates with hardware tokens for multi-factor authentication, and maintaining continuous monitoring through their Security Operations Center with detailed session logging retained for 18 months. All remote maintenance sessions are immediately terminated upon completion with automated connection cleanup preventing residual access. The organization deployed linear content filter pipelines per AC-4.28 for all cross-domain information transfers between their unclassified development network and classified production environment, implementing non-bypassable filtering architecture with both discretionary access controls based on user clearance levels and mandatory access controls enforcing classification labels, ensuring consistent policy application across all filter stages. However, their media downgrading equipment used for declassifying technical documentation has not undergone testing for the past 14 months, despite the organizationally defined testing frequency of every 12 months, with the Media Protection Officer documenting equipment usage but deferring testing due to operational demands and vendor scheduling conflicts.\\n\\nPolicies referenced: MP-8.2, CP-2.8, MA-4, AC-4.28\",\n",
      "    \"is-compliant\": false,\n",
      "    \"non-compliant-reason\": \"The scenario violates MP-8.2 RULE-03 which requires equipment testing to be conducted according to the defined frequency and SHALL NOT exceed the maximum interval without documented risk acceptance. The media downgrading equipment has not been tested for 14 months, exceeding the 12-month defined frequency, and there is no documented risk acceptance for this delay.\",\n",
      "    \"judged-compliant\": false,\n",
      "    \"judged-compliant-reason\": \"The scenario violates POL_MP-8.2 [RULE-01] which states 'Downgrading equipment MUST be tested at least quarterly to ensure proper functionality and effectiveness.' The validation rule 'IF last_equipment_test_date > 90_days_ago THEN violation' is triggered since the media downgrading equipment has not been tested for 14 months (420+ days), far exceeding the required quarterly (90-day) testing frequency.\",\n",
      "    \"llm-judge\": \"us.anthropic.claude-sonnet-4-20250514-v1:0\",\n",
      "    \"judged-dtm\": \"2026-01-09T15:35:00.049040\"\n",
      "  },\n",
      "  {\n",
      "    \"scenario-id\": \"scenario-id-8\",\n",
      "    \"scenario-detail\": \"SecureVault Corporation, a financial services company with 6,800+ employees managing classified financial intelligence systems for federal agencies, is deploying advanced security controls across their hybrid cloud infrastructure supporting TOP SECRET/SCI operations. The organization implemented comprehensive critical asset identification per CP-2.8, conducting detailed business impact analysis to identify mission-critical components including their real-time threat intelligence platform processing classified financial data, the secure trading infrastructure supporting $8.7B in daily transactions, and the customer identity management system containing sensitive personal and financial records. The Chief Security Officer maintains current inventories encompassing both technical elements (database clusters, network security appliances, encryption systems) and operational elements (incident response procedures, cleared analyst teams, business continuity protocols) with semi-annual reviews triggered by significant infrastructure changes or new regulatory requirements. The company established rigorous nonlocal maintenance protocols per MA-4, mandating Security Review Board approval for all remote diagnostic activities, implementing RSA SecurID tokens with biometric authentication for vendor access, and deploying continuous session monitoring through their 24/7 Security Operations Center with comprehensive audit trails maintained for 15 months per regulatory requirements. All remote connections are automatically terminated within 5 minutes of maintenance completion using automated scripts preventing unauthorized persistence. The organization deployed sophisticated linear content filter pipelines per AC-4.28 for cross-domain transfers between their commercial banking network and classified intelligence systems, implementing mandatory access controls enforcing strict classification policies and discretionary access controls based on personnel clearance verification, with non-bypassable architecture ensuring all data passes through sequential filtering stages. Their media downgrading equipment undergoes rigorous monthly testing per organizational policy, with the last successful test completed 3 weeks ago and comprehensive documentation maintained by the Media Protection team. However, the critical asset identification process focuses exclusively on technical system components including servers, databases, and network infrastructure, but fails to identify operational aspects such as security procedures, personnel roles, and business processes that support mission and business functions.\\n\\nPolicies referenced: MP-8.2, CP-2.8, MA-4, AC-4.28\",\n",
      "    \"is-compliant\": false,\n",
      "    \"non-compliant-reason\": \"The scenario violates CP-2.8 RULE-02 which requires critical asset identification to include both technical aspects AND operational aspects. While technical assets are properly identified, the scenario explicitly states that operational aspects such as security procedures, personnel roles, and business processes are not included in the critical asset identification process.\",\n",
      "    \"judged-compliant\": false,\n",
      "    \"judged-compliant-reason\": \"Violates POL_CP-2.8 [RULE-02]: Critical asset identification MUST include both technical aspects (system components, IT services, IT products, mechanisms) and operational aspects (procedures, personnel). The scenario states 'the critical asset identification process focuses exclusively on technical system components... but fails to identify operational aspects such as security procedures, personnel roles, and business processes that support mission and business functions.'\",\n",
      "    \"llm-judge\": \"us.anthropic.claude-sonnet-4-20250514-v1:0\",\n",
      "    \"judged-dtm\": \"2026-01-09T15:35:04.099786\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "source_scenarios_file = \"scenarios.json\"\n",
    "judged_scenarios_file = \"judged_scenarios.json\"\n",
    "\n",
    "source_scenarios = load_scenarios_from_s3(INPUT_BUCKET, INPUT_PREFIX, source_scenarios_file)\n",
    "\n",
    "judged_scenarios = judge_scenarios(\n",
    "    source_scenarios,\n",
    "    MODEL_ARN,\n",
    "    KNOWLEDGE_BASE_ID\n",
    ")\n",
    "save_scenarios_to_file(judged_scenarios, '/home/sagemaker-user/' + judged_scenarios_file)\n",
    "save_scenarios_to_s3(judged_scenarios, OUTPUT_BUCKET, OUTPUT_PREFIX, judged_scenarios_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "execution_state": "idle",
   "id": "93818d94-146b-4a31-bdf9-1e25bc916410",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
